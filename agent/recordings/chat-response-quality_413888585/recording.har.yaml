log:
  _recordingName: chat-response-quality
  creator:
    comment: persister:fs
    name: Polly.JS
    version: 6.0.6
  entries:
    - _id: 9ccc3edd6f21b309791c774c159519e8
      _order: 0
      cache: {}
      request:
        bodySize: 5464
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-eba4660e6043cfdd29f7cb44316370f1-ae33b10035b33190-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What code do you have access to?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 86153
        content:
          mimeType: text/event-stream
          size: 86153
          text: >+
            event: completion

            data: {"completion":"Based on the provided context, I have access to the code in the repository https://github.com/sourcegraph/zoekt, which appears to be a fork of the original https://github.com/google/zoekt repository. The README file mentions that this is now the main maintained source for the Zoekt search engine.\n\nSome of the specific code mentioned in the README includes:\n\n- cmd/zoekt-index\n- cmd/zoekt-git-index  \n- cmd/zoekt-{repo-index,mirror-gitiles}\n- cmd/zoekt-webserver\n- cmd/zoekt\n- cmd/zoekt-indexserver\n- cmd/zoekt-sourcegraph-indexserver (Sourcegraph-specific)\n\nThe README provides instructions for downloading, indexing code repositories, searching via web interface/JSON API/CLI, installation, running as a search service, and dealing with symbol/ctag data.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:03 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:01.751Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 916d374bfb194ba7a3b8bd92eb875cd9
      _order: 0
      cache: {}
      request:
        bodySize: 5403
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8ef1e3d6d4b938b95dcc940f2edadb4f-91f3a3cf37297a7c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how do slices work in go?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 723137
        content:
          mimeType: text/event-stream
          size: 723137
          text: >+
            event: completion

            data: {"completion":"In Go, slices are reference types that provide a way to work with a section or \"slice\" of an underlying array. They are lightweight and provide a flexible way to work with arrays without the need for explicit memory management or resizing. Here are some key points about how slices work in Go:\n\n1. **Slices are References**: A slice is a reference type that points to an underlying array. It consists of three components: a pointer to the array, a length (the number of elements it contains), and a capacity (the maximum number of elements it can hold before resizing is required).\n\n2. **Length and Capacity**: The length of a slice is the number of elements it contains, while the capacity is the total number of elements it can hold without the need for resizing. The length can never exceed the capacity.\n\n3. **Creating Slices**: Slices can be created directly from arrays or by using the built-in `make` function. For example, `mySlice := []int{1, 2, 3}` creates a slice from an array literal, while `mySlice := make([]int, 3, 5)` creates a slice with a length of 3 and a capacity of 5.\n\n4. **Modifying Slices**: Slices can be modified by appending elements, removing elements, or even extending their capacity using the built-in `append` function. When the length of a slice reaches its capacity, a new, larger underlying array is allocated, and the existing elements are copied over.\n\n5. **Slice Expressions**: Slices can be created from other slices using \"slice expressions\" that specify the start and end indices. For example, `mySlice[1:3]` creates a new slice that points to the same underlying array as `mySlice` but includes only the elements at indices 1 and 2.\n\n6. **Slice Sharing**: Slices that are derived from the same underlying array share the same memory. Modifying an element in one slice will affect the same element in the other slices that share the same underlying array.\n\n7. **Nil Slices**: A nil slice has a length and capacity of 0 and does not point to an underlying array. Appending elements to a nil slice will create a new underlying array.\n\n8. **Passing Slices to Functions**: Slices are passed to functions by reference, so modifications made to the slice within the function will be visible to the caller.\n\nOverall, slices in Go provide a powerful and efficient way to work with arrays, allowing you to easily create, modify, and pass around sections of an array without the need for explicit memory management or resizing.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:09 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:07.943Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 6251e610397486790ac7ba3828202ed5
      _order: 0
      cache: {}
      request:
        bodySize: 5418
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c7e50f2fef32916e0ca7b848af43fe99-7d2db1090fabea42-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Do not make
                  any assumptions. Question: what does this regex do? 

                  /a|e|i|o|u/
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 96149
        content:
          mimeType: text/event-stream
          size: 96149
          text: >+
            event: completion

            data: {"completion":"The provided regular expression `/a|e|i|o|u/` is a pattern that matches any single character that is either 'a', 'e', 'i', 'o', or 'u'. It uses the vertical bar `|` as an alternation operator, which means it will match any one of the characters or patterns on either side of the bar.\n\nThis regular expression can be used to search for or match against vowels in a given string. For example, if you have a string \"hello\", this regex will match the characters 'e' and 'o' in that string.\n\nNote that this is a case-sensitive regex, so it will not match uppercase vowels 'A', 'E', 'I', 'O', or 'U' unless the regex is modified to include them or make it case-insensitive (e.g., `/a|e|i|o|u|A|E|I|O|U/i`).","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:19 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:17.959Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2e880aecb917c53851254709f67b2468
      _order: 0
      cache: {}
      request:
        bodySize: 4924
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-42e4739ea00b5040ea79f2118494479d-f6c9bb6d8b57ac74-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What does this repo do??"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 176735
        content:
          mimeType: text/event-stream
          size: 176735
          text: >+
            event: completion

            data: {"completion":"Based on the provided code, this repository appears to be part of Zoekt, which seems to be a code search engine or tool. The code deals with sorting and truncating search results based on various limits and options.\n\nSome key observations:\n\n1. The package is named `zoekt`, which likely refers to the Zoekt code search engine.\n2. The `SortAndTruncateFiles` function sorts and truncates a list of `FileMatch` results based on the provided `SearchOptions`.\n3. The `NewDisplayTruncator` function creates a stateful `DisplayTruncator` function that enforces limits on the number of documents (files) and matches (chunks or lines) displayed in the search results.\n4. The `limitMatches` function limits the number of chunk or line matches in each `FileMatch` based on the provided limit.\n5. The `limitChunkMatches` and `limitLineMatches` functions implement specific logic for truncating chunk matches and line matches, respectively, within a `FileMatch`.\n\nSo, in summary, this codebase appears to be part of Zoekt, a code search engine, and the provided code is responsible for sorting and truncating search results based on various limits and options specified by the user or the search configuration.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:30 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:28.730Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: e1fe7f3e47200ec1ce4968362025efbb
      _order: 0
      cache: {}
      request:
        bodySize: 32190
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ae1b8dbf0bb2317fc13cd4c9cdc52a0e-ea14226129f2b9d6-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: describe my code"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 224159
        content:
          mimeType: text/event-stream
          size: 224159
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, your code is part of the Zoekt project, which is a fast text search engine intended for use with source code. Here's a brief description of the different files:\n\n1. `src/external-services.ts`: This is a TypeScript file that seems to be part of the Sourcegraph codebase, which is likely using Zoekt as a dependency.\n\n2. `README.md`: This is the main README file for the Zoekt project. It provides instructions for downloading, indexing, searching, and installing Zoekt.\n\n3. `limit.go`: This Go file contains functions related to limiting the number of matches and file matches returned by Zoekt, based on various search options.\n\n4. `eval.go`: This is a Go file that contains the core search logic for Zoekt. It includes functions for simplifying queries, setting default search options, performing the actual search, gathering matches, and handling different types of queries (e.g., regexp, substring, branch queries).\n\nThe codebase appears to be written in a combination of Go (for the core Zoekt search engine) and TypeScript (for the Sourcegraph integration). The Go code is responsible for indexing source code repositories, parsing and evaluating search queries, and returning search results. The TypeScript code likely integrates Zoekt with the Sourcegraph codebase, possibly by exposing Zoekt's functionality through external services or APIs.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:39 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:35.601Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9d31e89dacdea3b3f7271115eaf63b4a
      _order: 0
      cache: {}
      request:
        bodySize: 5402
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-2e6ff4e8519c0ac9c2673b7b71c985c4-4b0568dbc9a8c14e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: @zoekt describe my code."
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 359990
        content:
          mimeType: text/event-stream
          size: 359990
          text: >+
            event: completion

            data: {"completion":"Based on the provided code snippets, it appears that this codebase is related to a project called Sourcegraph. The code snippets suggest that it deals with file watching, search and retrieval, and potentially some gRPC communication.\n\nHere's a breakdown of what each code snippet suggests:\n\n1. `agent.go`: This file defines an `Agent` struct, but without more context, it's difficult to determine its purpose.\n\n2. `watcher.go`: This file contains code for a `DirectoryWatcher` struct. It seems to be responsible for watching a directory for changes, loading shards (potentially related to file indexing or caching), and managing goroutines for scanning and watching the directory.\n\n3. `README.md`: This is a typical readme file found in most projects, likely containing information about the project.\n\n4. `limit.go`: This file contains code for sorting and truncating a slice of `FileMatch` structs based on certain options (`SearchOptions`). This suggests functionality related to search results and potentially limiting or truncating the results.\n\n5. `chunker_test.go`: This file contains a test case (`TestChunkerE2E`) for testing a `Chunker` component. The test involves setting up a gRPC server and client, streaming data, and verifying the chunking behavior. This suggests that the codebase may involve gRPC communication and potentially data streaming or chunking.\n\nOverall, based on the provided code snippets, it seems that this codebase is part of the Sourcegraph project and likely deals with file indexing, search, and retrieval, potentially involving gRPC communication and data streaming or chunking. However, without more context and a deeper understanding of the project's architecture and design, it's difficult to provide a more detailed description.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:45 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:43.887Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 09be36b2eae1620af1b6aa36101b8fe7
      _order: 0
      cache: {}
      request:
        bodySize: 5400
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b3c05e606e26ece4cbedbe2c1b8d517c-d6e1eb46e91c102e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: is my code base clean?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 193749
        content:
          mimeType: text/event-stream
          size: 193749
          text: >+
            event: completion

            data: {"completion":"Based solely on the limited code snippets provided, it's difficult to make a definitive assessment of whether the entire codebase is clean or not. A few observations:\n\n1. The code snippets themselves appear to be well-formatted and follow common Go style guidelines.\n2. The test case in `grpc/chunk/chunker_test.go` seems well-structured and comprehensive, which is a good sign.\n3. However, the snippets are very small and don't provide enough context about the overall architecture, coding practices, and adherence to principles like SOLID, DRY, etc.\n\nTo properly evaluate the cleanliness of a codebase, one would typically need to look at factors such as:\n\n- Overall code organization and structure\n- Naming conventions and consistency\n- Adherence to best practices and design patterns\n- Code duplication and potential for refactoring\n- Test coverage and quality of tests\n- Code complexity and readability\n- Proper use of language features and idioms\n- Presence of technical debt or code smells\n- Documentation and code comments\n- Consistency in coding styles and formatting\n\nWithout access to the broader codebase and context, it's difficult to make a fair assessment. A more comprehensive code review or static analysis would be required to provide a well-informed opinion on the overall cleanliness of the codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:22:55 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:22:53.452Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ed055e69aed2cac21126995707bbbea6
      _order: 0
      cache: {}
      request:
        bodySize: 10366
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cd87662d0520ce0ac15fd8132df149d3-c5c70a2f4aabd6e9-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What does directory watcher do?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 271604
        content:
          mimeType: text/event-stream
          size: 271604
          text: >+
            event: completion

            data: {"completion":"Based on the provided code snippet from `shards/watcher.go`, the `DirectoryWatcher` appears to be responsible for watching a directory for changes to files and reloading/updating some kind of data structure or index accordingly.\n\nHere's a breakdown of what the code is doing:\n\n1. The `newDirectoryWatcher` function creates a new `DirectoryWatcher` instance with the given directory path and a `shardLoader` (likely a function to load/reload data from the watched files).\n\n2. It initializes the `DirectoryWatcher` struct with the directory path, an empty map to store file timestamps, the `shardLoader`, and some channels for communication and synchronization.\n\n3. It starts a new goroutine that performs the following:\n   a. Defers closing the `ready` channel.\n   b. Calls `sw.scan()` to initially scan the directory and populate the timestamp map (likely).\n   c. Calls `sw.watch()` to start watching the directory for file changes.\n   d. If any errors occur during `scan` or `watch`, the error is stored in `sw.readyErr`.\n\n4. The `newDirectoryWatcher` function returns the newly created `DirectoryWatcher` instance.\n\nWhile the specific implementation details of `scan` and `watch` are not provided, based on the code and the naming conventions, we can infer that the `DirectoryWatcher` is responsible for monitoring a directory for file changes and triggering a reload/update of some data structure or index (likely related to search indexing) when changes are detected.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:02 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:00.944Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8f0855b18056bf1ea61f069b298fcfd2
      _order: 0
      cache: {}
      request:
        bodySize: 10368
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-d3f82810071b6fa3d59b2c02e1c34e66-a0d4a41f4928b79f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: where do we test the grpc chunker"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 17657
        content:
          mimeType: text/event-stream
          size: 17657
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the gRPC chunker is tested in the file `grpc/chunk/chunker_test.go`. Specifically, there is a test function `TestChunkerE2E` that tests the end-to-end behavior of the chunker by running a gRPC server and client and verifying the chunked messages received by the client.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:11 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:09.562Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c84cad3140c969dac76cda40d9181ada
      _order: 0
      cache: {}
      request:
        bodySize: 10102
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-bafe423a97736c75ac51cd036805a4a6-c4aecbddb9ea3cfa-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Are you capable of upgrading my pytorch
                  version to 1.0.0, there is a guide in the pytorch site"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 44881
        content:
          mimeType: text/event-stream
          size: 44881
          text: >+
            event: completion

            data: {"completion":"I'm afraid I don't have enough context to upgrade PyTorch versions or provide guidance on that based on the provided code. The code you shared is for zoekt, which is a text search engine written in Go. It does not seem to be related to PyTorch or Python at all.\n\nIf you need assistance with upgrading PyTorch, I'd suggest referring to the official PyTorch documentation and guides, as they would have the most up-to-date and accurate information on that process. Without any Python or PyTorch code context, I can't provide any specific advice for upgrading the library version.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:12.552Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: efd8697808232cc4dd6415785ad7cc1b
      _order: 0
      cache: {}
      request:
        bodySize: 10102
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-3ab9b7776993a3686b07e470272cb64b-c499060ec313f87f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Can you look through the files and
                  identify the conflicting packages that may be causing this?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 114740
        content:
          mimeType: text/event-stream
          size: 114740
          text: >+
            event: completion

            data: {"completion":"Unfortunately, there does not appear to be any conflicting packages or import statements in the code provided. The files shown are:\n\n1. `README.md` - This is a markdown file describing the Zoekt project, providing instructions on downloading, indexing, searching, and installing Zoekt. It does not contain any Go code or package imports.\n\n2. `limit.go` - This is a Go source file containing functions related to limiting the number of search results displayed, such as `SortAndTruncateFiles`, `NewDisplayTruncator`, `limitChunkMatches`, and `limitLineMatches`. It is part of the `zoekt` package, but there are no import statements in this file that could conflict with other packages.\n\nWithout any additional context or error messages indicating conflicts, it is difficult to identify package conflicts from the provided code snippets alone. Package conflicts typically arise when two or more imported packages have the same package name, or when there are cyclic import dependencies between packages.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:18 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:16.931Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f02b661d7cce05e0f8e7be9a9b3c54a8
      _order: 0
      cache: {}
      request:
        bodySize: 32222
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c2376ed72c7696807a40fb28e3a1d96b-0bcb6abb3c663a52-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Mind taking a second look at the file?
                  @limit.go"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 432346
        content:
          mimeType: text/event-stream
          size: 432346
          text: >+
            event: completion

            data: {"completion":"Sure, let's take a look at the file `limit.go`.\n\nThis file contains functions related to limiting the number of matches and chunk matches returned in search results. Here's a breakdown of the key functions:\n\n1. `SortAndTruncateFiles`: This is a convenience function that sorts the `FileMatch` slice and then truncates it based on the `SearchOptions` provided.\n\n2. `NewDisplayTruncator`: This function returns a `DisplayTruncator` function, which is a stateful function that enforces document and match display limits by truncating the input slice of `FileMatch` before returning it. If there are no limits to enforce, it returns a function that simply returns the input slice without any truncation.\n\n3. `limitChunkMatches`: This function limits the number of `ChunkMatches` in a given `FileMatch`. It truncates the `Ranges`, `SymbolInfo`, and `Content` fields of each `ChunkMatch` based on the provided limit.\n\n4. `limitLineMatches`: Similar to `limitChunkMatches`, but it limits the number of `LineMatches` in a `FileMatch` by truncating the `LineFragments` field.\n\nThe `limit.go` file seems to be responsible for enforcing the limits specified in the `SearchOptions`, such as `MaxDocDisplayCount` and `MaxMatchDisplayCount`. These limits are used to control the size of the search results, preventing potential issues caused by overly broad searches or large result sets.\n\nThe `limitChunkMatches` function is particularly interesting because it handles the truncation of `Content` in `ChunkMatches`. It does this by removing the last N lines from the `Content` string, where N is the difference between the line number of the end of the old last `Range` and the new last `Range` after truncation.\n\nOverall, these functions play a crucial role in managing the size and content of search results, ensuring that they remain within the specified limits and do not overload the system.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:27 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:23.803Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 3a212a27440dddfdd973cef42704f036
      _order: 0
      cache: {}
      request:
        bodySize: 10050
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-9f6d589ac353b212b10fddda69e58c37-9fe5e9e51cab34f0-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Why does this project use the MIT
                  license?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 30535
        content:
          mimeType: text/event-stream
          size: 30535
          text: >+
            event: completion

            data: {"completion":"Unfortunately, there is no information provided about why this project uses the MIT license. The provided context does not mention the license used by the project or the rationale behind choosing a particular license.\n\nMost open source projects choose licenses like MIT or Apache to allow it to be freely used, modified, and distributed by others. However, without any explicit details in the codebase context, I cannot provide a specific explanation for why the Zoekt project uses the MIT license.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:35 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:33.339Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 95aeef0309bcc1ce6f7227ef34a6cd4b
      _order: 0
      cache: {}
      request:
        bodySize: 32033
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-58ed7a4695cc63778068069a25146061-aac31087248549cb-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: See zoekt repo find location of tensor
                  function"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 107346
        content:
          mimeType: text/event-stream
          size: 107346
          text: >+
            event: completion

            data: {"completion":"Unfortunately, after looking through the provided code files, I could not find any references to a \"tensor\" function or related tensor operations.\n\nThe code in this repository appears to be for Zoekt, a fast text search engine intended for source code. It does not seem to contain any tensor/deep learning related functionality.\n\nThe files provided cover functionality related to:\n\n1. README.md - General overview and instructions for Zoekt\n2. limit.go - Code for limiting/truncating search results based on configured options\n3. eval.go - Core search evaluation logic, including parsing queries, simplifying queries, gathering matches, scoring files, etc.\n\nUnless the \"tensor\" function is referring to some internal data structure/algorithm name that I'm not able to infer from the code, there does not appear to be any implementation related to tensors in this codebase. Let me know if you need any clarification or have additional context to provide.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:41 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:37.173Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: af453c2e57dd3e6f441e7a1d2b77bc1c
      _order: 0
      cache: {}
      request:
        bodySize: 10415
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-88fa45aadd142304e590696059c048c2-db1ae0a1d01cc04c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Explain the logic in src/agent.go,
                  particularly how agents interact with ranking"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 19813
        content:
          mimeType: text/event-stream
          size: 19813
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided codebase context does not actually contain the `src/agent.go` file or any details about how \"agents\" work in this codebase. The only context given is a single line comment `// Agent is an agent`. Without more code from that file, I cannot provide an explanation of the logic or how agents may interact with ranking in this codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:45 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:44.046Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 943d9112c603f1339bacb030e7dc468f
      _order: 0
      cache: {}
      request:
        bodySize: 5450
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-7e56306ffb38421c36dcb7676e99d946-3bb60f2685e46f60-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: explain @README.md"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 227428
        content:
          mimeType: text/event-stream
          size: 227428
          text: >+
            event: completion

            data: {"completion":"The provided content is the README.md file for the Zoekt project. It provides an overview and instructions for using Zoekt, which is a fast text search engine intended for searching source code.\n\nHere are the main sections:\n\n1. **Introduction**: Explains what Zoekt is and provides some context on its name/pronunciation.\n\n2. **Instructions**:\n   - Downloading the Zoekt source code\n   - Indexing directories, Git repositories, and repo repositories (collections of Git repos)\n   - Searching indexed data via the web interface, JSON API, or CLI\n\n3. **Installation**: Suggests using a systemd unit file for a more organized installation on a Linux server.\n\n4. **Search Service**: Describes a service management program `zoekt-indexserver` that can mirror and index repositories from various sources like GitHub.\n\n5. **Symbol Search**: Recommends installing Universal ctags for improved symbol/code element search ranking.\n\n6. **Acknowledgements**: Credits the original creators of Zoekt.\n\n7. **Fork Details**: Explains the differences between this fork (sourcegraph/zoekt) and the original google/zoekt repository that it was forked from. Note that this is now the main/defacto source for Zoekt development.\n\n8. **Disclaimer**: States that this is not an official Google product.\n\nThe README provides instructions and context to help users understand, install, and use the Zoekt source code search engine effectively.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:49 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:47.429Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a68f6677d32627d41ae338a57a73545d
      _order: 0
      cache: {}
      request:
        bodySize: 11552
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-14d920bf80180297d76e3887886c5bbe-caa727f8a44184f5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  The provided content is the README.md file for the Zoekt
                  project. It provides an overview and instructions for using
                  Zoekt, which is a fast text search engine intended for
                  searching source code.


                  Here are the main sections:


                  1. **Introduction**: Explains what Zoekt is and provides some context on its name/pronunciation.


                  2. **Instructions**:
                     - Downloading the Zoekt source code
                     - Indexing directories, Git repositories, and repo repositories (collections of Git repos)
                     - Searching indexed data via the web interface, JSON API, or CLI

                  3. **Installation**: Suggests using a systemd unit file for a more organized installation on a Linux server.


                  4. **Search Service**: Describes a service management program `zoekt-indexserver` that can mirror and index repositories from various sources like GitHub.


                  5. **Symbol Search**: Recommends installing Universal ctags for improved symbol/code element search ranking.


                  6. **Acknowledgements**: Credits the original creators of Zoekt.


                  7. **Fork Details**: Explains the differences between this fork (sourcegraph/zoekt) and the original google/zoekt repository that it was forked from. Note that this is now the main/defacto source for Zoekt development.


                  8. **Disclaimer**: States that this is not an official Google product.


                  The README provides instructions and context to help users understand, install, and use the Zoekt source code search engine effectively.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: what does @limit.go do?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 325941
        content:
          mimeType: text/event-stream
          size: 325941
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file contains functions related to limiting or truncating the search results returned by Zoekt based on the specified search options.\n\nThe main functionality provided in this file is:\n\n1. `SortAndTruncateFiles`: This function sorts the `FileMatch` results and then truncates them based on the `SearchOptions` specified, such as `MaxDocDisplayCount` and `MaxMatchDisplayCount`.\n\n2. `DisplayTruncator`: This is a type alias for a function that takes a slice of `FileMatch` results and returns a truncated slice along with a boolean indicating if there are more results to be displayed.\n\n3. `NewDisplayTruncator`: This function returns a `DisplayTruncator` function that enforces the `MaxDocDisplayCount` and `MaxMatchDisplayCount` limits specified in the `SearchOptions`.\n\n4. `limitMatches`: This is a helper function used by `NewDisplayTruncator` to limit the number of matches in each `FileMatch` based on whether `ChunkMatches` or `LineMatches` should be limited.\n\n5. `limitChunkMatches`: This function limits the number of `ChunkMatches` in a `FileMatch` by truncating the `Ranges`, `SymbolInfo`, and `Content` fields as necessary.\n\n6. `limitLineMatches`: This function limits the number of `LineMatches` in a `FileMatch` by truncating the `LineFragments` field.\n\nIn summary, the `limit.go` file provides functionality to enforce limits on the number of file matches and individual line/chunk matches displayed in the search results, based on the specified search options. This helps in controlling the size of the results and improving performance when displaying large numbers of matches.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:57 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:55.657Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 572412178cbc35038abd10f8c222b3ca
      _order: 0
      cache: {}
      request:
        bodySize: 5463
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-bbcc04fbe91e8f2275c88a4e08114929-c8356a68c6a8e473-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What code do you have access to?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 226264
        content:
          mimeType: text/event-stream
          size: 226264
          text: >+
            event: completion

            data: {"completion":"Based on the information provided in the README.md file, I have access to the following code:\n\n1. The Zoekt text search engine, which is a fork of the original \"github.com/google/zoekt\" repository. This is now the main maintained source of Zoekt.\n\n2. The following command-line tools:\n   - `zoekt-index`: Used to index a directory.\n   - `zoekt-git-index`: Used to index a Git repository.\n   - `zoekt-repo-index` and `zoekt-mirror-gitiles`: Used to index Repo repositories.\n   - `zoekt-webserver`: Provides a web interface for searching.\n   - `zoekt`: Provides a command-line interface for searching.\n   - `zoekt-indexserver`: A service management program that mirrors and indexes repositories.\n\n3. Some Sourcegraph-specific changes, including:\n   - `zoekt-sourcegraph-indexserver`: A command that indexes all enabled repositories on Sourcegraph.\n   - Exposing the API via `keegancsmith/rpc`.\n   - Adding a `BranchesRepos` query primitive to efficiently specify a set of repositories to search.\n   - Handling empty shard directories on startup.\n   - Returning symbol/ctag data in search results and allowing symbol regex queries.\n   - Searching shards in order of repo name and ignoring shard ranking.\n\nThe README.md file provides instructions for downloading, indexing, and searching using the Zoekt codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:23:58 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:23:57.437Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 21179c2f2ed79e5dfe7366e62a84f0e1
      _order: 0
      cache: {}
      request:
        bodySize: 5402
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-f1c27e465d9e112fa949f80a219d41aa-ae5714a429980692-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how do slices work in go?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 461336
        content:
          mimeType: text/event-stream
          size: 461336
          text: >+
            event: completion

            data: {"completion":"Slices in Go are powerful data structures that provide a flexible and efficient way to work with collections of data. Here are some key points about how slices work in Go:\n\n1. **Underlying Array**: Slices are not arrays themselves, but they provide a view into a *backing array*. This means that slices don't store the actual data, but rather a reference to a section of an underlying array.\n\n2. **Length and Capacity**: Slices have two important properties: length and capacity. The length represents the number of elements in the slice, while the capacity represents the total size of the underlying array.\n\n3. **Slicing**: Slices can be *sliced* to create new slices that reference a subset of the underlying array. The syntax for slicing is `slice[start:end]`, where `start` is the inclusive index where the new slice begins, and `end` is the exclusive index where the new slice ends.\n\n4. **Zero Value**: The zero value of a slice is `nil`, which means the slice has a length and capacity of 0, and the backing array is also `nil`.\n\n5. **Appending**: Slices can be dynamically expanded using the `append()` function. If the underlying array has sufficient capacity, the new elements are simply added to the end of the slice. If the underlying array doesn't have enough capacity, a new, larger array is allocated, and the elements from the original array are copied over.\n\n6. **Memory Allocation**: When you create a new slice using the `make()` function, you can specify the length and capacity of the slice. This allows you to control the memory allocation and avoid unnecessary resizing of the underlying array.\n\n7. **Efficiency**: Slices are designed to be efficient in terms of memory usage and performance. Accessing elements in a slice is a constant-time operation, and appending to a slice is also efficient, especially when the underlying array has sufficient capacity.\n\nBy understanding these key aspects of how slices work in Go, you can write more efficient and effective code that utilizes this powerful data structure.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:02 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:01.404Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 64ba021a3b70f2403a54b394f36cc64a
      _order: 0
      cache: {}
      request:
        bodySize: 5417
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1f3fc3ffa40e0b89f62f209a67105c6a-075a7e907f5cd65b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Do not make
                  any assumptions. Question: what does this regex do? 

                  /a|e|i|o|u/
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 59822
        content:
          mimeType: text/event-stream
          size: 59822
          text: >+
            event: completion

            data: {"completion":"The provided regular expression `/a|e|i|o|u/` is a character class that matches any single character that is a lowercase vowel in the English alphabet. Specifically, it will match the characters \"a\", \"e\", \"i\", \"o\", or \"u\".\n\nThis type of regular expression is commonly used for tasks such as:\n\n1. Validating that a string contains at least one vowel character.\n2. Extracting all vowel characters from a given string.\n3. Performing substitutions or transformations on vowel characters within a string.\n\nThe `|` operator in the regex is used for alternation, allowing the regex to match any of the listed characters (a, e, i, o, or u).","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:07 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:06.559Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 12b8b0cb27c8e6bc0b1ec1b1486675fe
      _order: 0
      cache: {}
      request:
        bodySize: 4923
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1cc83c040c462fbbdcfc259816918b8c-512de2d82c7c3396-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What does this repo do??"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 128578
        content:
          mimeType: text/event-stream
          size: 128578
          text: >+
            event: completion

            data: {"completion":"Based on the code provided, this appears to be a part of the Zoekt codebase, which is a code search engine. The code in the `limit.go` file is responsible for handling the display limits for the search results.\n\nSpecifically, the `SortAndTruncateFiles` function takes a list of `FileMatch` objects and a `SearchOptions` struct, sorts the files, and then truncates the results based on the `MaxDocDisplayCount` and `MaxMatchDisplayCount` limits specified in the `SearchOptions`.\n\nThe `NewDisplayTruncator` function returns a `DisplayTruncator` function, which is responsible for enforcing the document and match display limits. The `limitChunkMatches` and `limitLineMatches` functions are used to limit the number of chunk matches and line matches, respectively, within each `FileMatch` object.\n\nOverall, this code is part of the functionality that handles the display of search results in the Zoekt codebase, ensuring that the number of documents and matches shown to the user is limited based on the specified options.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:11 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:11.063Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 5764dd37305781f515f84b24e9e4b30f
      _order: 0
      cache: {}
      request:
        bodySize: 10211
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-09b89c5bef0739c1447ab145adcab00d-c2a6b22dd995f992-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: describe my code"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 616935
        content:
          mimeType: text/event-stream
          size: 616935
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the code appears to be a part of the Zoekt search engine, which is a fast text search engine intended for use with source code. Here's a breakdown of the code:\n\n1. `SortAndTruncateFiles` function:\n   - This is a convenience function that sorts the provided `FileMatch` slices and then truncates them based on the search options.\n   - It calls the `SortFiles` function to sort the `FileMatch` slices and then calls the `NewDisplayTruncator` function to create a `DisplayTruncator` function, which is used to truncate the `FileMatch` slices.\n\n2. `DisplayTruncator` type and `NewDisplayTruncator` function:\n   - The `DisplayTruncator` is a stateful function that enforces document and match display limits by truncating and mutating the input `FileMatch` slices.\n   - The `NewDisplayTruncator` function returns a `DisplayTruncator` function and a boolean flag indicating whether there are any limits to enforce.\n   - If there are no limits to enforce, the `DisplayTruncator` function simply returns the input `FileMatch` slice as-is.\n   - If there are limits to enforce, the `DisplayTruncator` function will truncate the `FileMatch` slice based on the specified document and match limits.\n\n3. `limitMatches` function:\n   - This function is responsible for limiting the number of matches in the `FileMatch` slices.\n   - It calls either the `limitChunkMatches` or `limitLineMatches` function, depending on the `chunkMatches` flag in the `SearchOptions`.\n\n4. `limitChunkMatches` function:\n   - This function limits the number of `ChunkMatches` in a `FileMatch` object.\n   - It truncates the `Ranges`, `SymbolInfo`, and `Content` fields of the `ChunkMatches` to ensure that the limit is not exceeded.\n\n5. `limitLineMatches` function:\n   - This function limits the number of `LineMatches` in a `FileMatch` object.\n   - It truncates the `LineFragments` field of the `LineMatches` to ensure that the limit is not exceeded.\n\nOverall, this code is responsible for managing the display and match limits in the Zoekt search engine, ensuring that the search results are properly truncated and displayed according to the specified limits.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:13.766Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: fbf37118ae78331c2968cf8bfdfa26bd
      _order: 0
      cache: {}
      request:
        bodySize: 5401
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-06a6a4992b4e09ff3859982bf8f8a1d7-9ddfcd7f8d1d5c50-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: @zoekt describe my code."
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 41078
        content:
          mimeType: text/event-stream
          size: 41078
          text: >+
            event: completion

            data: {"completion":"I'm afraid I don't have enough context to provide a meaningful description of your code. The code snippets you provided are from various files in a codebase, but without more information about the overall project and its purpose, I cannot accurately describe your code. Could you please provide some additional context about the project, such as what it is used for, what the high-level architecture looks like, or any other relevant details that would help me better understand the codebase? With more context, I'd be happy to try and describe your code in more detail.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:19 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:18.846Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 36d1c4bb2d9d9a2446354bb66f6f99b6
      _order: 0
      cache: {}
      request:
        bodySize: 5399
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0d25af80f2383f6383b28cf92098d8a2-3cad675a5367e68d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: is my code base clean?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 211481
        content:
          mimeType: text/event-stream
          size: 211481
          text: >+
            event: completion

            data: {"completion":"Without access to the full codebase and more context, it's difficult for me to definitively assess whether the codebase is \"clean\" or not. Determining code cleanliness requires a more holistic review of the overall code structure, adherence to best practices, maintainability, test coverage, and other factors.\n\nThe provided code snippets give a limited view and don't provide enough information to make a comprehensive judgment. Some things that could indicate potential areas for improvement are:\n\n1. The commented-out code blocks in the `watcher.go` file, which suggests there might be unfinished or refactored functionality.\n2. The lack of comments or documentation in some of the files, which could impact code readability and maintainability.\n3. The presence of test code (in `chunker_test.go`) suggests the codebase includes tests, which is generally a positive sign, but more information about the test coverage and quality would be needed to fully assess the codebase.\n\nWithout a deeper understanding of the project's requirements, architecture, and development practices, it's difficult to provide a definitive assessment of the codebase's cleanliness. A more thorough review of the full codebase, including code organization, naming conventions, error handling, and adherence to established coding standards, would be necessary to provide a more detailed evaluation.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:20.768Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: bc231ff424e69e8a39947a3a7f6e2163
      _order: 0
      cache: {}
      request:
        bodySize: 10365
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e4808aada1eeef51aececdd7fed167e3-1507908e8eeabbff-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What does directory watcher do?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 244534
        content:
          mimeType: text/event-stream
          size: 244534
          text: >+
            event: completion

            data: {"completion":"Based on the code snippet provided for the `newDirectoryWatcher` function in the `watcher.go` file, the directory watcher appears to perform the following tasks:\n\n1. It creates a new `DirectoryWatcher` struct, which has the following fields:\n   - `dir`: the directory to watch\n   - `timestamps`: a map to keep track of the modification timestamps of files in the directory\n   - `loader`: a `shardLoader` function to load the file contents\n   - `ready`: a channel to signal when the watcher is ready\n   - `quit`: a channel to signal the watcher to stop\n   - `stopped`: a channel to signal when the watcher has stopped\n\n2. It starts a goroutine that performs two main operations:\n   - Scans the directory and initializes the `timestamps` map.\n   - Sets up a file watcher to monitor the directory for changes.\n\n3. If either the scan or the watch operation encounters an error, the error is stored in the `readyErr` field of the `DirectoryWatcher` struct.\n\n4. The `newDirectoryWatcher` function returns the newly created `DirectoryWatcher` struct and any error that occurred during initialization.\n\nIn summary, the directory watcher appears to be responsible for monitoring a directory for changes, keeping track of file modification timestamps, and loading the contents of the files in the directory. This functionality is likely used in a larger system to keep an index or cache up-to-date as the files in the directory change.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:25 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:24.441Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c9ba071705bcc16bf157456aa634c34d
      _order: 0
      cache: {}
      request:
        bodySize: 10367
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-315b7b737661a8524b74b21886e81d77-83c4dda9e82deadc-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: where do we test the grpc chunker"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 11222
        content:
          mimeType: text/event-stream
          size: 11222
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the grpc chunker is tested in the file `grpc/chunk/chunker_test.go`. Specifically, the `TestChunkerE2E` function in this file tests the end-to-end functionality of the grpc chunker.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:28 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:27.890Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0f5c86dac1838d4ca462fbc3cb9e4e0c
      _order: 0
      cache: {}
      request:
        bodySize: 10101
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-f9bb1decfd143eed0749a722eb9741a7-9d712a005b228c43-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Are you capable of upgrading my pytorch
                  version to 1.0.0, there is a guide in the pytorch site"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 52808
        content:
          mimeType: text/event-stream
          size: 52808
          text: >+
            event: completion

            data: {"completion":"I apologize, but I do not see any references to PyTorch or version upgrades in the provided codebase context. The codebase appears to be related to a text search engine called \"Zoekt\", and the code provided is for the `limit.go` file, which handles the truncation of search results. As an AI assistant, I do not have the capability to directly upgrade PyTorch versions or modify code that is not related to the provided context. If you have a separate PyTorch-based project that needs a version upgrade, I'd suggest consulting the PyTorch documentation or reaching out to the PyTorch community for guidance on how to perform that upgrade.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:30 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:29.324Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 559b962e2c32288900f917524cc96e80
      _order: 0
      cache: {}
      request:
        bodySize: 10101
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8e84fc888dc23476fdea73fdd6cc274d-0050d66fa4ad2bd5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Can you look through the files and
                  identify the conflicting packages that may be causing this?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 80022
        content:
          mimeType: text/event-stream
          size: 80022
          text: >+
            event: completion

            data: {"completion":"Based on the code provided, I don't see any obvious conflicting packages that might be causing issues. The code appears to be part of the `zoekt` package and is focused on limiting and truncating search results based on the specified search options.\n\nThe `limit.go` file contains functions for sorting and truncating the search results, as well as limiting the number of matches displayed. This seems to be a core part of the search functionality, and I don't see any references to conflicting external packages.\n\nWithout more context about the overall codebase and any specific issues you're facing, I can't identify any conflicting packages that may be causing problems. The code provided appears to be self-contained within the `zoekt` package and doesn't seem to have any obvious external dependencies that could be causing conflicts.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:32 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:31.564Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b80c76cfd3d6a58aab5aa8d854e53cc8
      _order: 0
      cache: {}
      request:
        bodySize: 10243
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-62d78063b14bfa9f510cfb0561f92303-f3e0daff0fc16023-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Mind taking a second look at the file?
                  @limit.go"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 348922
        content:
          mimeType: text/event-stream
          size: 348922
          text: >+
            event: completion

            data: {"completion":"Sure, let me take a closer look at the `limit.go` file.\n\nThe `limit.go` file contains utility functions related to limiting the number of search results displayed to the user. The main functions in this file are:\n\n1. `SortAndTruncateFiles`: This function takes a list of `FileMatch` objects and sorts them, and then truncates the list based on the search options.\n\n2. `NewDisplayTruncator`: This function returns a `DisplayTruncator` function that can be used to enforce document and match display limits. The `DisplayTruncator` function takes a list of `FileMatch` objects and returns a truncated list, along with a boolean indicating whether there are more results available.\n\n3. `limitMatches`: This function is used by `NewDisplayTruncator` to limit the number of matches in each `FileMatch` object, based on whether the matches are chunked or just line-based.\n\n4. `limitChunkMatches`: This function is used to limit the number of chunk matches in a `FileMatch` object. It modifies the `ChunkMatches`, `SymbolInfo`, and `Content` fields to fit within the limit.\n\n5. `limitLineMatches`: This function is used to limit the number of line matches in a `FileMatch` object. It modifies the `LineFragments` field to fit within the limit.\n\nThe code in this file appears to be well-organized and well-documented, handling the complexities of limiting search results in a robust manner. The functions are relatively self-contained and follow good coding practices, such as using named return values and handling potential panics.\n\nOverall, the `limit.go` file seems to be a well-implemented part of the Zoekt codebase, providing functionality for managing the display of search results.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:35 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:34.107Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0d2e45f7412f1b4da34557365316157f
      _order: 0
      cache: {}
      request:
        bodySize: 10049
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-4c1642ac0ff46c5ab0bd7be6a5306834-dc2fb54f2811c43b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Why does this project use the MIT
                  license?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 22218
        content:
          mimeType: text/event-stream
          size: 22218
          text: >+
            event: completion

            data: {"completion":"The code provided does not contain any information about the license used for this project. The README.md file, which provides the codebase context, does not mention the license either. Without any explicit information about the license, I cannot determine why this project uses the MIT license. The choice of license is typically made by the project's maintainers and is not directly evident from the code itself.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:38 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:37.838Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 5638d53d1e33460f56534ac5e2f82e19
      _order: 0
      cache: {}
      request:
        bodySize: 10054
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cbf68ed5c2d530adffe67dedc48219f3-9f37dcabd8684012-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: See zoekt repo find location of tensor
                  function"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 49664
        content:
          mimeType: text/event-stream
          size: 49664
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, there is no mention of a \"tensor\" function. The code appears to be focused on a text search engine called \"Zoekt\" and does not contain any references to a tensor function. The code in the `limit.go` file is related to limiting the number of search results and truncating the match data to adhere to search options, but does not contain anything about a tensor function.\n\nWithout any additional information about where this \"tensor\" function is located, I do not have enough context to provide a specific answer. The codebase provided does not seem to contain the functionality you are looking for.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:40 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:39.560Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d9c4150ed4d1cc23a91852a83855a140
      _order: 0
      cache: {}
      request:
        bodySize: 10414
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-bdf6b045e8f7fa38a106d5e8f5629979-a99b477fd28ba162-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Explain the logic in src/agent.go,
                  particularly how agents interact with ranking"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 31456
        content:
          mimeType: text/event-stream
          size: 31456
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided codebase context does not contain enough information to explain the logic in the `agent.go` file and how agents interact with ranking. The codebase context only includes a single line, which states that the `Agent` is an agent. Without more context from the codebase, I do not have enough information to provide a meaningful explanation of the logic and the interaction with ranking. More detailed codebase context would be needed to analyze and explain the relevant functionality.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:43 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:42.119Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b0798c6fde67128eb9a6acfe4f3558e1
      _order: 0
      cache: {}
      request:
        bodySize: 5449
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-097b9fbf27ec9cb3e8725f8d58b9472e-9069bcbaffac5467-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: explain @README.md"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 546448
        content:
          mimeType: text/event-stream
          size: 546448
          text: >+
            event: completion

            data: {"completion":"Based on the contents of the provided README.md file, here is an explanation of the codebase:\n\n1. **Overview**:\n   - This is a fast text search engine, intended for use with source code.\n   - It is a fork of the original \"zoekt\" project hosted on GitHub at google/zoekt.\n   - The Sourcegraph version is now the main maintained source of Zoekt.\n\n2. **Installation and Usage**:\n   - The codebase provides instructions for downloading, indexing, and searching using Zoekt.\n   - It covers different methods for indexing, including directories, Git repositories, and Repo repositories.\n   - It also provides instructions for setting up the web interface, using the JSON API, and the command-line interface (CLI).\n   - There are instructions for setting up Zoekt as a service using a systemd unit file.\n\n3. **Search Service**:\n   - Zoekt comes with a service management program called zoekt-indexserver.\n   - This program can automatically mirror and index repositories from GitHub users, GitHub organizations, and Gitiles URLs.\n   - It handles the tasks of fetching new data and cleaning up log files.\n\n4. **Symbol Search**:\n   - The README recommends installing Universal ctags to improve the ranking of search results.\n\n5. **Acknowledgements**:\n   - The codebase acknowledges the original creator, Han-Wen Nienhuys, and the person who came up with the idea, Alexander Neubeck.\n\n6. **Fork Details**:\n   - This section explains the differences between this Sourcegraph fork and the original google/zoekt project.\n   - It mentions the addition of a Sourcegraph-specific indexing command, exposure of the API through a custom RPC library, and other minor changes.\n   - This section is marked as containing outdated information, as this Sourcegraph fork is now the main source for Zoekt.\n\n7. **Disclaimer**:\n   - The codebase includes a disclaimer that this is not an official Google product.\n\nIn summary, this is a fast text search engine for source code, forked from the original google/zoekt project and now maintained by Sourcegraph. It provides detailed instructions for installation, indexing, and searching, as well as additional features and service management capabilities.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:45 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:44.092Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: dad4f0d1add302ea4e0839578aa42f3c
      _order: 0
      cache: {}
      request:
        bodySize: 12320
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c9ae6948ae41971dc61cc543d21a1774-29f52d22bf328c17-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  Based on the contents of the provided README.md file, here is
                  an explanation of the codebase:


                  1. **Overview**:
                     - This is a fast text search engine, intended for use with source code.
                     - It is a fork of the original "zoekt" project hosted on GitHub at google/zoekt.
                     - The Sourcegraph version is now the main maintained source of Zoekt.

                  2. **Installation and Usage**:
                     - The codebase provides instructions for downloading, indexing, and searching using Zoekt.
                     - It covers different methods for indexing, including directories, Git repositories, and Repo repositories.
                     - It also provides instructions for setting up the web interface, using the JSON API, and the command-line interface (CLI).
                     - There are instructions for setting up Zoekt as a service using a systemd unit file.

                  3. **Search Service**:
                     - Zoekt comes with a service management program called zoekt-indexserver.
                     - This program can automatically mirror and index repositories from GitHub users, GitHub organizations, and Gitiles URLs.
                     - It handles the tasks of fetching new data and cleaning up log files.

                  4. **Symbol Search**:
                     - The README recommends installing Universal ctags to improve the ranking of search results.

                  5. **Acknowledgements**:
                     - The codebase acknowledges the original creator, Han-Wen Nienhuys, and the person who came up with the idea, Alexander Neubeck.

                  6. **Fork Details**:
                     - This section explains the differences between this Sourcegraph fork and the original google/zoekt project.
                     - It mentions the addition of a Sourcegraph-specific indexing command, exposure of the API through a custom RPC library, and other minor changes.
                     - This section is marked as containing outdated information, as this Sourcegraph fork is now the main source for Zoekt.

                  7. **Disclaimer**:
                     - The codebase includes a disclaimer that this is not an official Google product.

                  In summary, this is a fast text search engine for source code, forked from the original google/zoekt project and now maintained by Sourcegraph. It provides detailed instructions for installation, indexing, and searching, as well as additional features and service management capabilities.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: what does @limit.go do?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 435691
        content:
          mimeType: text/event-stream
          size: 435691
          text: >+
            event: completion

            data: {"completion":"Based on the code provided in the `limit.go` file, it appears to contain functionality for:\n\n1. **SortAndTruncateFiles**: This function takes a slice of `FileMatch` objects and a `SearchOptions` struct, and sorts the files and then truncates them based on the limits specified in the `SearchOptions`.\n\n2. **DisplayTruncator**: This is a stateful function that acts as a \"truncator\" for the search results. It enforces the document and match display limits specified in the `SearchOptions` by truncating and mutating the `FileMatch` slice before returning it. It keeps track of when the limits have been exhausted and returns `hasMore = false` once the limits are reached.\n\n3. **NewDisplayTruncator**: This function creates a new `DisplayTruncator` function that enforces the limits specified in the provided `SearchOptions`. If there are no limits to enforce, it returns a dummy `DisplayTruncator` that simply returns the input `FileMatch` slice.\n\n4. **limitMatches**: This function is used by the `DisplayTruncator` to limit the number of matches in each `FileMatch` object, either by limiting the number of `ChunkMatches` or `LineMatches`, depending on the `chunkMatches` flag.\n\n5. **limitChunkMatches**: This function is responsible for limiting the number of `ChunkMatches` in a `FileMatch` object. It truncates the `Ranges`, `SymbolInfo`, and `Content` fields of the `ChunkMatches` to fit within the specified limit.\n\n6. **limitLineMatches**: This function is responsible for limiting the number of `LineMatches` in a `FileMatch` object. It truncates the `LineFragments` field of the `LineMatches` to fit within the specified limit.\n\nIn summary, the `limit.go` file provides functionality for sorting, truncating, and limiting the display of search results based on the specified limits in the `SearchOptions` struct.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:50 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:49.713Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c2241a6e40f3888c099bb4262419e98c
      _order: 0
      cache: {}
      request:
        bodySize: 5415
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0c60afd3ac6bbed156924fed0ebdade8-357a875ce9c9973e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: style css checkbox using light purple"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 790376
        content:
          mimeType: text/event-stream
          size: 790376
          text: >+
            event: completion

            data: {"completion":"Unfortunately, I don't have enough context from the provided code snippets to provide a CSS style for a light purple checkbox. The provided code snippets appear to be written in Go and Markdown, and do not contain any CSS code.\n\nHowever, here's an example of how you can style a checkbox with a light purple color using CSS:\n\n```css\n/* Custom Checkbox Styles */\n/* Customize the label (the container) */\n.checkbox-container {\n  display: block;\n  position: relative;\n  padding-left: 35px;\n  margin-bottom: 12px;\n  cursor: pointer;\n  font-size: 16px;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n}\n\n/* Hide the browser's default checkbox */\n.checkbox-container input {\n  position: absolute;\n  opacity: 0;\n  cursor: pointer;\n  height: 0;\n  width: 0;\n}\n\n/* Create a custom checkbox */\n.checkmark {\n  position: absolute;\n  top: 0;\n  left: 0;\n  height: 25px;\n  width: 25px;\n  background-color: #eee;\n  border-radius: 4px;\n}\n\n/* On mouse-over, add a light purple background color */\n.checkbox-container:hover input ~ .checkmark {\n  background-color: #ccc;\n}\n\n/* When the checkbox is checked, add a light purple background */\n.checkbox-container input:checked ~ .checkmark {\n  background-color: #c8b3e7;\n}\n\n/* Create the checkmark/indicator (hidden when not checked) */\n.checkmark:after {\n  content: \"\";\n  position: absolute;\n  display: none;\n}\n\n/* Show the checkmark when checked */\n.checkbox-container input:checked ~ .checkmark:after {\n  display: block;\n}\n\n/* Style the checkmark/indicator */\n.checkbox-container .checkmark:after {\n  left: 9px;\n  top: 5px;\n  width: 5px;\n  height: 10px;\n  border: solid white;\n  border-width: 0 3px 3px 0;\n  -webkit-transform: rotate(45deg);\n  -ms-transform: rotate(45deg);\n  transform: rotate(45deg);\n}\n```\n\nThis CSS code creates a custom checkbox with a light purple color (`#c8b3e7`) when checked. You can adjust the colors and sizes to fit your design requirements.\n\nTo use this CSS, you'll need to add the appropriate HTML markup for the checkbox:\n\n```html\n\u003clabel class=\"checkbox-container\"\u003e\n  Checkbox Label\n  \u003cinput type=\"checkbox\"\u003e\n  \u003cspan class=\"checkmark\"\u003e\u003c/span\u003e\n\u003c/label\u003e\n```\n\nNote that this is just an example, and you may need to adjust the CSS and HTML to fit your specific use case and design requirements.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:26:51 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:26:50.250Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 94e9b5ee46c074e695401bba8c12ef0b
      _order: 0
      cache: {}
      request:
        bodySize: 5414
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-25af531937a000328513bf2e6c6699bd-c272f3af0318bb4e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: style css checkbox using light purple"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 660080
        content:
          mimeType: text/event-stream
          size: 660080
          text: >+
            event: completion

            data: {"completion":"To style a checkbox using a light purple color in CSS, you can use the following code:\n\n```css\n/* Checkbox container */\n.checkbox-container {\n  display: block;\n  position: relative;\n  padding-left: 30px;\n  cursor: pointer;\n  font-size: 16px;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n}\n\n/* Hide the default checkbox */\n.checkbox-container input {\n  position: absolute;\n  opacity: 0;\n  cursor: pointer;\n  height: 0;\n  width: 0;\n}\n\n/* Custom checkbox */\n.checkmark {\n  position: absolute;\n  top: 0;\n  left: 0;\n  height: 20px;\n  width: 20px;\n  background-color: #f1f1f1;\n  border-radius: 3px;\n}\n\n/* On mouse-over, add a light purple background color */\n.checkbox-container:hover input ~ .checkmark {\n  background-color: #e6d8ff;\n}\n\n/* When the checkbox is checked, add a light purple background */\n.checkbox-container input:checked ~ .checkmark {\n  background-color: #e6d8ff;\n}\n\n/* Create the checkmark/indicator (hidden when not checked) */\n.checkmark:after {\n  content: \"\";\n  position: absolute;\n  display: none;\n}\n\n/* Show the checkmark when checked */\n.checkbox-container input:checked ~ .checkmark:after {\n  display: block;\n}\n\n/* Style the checkmark/indicator */\n.checkbox-container .checkmark:after {\n  left: 6px;\n  top: 2px;\n  width: 5px;\n  height: 10px;\n  border: solid #8a78b8;\n  border-width: 0 3px 3px 0;\n  -webkit-transform: rotate(45deg);\n  -ms-transform: rotate(45deg);\n  transform: rotate(45deg);\n}\n```\n\nThis CSS code creates a custom checkbox with a light purple color for the background and the checkmark. The checkbox container is styled to match the default checkbox appearance, and the custom checkbox is created using a pseudo-element. When the checkbox is hovered over or checked, the background color changes to a light purple shade.\n\nYou can use this CSS code in your HTML by wrapping your checkboxes with the `.checkbox-container` class, like this:\n\n```html\n\u003clabel class=\"checkbox-container\"\u003e\n  \u003cinput type=\"checkbox\"\u003e\n  \u003cspan class=\"checkmark\"\u003e\u003c/span\u003e\n  Checkbox Label\n\u003c/label\u003e\n```\n\nThis will apply the custom styling to your checkboxes throughout your application.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:27:01 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:27:00.625Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8d35d338438edc8c185fbf75996a48bb
      _order: 0
      cache: {}
      request:
        bodySize: 5412
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ad0b2df35af3c007c86b4e7f1e52a119-f62f380cbec58538-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how to upgrade my  python version?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 363492
        content:
          mimeType: text/event-stream
          size: 363492
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code snippets do not contain any information about upgrading Python versions. These code snippets are written in Go programming language and appear to be related to various parts of a codebase such as handling files, directories, gRPC communication, and displaying search results.\n\nTo upgrade your Python version, the process typically involves the following steps:\n\n1. **Determine your current Python version**: Open your terminal or command prompt and run the following command to check your current Python version:\n\n```\npython --version\n```\n\n2. **Download the latest Python version**: Visit the official Python website (https://www.python.org/downloads/) and download the latest version of Python for your operating system.\n\n3. **Run the Python installer**: Once the download is complete, run the Python installer executable. During the installation process, you may have the option to add Python to your system's PATH environment variable. It is recommended to select this option to make running Python from the command line easier.\n\n4. **Verify the new Python version**: After the installation is complete, open a new terminal or command prompt window and run the following command to verify the new Python version:\n\n```\npython --version\n```\n\nNote that installing a new Python version does not typically replace or remove any existing Python installations on your system. The new version is installed alongside the existing ones.\n\nAlternatively, you can use version managers like `pyenv` (for Unix-based systems) or the Windows Subsystem for Linux (WSL) to install and manage multiple Python versions on your system.\n\nIf you encounter any issues or have specific requirements (e.g., installing Python for a particular project or virtual environment), it's best to consult the official Python documentation or seek assistance from the Python community forums.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:48:05 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:48:04.220Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 89ba40e451e688a28794a2aa162c915c
      _order: 0
      cache: {}
      request:
        bodySize: 5411
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-45a67cffa8122132ab726e8dad159b5c-1cd375c6db612704-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how to upgrade my  python version?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 298884
        content:
          mimeType: text/event-stream
          size: 298884
          text: >+
            event: completion

            data: {"completion":"The provided codebase context does not contain any information about upgrading Python versions. The files provided are written in Go and Markdown, and do not include any Python-related content. To upgrade your Python version, you would need to look for information specific to your operating system and the Python installation you currently have. Some general steps you could try:\n\n1. **Check your current Python version**: Open a terminal or command prompt and run `python --version` to see which version of Python you have installed.\n\n2. **Download the latest Python version**: Visit the official Python website (https://www.python.org/downloads/) and download the latest version of Python for your operating system.\n\n3. **Install the new Python version**: Follow the installation instructions provided on the Python website for your operating system. This may involve running an installer or using a package manager like `apt-get`, `yum`, or `brew`.\n\n4. **Set the new Python version as the default**: Depending on your operating system, you may need to update your system's PATH environment variable to make the new Python version the default. This can be done through the system settings or by editing configuration files.\n\n5. **Verify the new Python version**: After the installation, open a new terminal or command prompt and run `python --version` again to confirm that the new version of Python is now being used.\n\nThe specific steps may vary depending on your operating system and the way Python is installed on your machine. If you encounter any issues, you can search for guides or tutorials specific to your setup or reach out to the Python community for assistance.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:48:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:48:13.206Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 195b9854e8bc17bd73f443d242c0aa2b
      _order: 0
      cache: {}
      request:
        bodySize: 5401
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-53c531f36dfecdb91ae600496e2c6c32-87c89e9e74bc3f23-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how do goroutines work?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 377374
        content:
          mimeType: text/event-stream
          size: 377374
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code snippets do not contain any information about how goroutines work in Go. Goroutines are a fundamental concept in Go's concurrency model, which allows writing concurrent programs by explicitly creating lightweight threads of execution called goroutines.\n\nIn summary, goroutines work as follows:\n\n1. **Creation**: Goroutines are created by calling the `go` keyword followed by a function call. This creates a new goroutine that runs concurrently with the current goroutine.\n\n2. **Scheduling**: Go's runtime scheduler is responsible for efficiently scheduling and running goroutines on the available logical processors.\n\n3. **Communication**: Goroutines communicate by passing data through channels, which are typed message queues that allow safe communication and synchronization between goroutines.\n\n4. **Synchronization**: Go provides various synchronization primitives, such as channels, mutexes, and wait groups, to coordinate and synchronize the execution of goroutines.\n\n5. **Memory Model**: Go's memory model ensures that goroutines have access to consistent views of shared memory, preventing race conditions and other concurrency issues.\n\n6. **Multiplexing**: Go's runtime multiplexes goroutines onto a smaller set of operating system threads, allowing efficient utilization of system resources and enabling the creation of a large number of goroutines.\n\n7. **Garbage Collection**: Go's garbage collector automatically manages the memory used by goroutines, ensuring that unused memory is reclaimed.\n\nWhile the provided code snippets do not cover goroutines directly, some examples show the creation and usage of channels (`make(chan struct{})`) and the use of goroutines (`go func() { ... }()`). However, the details of how goroutines work internally are not covered in the given context.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 22:09:29 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T22:09:27.785Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 37da05ebfc09480fad70506cc67f97cf
      _order: 0
      cache: {}
      request:
        bodySize: 7350
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-3a694ea21015531c47f064db36152ec3-6dc7fe33179e7bac-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: >-
                  Unfortunately, the provided code snippets do not contain any
                  information about how goroutines work in Go. Goroutines are a
                  fundamental concept in Go's concurrency model, which allows
                  writing concurrent programs by explicitly creating lightweight
                  threads of execution called goroutines.


                  In summary, goroutines work as follows:


                  1. **Creation**: Goroutines are created by calling the `go` keyword followed by a function call. This creates a new goroutine that runs concurrently with the current goroutine.


                  2. **Scheduling**: Go's runtime scheduler is responsible for efficiently scheduling and running goroutines on the available logical processors.


                  3. **Communication**: Goroutines communicate by passing data through channels, which are typed message queues that allow safe communication and synchronization between goroutines.


                  4. **Synchronization**: Go provides various synchronization primitives, such as channels, mutexes, and wait groups, to coordinate and synchronize the execution of goroutines.


                  5. **Memory Model**: Go's memory model ensures that goroutines have access to consistent views of shared memory, preventing race conditions and other concurrency issues.


                  6. **Multiplexing**: Go's runtime multiplexes goroutines onto a smaller set of operating system threads, allowing efficient utilization of system resources and enabling the creation of a large number of goroutines.


                  7. **Garbage Collection**: Go's garbage collector automatically manages the memory used by goroutines, ensuring that unused memory is reclaimed.


                  While the provided code snippets do not cover goroutines directly, some examples show the creation and usage of channels (`make(chan struct{})`) and the use of goroutines (`go func() { ... }()`). However, the details of how goroutines work internally are not covered in the given context.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: explain how they relate to wait groups"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 179391
        content:
          mimeType: text/event-stream
          size: 179391
          text: >+
            event: completion

            data: {"completion":"Unfortunately, none of the provided code snippets mention or demonstrate the usage of wait groups in Go. Wait groups are a synchronization primitive in Go's standard library that allow you to wait for a collection of goroutines to finish their execution.\n\nThe code snippets cover various topics, such as:\n\n1. `agent.go`: Defines an `Agent` type, but no details are provided.\n2. `watcher.go`: Implements a `DirectoryWatcher` type that watches for file changes in a directory, but it does not use wait groups.\n3. `README.md`: Just a placeholder README file.\n4. `limit.go`: Contains a function `SortAndTruncateFiles` that sorts and truncates a slice of `FileMatch` values, but it does not involve goroutines or wait groups.\n5. `chunker_test.go`: A test file for a chunker implementation, but it does not use wait groups.\n\nWithout the presence of wait group usage or relevant goroutine management in the provided code snippets, I cannot provide an explanation of how they relate to wait groups. Wait groups are typically used when you have multiple goroutines running concurrently, and you need to wait for all of them to complete before proceeding with further operations or cleaning up resources.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 22:09:38 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T22:09:36.832Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a4a26da37155d00348b76663792a58a0
      _order: 0
      cache: {}
      request:
        bodySize: 5400
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8d52ffd420ab011b5874f9eb96f735dc-f8edd17ec55d2a9f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how do goroutines work?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 43891
        content:
          mimeType: text/event-stream
          size: 43891
          text: >+
            event: completion

            data: {"completion":"I do not have enough information about the provided codebase context to give a detailed explanation of how goroutines work. The code snippets provided do not contain any direct references to goroutines. Goroutines are a concept in the Go programming language that allow concurrent execution of functions. Without more context about the overall codebase and its implementation, I cannot provide a comprehensive explanation of how goroutines are used in this specific project. To answer your question, I would need more details about the codebase and the usage of concurrency primitives like goroutines.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 22:09:39 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T22:09:38.196Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0736f89069486c5f51e711c4205f3f35
      _order: 0
      cache: {}
      request:
        bodySize: 6103
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-9ad09347ae79a9ea33d42c0e16e62316-140534f67a18c072-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: I do not have enough information about the provided codebase context to
                  give a detailed explanation of how goroutines work. The code
                  snippets provided do not contain any direct references to
                  goroutines. Goroutines are a concept in the Go programming
                  language that allow concurrent execution of functions. Without
                  more context about the overall codebase and its
                  implementation, I cannot provide a comprehensive explanation
                  of how goroutines are used in this specific project. To answer
                  your question, I would need more details about the codebase
                  and the usage of concurrency primitives like goroutines.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: explain how they relate to wait groups"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 120168
        content:
          mimeType: text/event-stream
          size: 120168
          text: >+
            event: completion

            data: {"completion":"Apologies, but the provided codebase context does not contain any references to wait groups or their usage with goroutines. The code snippets include some code comments and function declarations, but do not demonstrate any concurrency primitives like wait groups.\n\nWithout seeing any actual usage of goroutines and wait groups within the codebase, I cannot provide a meaningful explanation of how they relate to each other. Wait groups are a synchronization primitive in Go that allow you to wait for a collection of goroutines to finish executing before continuing. However, there is no evidence of that in the limited code context given.\n\nTo explain how goroutines and wait groups work together, I would need to see code that actually utilizes both of these concepts. Without that, I do not have enough information to give a detailed explanation. Please provide additional context or examples from the codebase that demonstrate the usage of goroutines and wait groups, and I would be happy to explain how they relate to each other.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 22:09:40 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T22:09:39.973Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d4fd220f06a1cdda9d883210f9c79114
      _order: 0
      cache: {}
      request:
        bodySize: 5558
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-7aae67c2bc2bc574f08ce86c76642e75-94e02f14296571f2-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What code do you have access to?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 9768
        content:
          mimeType: text/event-stream
          size: 9768
          text: >+
            event: completion

            data: {"completion":"Based on the provided README.md file, I have access to the documentation and instructions for the Zoekt codebase, including details on downloading, indexing, searching, installation, search service, symbol search, acknowledgements, fork details, and disclaimer.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:55 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:54.099Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 438bb07d88a638fc89d19bcd4d8af8e3
      _order: 0
      cache: {}
      request:
        bodySize: 5497
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-190de9fc5cd99e7122aa38cedfca9b43-25f0d6fb7da7bf20-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how do slices work in go?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 155608
        content:
          mimeType: text/event-stream
          size: 155608
          text: >+
            event: completion

            data: {"completion":"In Go, a slice is a dynamically-sized, flexible view of elements in an array. Slices are like references to arrays, and they do not store any data themselves. Instead, they provide a way to work with a subset of elements in an underlying array.\n\nA slice in Go is represented by a three-word data structure: a pointer to the underlying array, the length of the slice, and the capacity of the slice (i.e., the maximum number of elements that the slice can hold without resizing the underlying array).\n\nSlices can be created using the `make` function or by slicing an existing array or slice using the `[low:high]` syntax. When slicing an array or a slice, a new slice is created that references a subset of the original elements.\n\nSlices in Go are not fixed-size like arrays and can grow or shrink dynamically using the `append` function. When appending to a slice, if the length of the slice reaches the capacity, a new underlying array with a larger capacity is allocated and the existing elements are copied over.\n\nIt's important to note that slices are references to arrays, so modifying the elements of a slice will also modify the corresponding elements in the underlying array.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:24:56 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:24:55.633Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 16e26357eb2d208eb2957b747019078c
      _order: 0
      cache: {}
      request:
        bodySize: 5512
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-5cd5f517e21eec1120209b3df380a663-9f61a8067ae31ee6-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Do not make
                  any assumptions. Question: what does this regex do? 

                  /a|e|i|o|u/
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 2134
        content:
          mimeType: text/event-stream
          size: 2134
          text: >+
            event: completion

            data: {"completion":"This regular expression matches any lowercase vowel (a, e, i, o, u).","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:00 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:00.023Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a813eca19d41199767f4b33c80704aae
      _order: 0
      cache: {}
      request:
        bodySize: 5018
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-76e65e0036756fd21b7514b7bda7a721-a06439851829fff6-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What does this repo do??"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 14036
        content:
          mimeType: text/event-stream
          size: 14036
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the repo appears to be related to a search functionality. It includes functions for sorting and truncating file matches based on search options, as well as enforcing display limits for documents and matches. The code includes functions for handling chunk matches and line matches within file matches.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:02 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:01.966Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 87ecb48ff64a2341c5b139f9e84bb9e9
      _order: 0
      cache: {}
      request:
        bodySize: 10306
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-77053b6cb0a5fe229157a8ad5c181afb-4c14a3cf5332d0f7-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: describe my code"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 124868
        content:
          mimeType: text/event-stream
          size: 124868
          text: >+
            event: completion

            data: {"completion":"The code provided in the `limit.go` file defines functions related to sorting and truncating files in the context of a search operation. \n\n1. The `SortAndTruncateFiles` function sorts and truncates a list of `FileMatch` objects based on search options.\n2. The `DisplayTruncator` type and `NewDisplayTruncator` function are used to enforce display limits on documents and matches in the search results.\n3. The `limitMatches` function limits the number of matches in a list of `FileMatch` objects based on a specified limit and whether to chunk or line matches.\n4. The `limitChunkMatches` function specifically limits the number of chunk matches in a `FileMatch` object. It truncates the content based on the difference in line numbers between the last and new last ranges if necessary.\n5. The `limitLineMatches` function limits the number of line matches in a `FileMatch` object by truncating line fragments if needed.\n\nOverall, this code focuses on handling search result display limits by sorting and truncating files efficiently.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:04 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:03.744Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a230b2d0b1d1ef98eb769e5b52ff54ef
      _order: 0
      cache: {}
      request:
        bodySize: 5496
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-6d988b6b0cf028ec68c3c4131da596f3-e41b25ea27539c40-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: @zoekt describe my code."
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 17276
        content:
          mimeType: text/event-stream
          size: 17276
          text: >+
            event: completion

            data: {"completion":"I'm sorry, but I cannot access external sources of information such as the Zoekt search tool to describe your code. If you provide specific details or questions about the codebase context you have shared, I can certainly help analyze and provide information based on that context. Let me know how else I can assist you with the codebase context you provided.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:11 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:10.346Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: bc2601d3c770a03276f9bc86f2f8f184
      _order: 0
      cache: {}
      request:
        bodySize: 5494
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-541b09b8a6a77b081c96f9dc0751b57a-4bf80f434e0ea2b5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: is my code base clean?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 13492
        content:
          mimeType: text/event-stream
          size: 13492
          text: >+
            event: completion

            data: {"completion":"Without further analysis, it is difficult to determine if your code base is clean. It would require a more in-depth review of the entire codebase to assess its cleanliness and identify any potential issues. If you would like, I can help you analyze specific sections or files to provide feedback on their cleanliness.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:12 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:11.995Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 11e869e5af67b24353a86cd4d2bbe516
      _order: 0
      cache: {}
      request:
        bodySize: 10460
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0d483a717906fc5cf443c700ae711046-56c941d74e63de12-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: What does directory watcher do?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 39523
        content:
          mimeType: text/event-stream
          size: 39523
          text: >+
            event: completion

            data: {"completion":"The `newDirectoryWatcher` function creates a new `DirectoryWatcher` instance that watches a specific directory for changes. It initializes the directory watcher with the given directory path, a shard loader, and sets up channels for signaling readiness, quitting, and stopping. The function then starts a goroutine to scan the directory and watch for changes. If any errors occur during scanning or watching, the `readyErr` field in the `DirectoryWatcher` instance is set to the error. The function returns the created `DirectoryWatcher` instance and any potential error.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:13.636Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9d5dda6ba212ff30630a1ad874be11e5
      _order: 0
      cache: {}
      request:
        bodySize: 10462
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-bf5366ae82ec7d3ed14ccdd998818396-3fd1efa7142f3f93-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: where do we test the grpc chunker"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 7076
        content:
          mimeType: text/event-stream
          size: 7076
          text: >+
            event: completion

            data: {"completion":"The grpc chunker is tested in the `chunker_test.go` file under the `grpc/chunk` package. The specific test function that tests the chunker end-to-end is `TestChunkerE2E`.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:16 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:16.012Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 5b7632be27b60a2237fd018a521b7035
      _order: 0
      cache: {}
      request:
        bodySize: 10196
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ad4c345561693c3fa09b20d927c565cc-5485b5b191305c45-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Are you capable of upgrading my pytorch
                  version to 1.0.0, there is a guide in the pytorch site"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 27159
        content:
          mimeType: text/event-stream
          size: 27159
          text: >+
            event: completion

            data: {"completion":"I'm sorry, but as an AI coding assistant, my current capabilities are limited to assisting with coding-related tasks and providing guidance on software development. I am not capable of directly upgrading your PyTorch version. However, I can help you understand the upgrade process and provide guidance on how to upgrade PyTorch to version 1.0.0 based on the guide from the PyTorch website. Let me know if you need assistance with that.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:18 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:17.370Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c6e8d0b49aae726e5eedc9ab42ea0394
      _order: 0
      cache: {}
      request:
        bodySize: 10196
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ee52991b85e893aaee7cc10b86557fdb-afbf4158341e1951-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Can you look through the files and
                  identify the conflicting packages that may be causing this?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 9274
        content:
          mimeType: text/event-stream
          size: 9274
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, there does not appear to be any conflicting packages mentioned in the `limit.go` file. The `limit.go` file contains functions related to sorting and truncating files in the `zoekt` package.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:20 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:19.563Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 21fb828cb865bf1b31e5e2e5fd1678c5
      _order: 0
      cache: {}
      request:
        bodySize: 10338
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a48434cf816a38a4d1c405e805ebe8aa-6a925ff62796c65e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Mind taking a second look at the file?
                  @limit.go"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 3661
        content:
          mimeType: text/event-stream
          size: 3661
          text: >+
            event: completion

            data: {"completion":"Absolutely! Let me take another look at the file and provide more detailed information based on the codebase context. Just a moment.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:21.113Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 42445d1dd4cc270cb7cd1d274d6b9323
      _order: 0
      cache: {}
      request:
        bodySize: 10144
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-908c0c9da4e2aab542ffdced0975e3de-6644bec8b859cb38-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Why does this project use the MIT
                  license?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 11962
        content:
          mimeType: text/event-stream
          size: 11962
          text: >+
            event: completion

            data: {"completion":"The project likely uses the MIT license for its codebase as it is a permissive open-source license that allows users to freely use, modify, and distribute the software with relatively few restrictions. The MIT license is widely used in the open-source community due to its simplicity and flexibility.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:22 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:22.056Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f58dd5e7f2d594a9862de3eb9b97a5f7
      _order: 0
      cache: {}
      request:
        bodySize: 10149
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-09a503c28cec3f43b3f5a86d509d2edf-aaf3e7bb6fd389a5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: See zoekt repo find location of tensor
                  function"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 42233
        content:
          mimeType: text/event-stream
          size: 42233
          text: >+
            event: completion

            data: {"completion":"To find the location of the \"tensor\" function in the `zoekt` repository, you can search for it within the codebase. Here are the steps you can take:\n\n1. Use the search functionality provided by the `zoekt` tool to search for the \"tensor\" function within the repository codebase.\n2. You can search for occurrences of \"tensor\" using commands such as:\n   ```bash\n   $GOPATH/bin/zoekt 'tensor'\n   ```\n3. The search results should display the file locations where the \"tensor\" function is defined or used within the `zoekt` repository.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:24 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:23.617Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 38ca2a544be90fd54a4f8a2fd8edc4ba
      _order: 0
      cache: {}
      request:
        bodySize: 10509
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-7ef6484ae08d5231a5593c76c1487f09-80dd5757af3924db-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: Explain the logic in src/agent.go,
                  particularly how agents interact with ranking"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 5145
        content:
          mimeType: text/event-stream
          size: 5145
          text: >+
            event: completion

            data: {"completion":"I'm sorry, but the codebase context from file vscode/src/agent.go was not provided. Could you please provide the specific code snippet you would like me to explain?","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:27 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:26.252Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d1a2278fd8ed130c6590d285c8bc7331
      _order: 0
      cache: {}
      request:
        bodySize: 5544
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e7868e62f870ff2c52ea6c9a7fb813aa-58db90ec301b7e82-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: explain @README.md"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 75479
        content:
          mimeType: text/event-stream
          size: 75479
          text: >+
            event: completion

            data: {"completion":"The README.md file provides information about the Zoekt text search engine, a tool designed for fast text search in source code. It includes instructions on how to download, index, and search using Zoekt. The file also contains details on installation, search services, symbol search, acknowledgements, fork details, and a disclaimer. It explains how to use Zoekt for various tasks, such as indexing directories, Git repositories, and Repo repositories, as well as searching through the web interface, JSON API, and CLI. Additionally, it mentions the usage of systemd unit files for installation on a Linux server and the benefits of installing Universal ctags for improved ranking. The README also includes acknowledgements to the creators of Zoekt and explains the differences between the Sourcegraph fork and the original Google version.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:28 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:27.393Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 4af43bf2b0f74de78f8eab67d56c2d7c
      _order: 0
      cache: {}
      request:
        bodySize: 11047
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-785dfc844cd8b42c755cda83680db4a3-3962cb65b1f11d70-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: The README.md file provides information about the Zoekt text search
                  engine, a tool designed for fast text search in source code.
                  It includes instructions on how to download, index, and search
                  using Zoekt. The file also contains details on installation,
                  search services, symbol search, acknowledgements, fork
                  details, and a disclaimer. It explains how to use Zoekt for
                  various tasks, such as indexing directories, Git repositories,
                  and Repo repositories, as well as searching through the web
                  interface, JSON API, and CLI. Additionally, it mentions the
                  usage of systemd unit files for installation on a Linux server
                  and the benefits of installing Universal ctags for improved
                  ranking. The README also includes acknowledgements to the
                  creators of Zoekt and explains the differences between the
                  Sourcegraph fork and the original Google version.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: what does @limit.go do?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 75327
        content:
          mimeType: text/event-stream
          size: 75327
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file in the codebase defines functions related to sorting and truncating FileMatch objects in the context of the Zoekt text search engine. Specifically, the `SortAndTruncateFiles` function sorts a slice of FileMatch objects and then truncates it based on search options. The `DisplayTruncator` type and related functions enforce display limits for Document and Match objects by truncating and mutating them. The `NewDisplayTruncator` function generates a DisplayTruncator based on search options and limits. It takes care of limiting the number of ChunkMatches or LineMatches in a FileMatch object based on the specified limits. Overall, the `limit.go` file provides functionality for sorting and truncating search results to adhere to defined display limits in the Zoekt text search engine.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:25:31 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:25:30.481Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a4be87ac4f9918ea1a997fcc3e5bd33b
      _order: 0
      cache: {}
      request:
        bodySize: 5509
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-042f3dea078b7e8b3ff93878fae17d85-3a3218454e7e249b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: style css checkbox using light purple"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 46101
        content:
          mimeType: text/event-stream
          size: 46101
          text: >+
            event: completion

            data: {"completion":"To style a checkbox using light purple in CSS, you can use the following code snippet:\n\n```css\n.checkbox {\n  appearance: none;\n  -webkit-appearance: none;\n  -moz-appearance: none;\n  width: 20px;\n  height: 20px;\n  border: 2px solid #8C70FF; /* light purple color */\n  border-radius: 3px;\n  outline: none;\n  cursor: pointer;\n}\n\n.checkbox:checked {\n  background-color: #8C70FF; /* light purple color */\n}\n```\n\nThis CSS code styles a checkbox element with light purple border color and changes the background color to light purple when checked.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:27:06 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:27:05.481Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c9d85977133c930af259763e2edaa79d
      _order: 0
      cache: {}
      request:
        bodySize: 5506
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-31055b27210ca18b47bddcaf0f571ed3-4a5be4a9aa0e7284-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how to upgrade my  python version?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 180752
        content:
          mimeType: text/event-stream
          size: 180752
          text: >+
            event: completion

            data: {"completion":"To upgrade your Python version, you can follow these steps:\n\n1. Check your current Python version by running the following command in your terminal:\n```bash\npython --version\n```\n\n2. Determine the Python version you want to upgrade to. Let's assume you want to upgrade to Python 3.9.\n\n3. Depending on your operating system, you can use package managers like `pip`, `brew`, or `apt` to upgrade Python. Here are some common ways to upgrade Python:\n\n   - If you are using `pip`, you can upgrade Python by running:\n   ```bash\n   pip install --upgrade python\n   ```\n\n   - If you are using Homebrew on macOS, you can upgrade Python using:\n   ```bash\n   brew upgrade python\n   ```\n\n   - If you are using APT on Ubuntu or Debian, you can upgrade Python using:\n   ```bash\n   sudo apt update\n   sudo apt upgrade python3\n   ```\n\n4. Once the upgrade process is complete, you can verify the new Python version by running:\n```bash\npython --version\n```\n\n5. After upgrading Python, make sure to update any dependencies or virtual environments that rely on the Python version to ensure compatibility. \n\nRemember to back up any important files or projects before upgrading Python to prevent data loss or compatibility issues.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 21:48:17 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T21:48:16.743Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b1ecdcf76c237d1b8f278a00f481f73d
      _order: 0
      cache: {}
      request:
        bodySize: 5495
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b7d2e4aad077889c03c6dac80eaf6fba-b8c842c31488f5a0-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: how do goroutines work?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 98053
        content:
          mimeType: text/event-stream
          size: 98053
          text: >+
            event: completion

            data: {"completion":"Goroutines in Go are lightweight threads managed by the Go runtime. When a Go program is started, it creates a single Goroutine called the \"main Goroutine\". Additional Goroutines can be created using the `go` keyword followed by a function call. These Goroutines can run concurrently and independently of each other within the same address space.\n\nGoroutines are multiplexed onto multiple OS threads by the Go runtime, allowing for efficient use of multiple cores. They communicate with each other using channels, which are provided as a built-in feature in Go for safe communication between Goroutines. Goroutines are used extensively in Go to handle concurrent tasks, such as concurrent I/O operations, parallel processing, and more.\n\nIt's important to note that the Go runtime manages Goroutine scheduling and execution, which abstracts away many low-level details of thread management, making it easier for developers to work with concurrency in Go.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 22:09:44 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T22:09:43.250Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2cb4210c818fe01ce38720d825082755
      _order: 0
      cache: {}
      request:
        bodySize: 6556
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1fc4e3f4a769f41d12b367541344494d-677b11961dadc412-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: >-
                  Goroutines in Go are lightweight threads managed by the Go
                  runtime. When a Go program is started, it creates a single
                  Goroutine called the "main Goroutine". Additional Goroutines
                  can be created using the `go` keyword followed by a function
                  call. These Goroutines can run concurrently and independently
                  of each other within the same address space.


                  Goroutines are multiplexed onto multiple OS threads by the Go runtime, allowing for efficient use of multiple cores. They communicate with each other using channels, which are provided as a built-in feature in Go for safe communication between Goroutines. Goroutines are used extensively in Go to handle concurrent tasks, such as concurrent I/O operations, parallel processing, and more.


                  It's important to note that the Go runtime manages Goroutine scheduling and execution, which abstracts away many low-level details of thread management, making it easier for developers to work with concurrency in Go.
              - speaker: human
                text: "You have access to the provided codebase context. Do not make any
                  assumptions. Question: explain how they relate to wait groups"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 197635
        content:
          mimeType: text/event-stream
          size: 197635
          text: >+
            event: completion

            data: {"completion":"The provided codebase context includes tests for chunking functionality in a gRPC server implementation. In the tests, the `TestChunkerE2E` function tests the chunking behavior of the server by sending a request with a specific payload size and then receiving the response in chunks.\n\nWaitGroups are typically used in Go programs to wait for a collection of Goroutines to finish executing before proceeding. They are synchronized mechanisms that allow the main Goroutine to wait for a set of Goroutines to complete their tasks.\n\nIn the context of the provided code snippets, if we were to introduce WaitGroups to the tests, we could use them to wait for the completion of multiple Goroutines that handle the chunking and processing of responses in parallel. For example, we could create a WaitGroup at the beginning of the test, add the number of Goroutines we expect to wait for to the WaitGroup, and then have each Goroutine call `Done()` on the WaitGroup when it completes its task. Finally, we can call `Wait()` on the WaitGroup to block until all Goroutines have completed.\n\nBy using WaitGroups in this manner, we can ensure that the test waits for the completion of all concurrent operations before making assertions or proceeding to the next step, providing a way to synchronize the parallel execution of tasks in the test environment.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Fri, 14 Jun 2024 22:09:49 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-14T22:09:48.540Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 12581f1c735a04aeb88af7a54cd007b2
      _order: 0
      cache: {}
      request:
        bodySize: 217
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "217"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 340
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CodyConfigFeaturesResponse {
                  site {
                      codyConfigFeatures {
                          chat
                          autoComplete
                          commands
                          attribution
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CodyConfigFeaturesResponse
            value: null
        url: https://sourcegraph.com/.api/graphql?CodyConfigFeaturesResponse
      response:
        bodySize: 162
        content:
          encoding: base64
          mimeType: application/json
          size: 162
          text: "[\"H4sIAAAAAAAAAzyLwQqA\",\"IBAF/2XPfYFXof/YdC0h3dDnIcR/Dws6DQwznTyDyXSq\
            ETLp1N9Wc4j7KoxWpL72YJBBabIQN6jVdJ0yj885TYmzr38DlLg1RM1kAp9VxhjjAQA\
            A//8=\",\"AwCHzi5CbgAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.351Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 09b59ac55ce3c40d6f9ab8c79846a2c6
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 244
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query ContextFilters {
                  site {
                      codyContextFilters(version: V1) {
                          raw
                      }
                  }
              }
            variables: {}
        queryString:
          - name: ContextFilters
            value: null
        url: https://sourcegraph.com/.api/graphql?ContextFilters
      response:
        bodySize: 114
        content:
          encoding: base64
          mimeType: application/json
          size: 114
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdHJ+SmVzvl5JakVJW6ZOSWpRcUg0aLE\
            ciWrvNKcnNra2loAAAAA//8=\",\"AwA2LshlNQAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.823Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9d0e130a38eaf9d3cd8d9512afc14b87
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 328
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query ContextFilters {
                  site {
                      codyContextFilters(version: V1) {
                          raw
                      }
                  }
              }
            variables: {}
        queryString:
          - name: ContextFilters
            value: null
        url: https://sourcegraph.com/.api/graphql?ContextFilters
      response:
        bodySize: 104
        content:
          encoding: base64
          mimeType: application/json
          size: 104
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdHJ+SmVzvl5JakVJW6ZOSWpRcUg0aLEciWrv\
            NKcnNra2loAAAAA//8DADYuyGU1AAAA\"]"
          textDecoded:
            data:
              site:
                codyContextFilters:
                  raw: null
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.439Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 460fa85fef77ffa15bb82fa3a88049a3
      _order: 0
      cache: {}
      request:
        bodySize: 318
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "318"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 345
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmConfiguration {
                  site {
                      codyLLMConfiguration {
                          chatModel
                          chatModelMaxTokens
                          fastChatModel
                          fastChatModelMaxTokens
                          completionModel
                          completionModelMaxTokens
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmConfiguration
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmConfiguration
      response:
        bodySize: 251
        content:
          encoding: base64
          mimeType: application/json
          size: 251
          text: "[\"H4sIAAAAAAAAA3zOwQqC\",\"QBAG4HeZs+K0BqFXr3rrBYbdMRdtJ3ZXKmTfPSyiSOg0\
            8PP/H7OAoUhQLxBs5PVqMfe27RpxvT3NnqIV98wHip0YnqAGcnHwcrG60BPNhvMyD+I\
            cx1yh2qNSFWSfQUe3o4zsAtQ7hYgZ9BRi898byI7ziyvxAD+bLanlfJl4ffaN9tbzVf\
            wYihDJazHsYdP7gipETCmlBwAAAP//AwBQeP+1EwEAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.931Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7edf90ea650cb304fe26f9d57bd79477
      _order: 0
      cache: {}
      request:
        bodySize: 165
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "165"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 345
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmConfiguration {
                  site {
                      codyLLMConfiguration {
                          smartContextWindow
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmConfiguration
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmConfiguration
      response:
        bodySize: 135
        content:
          encoding: base64
          mimeType: application/json
          size: 135
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdHJ+SmVPj6+zvl5aZnppUWJJZn5eWD5\
            3MSiEuf8vJLUipLwzLyU/HIlK6XUvMSknNQUpdra2loAAAAA//8DAOgINKVLAAAA\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.955Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d890a82b3cc2fe4d514f289e8fe6d158
      _order: 0
      cache: {}
      request:
        bodySize: 150
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "150"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 340
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmProvider {
                  site {
                      codyLLMConfiguration {
                          provider
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmProvider
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmProvider
      response:
        bodySize: 134
        content:
          encoding: base64
          mimeType: application/json
          size: 134
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdHJ+SmVPj6+zvl5aZnppUWJJZn5eSDx\
            gqL8ssyU1CIlK6Xi/NKi5NT0osSCDKXa2tpaAAAAAP//\",\"AwAfFAXARQAAAA==\"\
            ]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.932Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 3fec40886d87367e761715c3159e6590
      _order: 0
      cache: {}
      request:
        bodySize: 341
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "341"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 325
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentUser {
                  currentUser {
                      id
                      hasVerifiedEmail
                      displayName
                      username
                      avatarURL
                      primaryEmail {
                          email
                      }
                      organizations {
                          nodes {
                              id
                              name
                          }
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentUser
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentUser
      response:
        bodySize: 376
        content:
          encoding: base64
          mimeType: application/json
          size: 376
          text: "[\"H4sIAAAAAAAAA2RPy07CQBT9l7tuaQ1R2klIFAQXaOMjNBjj4nZ6aaePmToPFJr+O2kwc\
            eHunJzHvaeHHC0C64E7rUnarSE9UpEDg3SXNLxSp+T+5eqp4nPwoESTkhZ7QfmqRdEA\
            s9qRB7kwXYPHBFsCBm/KaU6Fxq5cKOvHYRiCB86QlheD+TNkysa1v5ffrQMP8IAW9fb\
            1ERiU1naGBUFTTieFUkVDYwNX0pK0E67aAIO7ZREpvlnjV/ZOblFn1XW+Xp1+omyXRj\
            gTU5Nmm2XynM4eQnc81HMT3/gcPOi0aFEff0f0QBfw77PbYhTGazB4oHSBUpzQCiXNG\
            JMqJwPs43MYhuEMAAD//wMASoyTP04BAAA=\"]"
          textDecoded:
            data:
              currentUser:
                avatarURL: https://lh3.googleusercontent.com/a/ACg8ocKFaqbYeuBkbj5dFEzx8bXV8a7i3sVbKCNPV7G0uyvk=s96-c
                displayName: SourcegraphBot-9000
                hasVerifiedEmail: true
                id: VXNlcjozNDQ1Mjc=
                organizations:
                  nodes: []
                primaryEmail:
                  email: sourcegraphbot9k@gmail.com
                username: sourcegraphbot9k-fnwmu
        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 06:04:24 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T06:04:24.268Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 84b962509b12000d0eef7c8a8fa655f3
      _order: 0
      cache: {}
      request:
        bodySize: 268
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "268"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 341
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentUserCodySubscription {
                  currentUser {
                      codySubscription {
                          status
                          plan
                          applyProRateLimits
                          currentPeriodStartAt
                          currentPeriodEndAt
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentUserCodySubscription
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentUserCodySubscription
      response:
        bodySize: 231
        content:
          encoding: base64
          mimeType: application/json
          size: 231
          text: "[\"H4sIAAAAAAAAA1zMsQrC\",\"MBSF4Xc5c4U2VodsRToIgqWtDm6xyRCoSbi5GUrJu4uC\
            oI7n5+Os0IoV5IopERnHl2joPb1ehnSPE9nA1rtXi6w4RUg0h/F4bVEgzMpBouvPKKB\
            CmJeOfK/YnOzDcoRkSqb4fHeGrNcDK+KGISFKUW/K3aaqRyFkVcmtuOFPt05/2f2vzT\
            nnJwAAAP//AwBSFe7+wgAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.116Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ea3ddfc16f0b52a2180a9bd21c87dc08
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 240
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query Repository($name: String!) {
              	repository(name: $name) {
              		id
              	}
              }
            variables:
              name: github.com/sourcegraph/cody
        queryString:
          - name: Repository
            value: null
        url: https://sourcegraph.com/.api/graphql?Repository
      response:
        bodySize: 123
        content:
          encoding: base64
          mimeType: application/json
          size: 123
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqSi3IL84syS+qBPEyU5SslEJzw8qTjP0KUtwt\
            K1ND8o18Q3wr/UJ8K/0dbW2VamtrAQAAAP//AwDHAhygPQAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.592Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8d297306aeea324b87ef494954016fba
      _order: 0
      cache: {}
      request:
        bodySize: 164
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "164"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 248
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteIdentification {
              	site {
              		siteID
              		productSubscription {
              			license {
              				hashedKey
              			}
              		}
              	}
              }
            variables: {}
        queryString:
          - name: SiteIdentification
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteIdentification
      response:
        bodySize: 212
        content:
          encoding: base64
          mimeType: application/json
          size: 212
          text: "[\"H4sIAAAAAAAAAzTLsQ6CMBCA4Xe52YX2rgVmF+PI4HztXaWJAdKWwRDf3WDiv/zTd4BwY\
            xgPqLnp/7crjDCte4n6LLzNDw1wga2sssc27aHGkreW1+UErxx1qT87c51V7vqGEYbo\
            u9AZm/okmgxi70QZlZzzqNEaJOMNReocCdkgiCk4j4btwJwIPmdfAAAA//8DABj2u36\
            gAAAA\"]"
          textDecoded:
            data:
              site:
                productSubscription:
                  license:
                    hashedKey: 9c71b123f8fdef24486dea4e56674ec32452725c5165d53bd44fb6742a39aaf5
                siteID: SourcegraphWeb
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.555Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b584bf96a3d88ab96114e5cbea1e4bca
      _order: 0
      cache: {}
      request:
        bodySize: 164
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "164"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 332
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteIdentification {
              	site {
              		siteID
              		productSubscription {
              			license {
              				hashedKey
              			}
              		}
              	}
              }
            variables: {}
        queryString:
          - name: SiteIdentification
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteIdentification
      response:
        bodySize: 212
        content:
          encoding: base64
          mimeType: application/json
          size: 212
          text: "[\"H4sIAAAAAAAAAzTLsQ6CMBCA4Xe52YX2rgVmF+PI4HztXaWJAdKWwRDf3WDiv/zTd4BwY\
            xgPqLnp/7crjDCte4n6LLzNDw1wga2sssc27aHGkreW1+UErxx1qT87c51V7vqGEYbo\
            u9AZm/okmgxi70QZlZzzqNEaJOMNReocCdkgiCk4j4btwJwIPmdfAAAA//8DABj2u36\
            gAAAA\"]"
          textDecoded:
            data:
              site:
                productSubscription:
                  license:
                    hashedKey: 9c71b123f8fdef24486dea4e56674ec32452725c5165d53bd44fb6742a39aaf5
                siteID: SourcegraphWeb
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.350Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 203c1896021c3a09dfe619120ea1b725
      _order: 0
      cache: {}
      request:
        bodySize: 101
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "101"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 248
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteProductVersion {
                  site {
                      productVersion
                  }
              }
            variables: {}
        queryString:
          - name: SiteProductVersion
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteProductVersion
      response:
        bodySize: 139
        content:
          encoding: base64
          mimeType: application/json
          size: 139
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdEFRfkppcklYalFxZn5eUpWSkbm5pbm\
            BvFGBkYmugZmuoaG8aZ6JrqJRobJZimWpolGSQZKtbW1AAAAAP//AwCfPZebSQAAAA==\
            \"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.736Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2aa42833ae189b030c5bc322f1d27b0c
      _order: 0
      cache: {}
      request:
        bodySize: 101
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "101"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 332
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteProductVersion {
                  site {
                      productVersion
                  }
              }
            variables: {}
        queryString:
          - name: SiteProductVersion
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteProductVersion
      response:
        bodySize: 139
        content:
          encoding: base64
          mimeType: application/json
          size: 139
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdEFRfkppcklYalFxZn5eUpWSkbm5pbm\
            BvFGBkYmugZmuoaG8aZ6JrqJRobJZimWpolGSQZKtbW1AAAAAP//AwCfPZebSQAAAA==\
            \"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.929Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
  pages: []
  version: "1.2"
