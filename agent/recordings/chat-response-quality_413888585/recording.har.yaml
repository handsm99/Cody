log:
  _recordingName: chat-response-quality
  creator:
    comment: persister:fs
    name: Polly.JS
    version: 6.0.6
  entries:
    - _id: daf2b9e4348e47eba6764b64a5c4db5a
      _order: 0
      cache: {}
      request:
        bodySize: 5529
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-09bb07f6607b1914b94ef7a1a0e7d8f3-adccd99f570d640f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What code do you have access to?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 125642
        content:
          mimeType: text/event-stream
          size: 125642
          text: >+
            event: completion

            data: {"completion":"Based on the provided context, the codebase I have access to is the Zoekt source code repository, which is a fast text search engine intended for use with source code. The context includes information about downloading, indexing, searching, and installing Zoekt, as well as details about a fork of Zoekt maintained by Sourcegraph with some additional features and modifications.\n\nSpecifically, the context mentions that I have access to the following code:\n\n- The main Zoekt source code repository: https://github.com/sourcegraph/zoekt\n- Command line tools like `zoekt-index`, `zoekt-git-index`, `zoekt-repo-index`, `zoekt-mirror-gitiles`, `zoekt-webserver`, `zoekt`, and `zoekt-indexserver`\n- A Sourcegraph-specific command `zoekt-sourcegraph-indexserver` for indexing Sourcegraph repositories\n\nThe context does not provide the actual source code files, but it gives an overview of the main components and commands available in the Zoekt codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:50 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.514Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 35111eff1586dc3a34b7bb6562e1449e
      _order: 0
      cache: {}
      request:
        bodySize: 4989
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-30e87f505807e55a3599faba2009629b-e12cc7565a0f2d01-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What does this repo do??"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 155934
        content:
          mimeType: text/event-stream
          size: 155934
          text: >+
            event: completion

            data: {"completion":"Based on the provided code, it seems that this is part of a project called \"zoekt\". The code appears to be handling search result truncation and limiting for file matches.\n\nThe main functionality appears to be:\n\n1. `SortAndTruncateFiles` sorts the list of `FileMatch` objects and then truncates them based on the specified `SearchOptions`.\n\n2. `NewDisplayTruncator` creates a `DisplayTruncator` function that enforces limits on the maximum number of documents (files) and matches to display, based on the provided `SearchOptions`.\n\n3. `limitMatches` applies limits on either \"ChunkMatches\" or \"LineMatches\" within each `FileMatch` object, depending on the `chunkMatches` flag in `SearchOptions`.\n\n4. `limitChunkMatches` and `limitLineMatches` are helper functions that handle truncating the `ChunkMatches` and `LineMatches` respectively, based on the specified limit.\n\nHowever, without additional context, it's difficult to determine the exact purpose or functionality of this project. It seems to be related to searching and handling search results, but the specific use case or application is unclear.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:55 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:54.191Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ec0237b7fb306bf6990795b7365423d5
      _order: 0
      cache: {}
      request:
        bodySize: 32255
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-188682af9e37f10dca149a99c2bce32d-b18a7db6197dc70d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: describe my code"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 322881
        content:
          mimeType: text/event-stream
          size: 322881
          text: >+
            event: completion

            data: {"completion":"The provided code is part of the Zoekt project, which is a fast text search engine intended for searching source code. The code is written in Go and consists of several packages and files.\n\nHere's a breakdown of the files you provided:\n\n1. **eval.go**: This file contains functions related to evaluating search queries and performing searches on the indexed data. It includes functions for simplifying queries, setting default search options, executing searches, gathering matches, and handling various types of queries (e.g., repository queries, language queries, regular expression queries).\n\n2. **limit.go**: This file contains functions for limiting and truncating search results based on various options, such as the maximum number of displayed documents, matches, or context lines. It includes functions like `SortAndTruncateFiles`, `NewDisplayTruncator`, `limitChunkMatches`, and `limitLineMatches`.\n\n3. **vscode/src/external-services.ts**: This file appears to be part of a Visual Studio Code extension and contains TypeScript code related to external services.\n\n4. **README.md**: This is the project's README file, providing an overview of Zoekt, instructions for downloading, indexing, and searching, as well as information about installation, symbol search, and acknowledgments.\n\nThe code you provided covers different aspects of the Zoekt project, including search evaluation, result limiting, and user-facing components (like the Visual Studio Code extension and documentation).\n\nHowever, without more context, it's difficult to provide a detailed description of the code's purpose and functionality. If you have specific questions or need further clarification on any part of the code, please let me know.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:05 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:00.904Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 3643f0ea9f29089218cf330e260b278d
      _order: 0
      cache: {}
      request:
        bodySize: 5467
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-9472515d24d13d7a30139f019be0c71e-2017e6f11f8fa763-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: @zoekt describe my code."
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 346237
        content:
          mimeType: text/event-stream
          size: 346237
          text: >+
            event: completion

            data: {"completion":"From the code snippets provided, it seems like the codebase is related to some sort of code watching/monitoring system. Here's a brief description of what I can infer from each file:\n\n1. `agent.go`: This file defines an `Agent` struct, but there is no additional context provided about its purpose.\n\n2. `watcher.go`: This file defines a `DirectoryWatcher` struct and a `newDirectoryWatcher` function. The `DirectoryWatcher` appears to be responsible for watching a directory for file changes. It has fields like `dir`, `timestamps`, `loader`, and channels for managing the watcher's lifecycle (`ready`, `quit`, `stopped`). The `newDirectoryWatcher` function initializes a new `DirectoryWatcher` instance and starts a goroutine to scan the directory and start watching it.\n\n3. `README.md`: This is a typical readme file, but no additional context is provided.\n\n4. `limit.go`: This file contains a `SortAndTruncateFiles` function that sorts and truncates a slice of `FileMatch` structs based on some `SearchOptions`. It's not clear what these structs represent or what the purpose of this function is.\n\n5. `chunker_test.go`: This file contains a test for a `Chunker` implementation, specifically testing the end-to-end behavior of the `StreamingOutputCall` method. It appears to be testing the chunking of large payloads into smaller messages, possibly for streaming data over gRPC.\n\nWithout more context about the overall purpose of the codebase and how these components fit together, it's difficult to provide a more detailed description. If you have additional information or context about the codebase, please provide it, and I'll try to give a more accurate description.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:11 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:09.889Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8f940b4207fd413aa5784489de1409ce
      _order: 0
      cache: {}
      request:
        bodySize: 5465
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a4465971754ba6cb6a981577d49e3396-deea2161d90205b5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: is my code base clean?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 204081
        content:
          mimeType: text/event-stream
          size: 204081
          text: >+
            event: completion

            data: {"completion":"Based on the snippets provided, I don't have enough context to determine if the entire codebase is clean or not. The provided snippets are relatively small and isolated pieces of code. To assess the cleanliness of the codebase, I would need to see more of the codebase structure, coding conventions, naming conventions, code organization, and general code quality principles being followed.\n\nSome observations based on the provided snippets:\n\n1. The code formatting and syntax seems consistent with Go conventions.\n2. The test cases in `grpc/chunk/chunker_test.go` seem well-structured and clear, which is a good sign.\n3. The use of comments to explain code in `shards/watcher.go` is a good practice, although the commented-out code could potentially be removed.\n4. The `README.md` file is present, but its content is not provided, so I can't assess its quality.\n\nHowever, these are just small glimpses into the codebase. To provide a more comprehensive assessment, I would need access to a larger portion of the codebase, including the overall project structure, coding guidelines, and a broader sample of the codebase across different components or modules.\n\nIf you can provide additional codebase context or specific areas of concern, I can provide a more informed evaluation of the code cleanliness.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:20 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:18.910Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 1a69e8325111b9defbc68bb4855776a4
      _order: 0
      cache: {}
      request:
        bodySize: 10431
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-fa9b972c6cfad5567e1b6fd066085ce9-f16298ffa0e10867-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What does directory watcher do?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 304539
        content:
          mimeType: text/event-stream
          size: 304539
          text: >+
            event: completion

            data: {"completion":"Based on the code snippet from shards/watcher.go, the DirectoryWatcher appears to be a struct that watches a directory for changes to files. Here's a breakdown of what the code does:\n\n1. The `newDirectoryWatcher` function creates a new `DirectoryWatcher` instance with the following fields:\n   - `dir`: the directory path to watch\n   - `timestamps`: a map to store file paths and their modification times\n   - `loader`: a `shardLoader` interface to load shards (not shown in the provided code)\n   - `ready`: a channel to signal when the watcher is ready\n   - `quit`: a channel to signal when the watcher should quit\n   - `stopped`: a channel to signal when the watcher has stopped\n\n2. It starts a new goroutine that does the following:\n   - Calls `sw.scan()` to scan the directory and populate the `timestamps` map\n   - Calls `sw.watch()` to start watching the directory for changes\n\n3. If there are any errors during `scan()` or `watch()`, the error is stored in `sw.readyErr`.\n\n4. The `ready` channel is closed when the setup is complete (either successfully or with an error).\n\n5. The created `DirectoryWatcher` instance is returned.\n\nSo, in summary, the `DirectoryWatcher` scans a directory, keeps track of file modification times, and watches for changes to those files. It likely uses the `shardLoader` interface to load or reload shards (likely search indexes) when files change.\n\nHowever, without more context, it's difficult to determine the exact purpose and usage of the `DirectoryWatcher` within the broader codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:28 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:26.286Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a3db7a44fd6168285e9f0c998c3d0a9d
      _order: 0
      cache: {}
      request:
        bodySize: 10433
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-4ae209a05d6dcd694c406ab7f519c1c8-9ea84c6bf2349998-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: where do we test the grpc chunker"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 14901
        content:
          mimeType: text/event-stream
          size: 14901
          text: >+
            event: completion

            data: {"completion":"Based on the provided code context, the test for the gRPC chunker is implemented in the `TestChunkerE2E` function in the `grpc/chunk/chunker_test.go` file. This test function sets up a gRPC server and client to test the chunking behavior of the server for different input payload sizes.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:36 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:35.181Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 192592915d6df31fd4f400c63d0729ea
      _order: 0
      cache: {}
      request:
        bodySize: 10167
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-567325d427d8502200d0cae23c465236-87d81ba2fa991512-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Are you capable of upgrading my pytorch
                  version to 1.0.0, there is a guide in the pytorch site"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 43296
        content:
          mimeType: text/event-stream
          size: 43296
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code does not seem to be related to PyTorch or upgrading Python packages. The code appears to be part of the Zoekt search engine written in Go.\n\nWithout additional context or access to files related to PyTorch or Python package management, I cannot provide specific guidance on upgrading PyTorch to version 1.0.0.\n\nIf you have additional files or information relevant to your Python environment and PyTorch installation, please provide that context, and I'll do my best to assist you with the upgrade process based on the official PyTorch upgrade guide.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:40 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:38.105Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 58e2fc1bc2174f2d602e457f19914e6f
      _order: 0
      cache: {}
      request:
        bodySize: 10167
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b3affe76179871bdaefed2156d5aeda8-45d73788dc13edb9-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Can you look through the files and identify
                  the conflicting packages that may be causing this?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 75872
        content:
          mimeType: text/event-stream
          size: 75872
          text: >+
            event: completion

            data: {"completion":"I could not find any conflicting packages from the provided code snippets. The files seem to be part of the same `zoekt` package and are working with related structs and functions for search result truncation and limiting.\n\nThe `limit.go` file contains utility functions to sort, truncate, and limit the search result `FileMatch` slices based on the specified `SearchOptions`. It defines types like `DisplayTruncator` and helper functions like `limitChunkMatches`, `limitLineMatches` to enforce limits on the number of chunk matches, line matches per file.\n\nWithout more context about what conflicting packages you are referring to, I cannot provide a more specific answer. If you could provide more details or code snippets showing the conflicting package imports, that would be helpful.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:44 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:42.598Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 254e7feb135bc955872473b68b6173e6
      _order: 0
      cache: {}
      request:
        bodySize: 32287
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c9c11e2f62e61e1ea9d9ba0549b62705-1a249e7d6b8d801f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Mind taking a second look at the file?
                  @limit.go"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 204899
        content:
          mimeType: text/event-stream
          size: 204899
          text: >+
            event: completion

            data: {"completion":"Sure, I can take another look at limit.go. Here are a few observations:\n\n1. The file contains utility functions related to limiting the number of matches returned for search results. Specifically, it has functions to limit the number of ChunkMatches and LineMatches per file.\n\n2. The `limitChunkMatches` function handles limiting ChunkMatches. It can potentially truncate the `Ranges`, `SymbolInfo`, and `Content` fields of each ChunkMatch to enforce the limit.\n\n3. The `limitLineMatches` function handles limiting LineMatches by truncating the `LineFragments` slice for each LineMatch.\n\n4. Both `limitChunkMatches` and `limitLineMatches` return the remaining limit after processing each file, allowing for early termination once the limit is exhausted.\n\n5. The `SortAndTruncateFiles` function is a convenience function that sorts the FileMatches by score and then truncates them based on the `MaxDocDisplayCount` and `MaxMatchDisplayCount` options in SearchOptions.\n\n6. The `NewDisplayTruncator` function returns a closure (`DisplayTruncator`) that enforces the `MaxDocDisplayCount` and `MaxMatchDisplayCount` limits by truncating the FileMatches as needed.\n\nLet me know if you need any clarification or have additional questions about this file!","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:52 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:48.370Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d93d0fffe22b25f4b15e41dd18ffcf76
      _order: 0
      cache: {}
      request:
        bodySize: 10115
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-096358e41e357c993f857c51dc063ffb-f6ac27815d88cb9a-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Why does this project use the MIT license?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 29081
        content:
          mimeType: text/event-stream
          size: 29081
          text: >+
            event: completion

            data: {"completion":"Unfortunately, I don't see any information about the license used for this project in the provided code and README files. The README does not mention the license, and there is no LICENSE file included in the context you provided. Without additional context about the licensing, I cannot determine why this project uses the MIT license specifically. If there is a LICENSE file or other information about licensing in the codebase, please provide that context so I can better answer the question.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:41:58 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:41:56.543Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0fd30b83f18d68ea869a489cecff918e
      _order: 0
      cache: {}
      request:
        bodySize: 32098
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0853c5d38fc94c77da8046ba0fa160b5-01f7d8a0545d3722-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: See zoekt repo find location of tensor
                  function"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 70621
        content:
          mimeType: text/event-stream
          size: 70621
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code does not contain any information about a \"tensor\" function. The provided code is for the Zoekt search engine, which is used for searching through source code. Without having access to the actual source code repositories that Zoekt indexes, I cannot locate a specific function called \"tensor\".\n\nThe code you provided seems to be the core logic for evaluating search queries, gathering matches, and returning search results. It does not appear to contain any specific references to tensor-related functions or operations.\n\nIf you have a specific repository or set of source code files in mind, I would need access to those files to be able to search for the location of a \"tensor\" function within them using Zoekt or any other code search tool.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:04 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:00.129Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 928694dfcb6607258fc622dfb5a4291d
      _order: 0
      cache: {}
      request:
        bodySize: 10480
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-677a5bff6cbc8b0b2bc30440237f70c8-979fef3971b6be9d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Explain the logic in src/agent.go,
                  particularly how agents interact with ranking"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 39277
        content:
          mimeType: text/event-stream
          size: 39277
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided context does not include the contents of the `src/agent.go` file, so I cannot explain the logic in that file regarding how agents interact with ranking. The only context given for `agent.go` is a single line:\n\n```go\n// Agent is an agent\n```\n\nThis does not provide enough information to understand the logic or functionality of the agents. If you could provide the actual contents of the `src/agent.go` file, I would be able to analyze the code and explain the relevant parts related to how agents interact with ranking.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:08 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:06.531Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: fab8c8d98faa0ba22b4036740b9678e1
      _order: 0
      cache: {}
      request:
        bodySize: 5515
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-4c7d98dc1f12b94ef7953d498d6d88cb-2875cc5c11b891cd-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: explain @README.md"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 73300
        content:
          mimeType: text/event-stream
          size: 73300
          text: >+
            event: completion

            data: {"completion":"The provided context is the contents of the `README.md` file for the Zoekt codebase. It contains:\n\n1. A brief introduction about Zoekt being a fast text search engine for source code.\n2. Instructions on how to download, index, and search using Zoekt.\n3. Details on setting up a search service using Zoekt.\n4. Information about symbol/ctag search capabilities.\n5. Acknowledgments for the creators.\n6. Details about this fork (sourcegraph/zoekt) and how it differs from the original google/zoekt repository.\n\nThe `README.md` serves as documentation explaining what Zoekt is, how to use it, and specific details about the sourcegraph/zoekt fork. It provides the necessary context for someone new to understand and work with this codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:12 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:10.601Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 4471cc84df1a050b6f41e1d99016bbe4
      _order: 0
      cache: {}
      request:
        bodySize: 10922
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-10f92a6bddfdaa0a2dff75c1c4538c68-6148507337bc07b4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  The provided context is the contents of the `README.md` file
                  for the Zoekt codebase. It contains:


                  1. A brief introduction about Zoekt being a fast text search engine for source code.

                  2. Instructions on how to download, index, and search using Zoekt.

                  3. Details on setting up a search service using Zoekt.

                  4. Information about symbol/ctag search capabilities.

                  5. Acknowledgments for the creators.

                  6. Details about this fork (sourcegraph/zoekt) and how it differs from the original google/zoekt repository.


                  The `README.md` serves as documentation explaining what Zoekt is, how to use it, and specific details about the sourcegraph/zoekt fork. It provides the necessary context for someone new to understand and work with this codebase.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: what does @limit.go do?"
            model: anthropic/claude-3-sonnet-20240229
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 250186
        content:
          mimeType: text/event-stream
          size: 250186
          text: >+
            event: completion

            data: {"completion":"Got it, I should focus only on the provided code context from `limit.go`.\n\nThe `limit.go` file contains functions related to limiting the number of files and matches returned in a search result, based on the specified `SearchOptions`.\n\nSpecifically, it provides the following functionality:\n\n1. `SortAndTruncateFiles` sorts the `FileMatch` slice and then truncates it based on the `MaxDocDisplayCount` limit specified in `SearchOptions`.\n\n2. `NewDisplayTruncator` returns a `DisplayTruncator` function that enforces both `MaxDocDisplayCount` and `MaxMatchDisplayCount` limits by truncating the `FileMatch` slice accordingly. If no limits are specified, it returns a no-op function.\n\n3. `limitMatches` is a helper function that either calls `limitChunkMatches` or `limitLineMatches` based on the `ChunkMatches` option, to limit the number of chunk/line matches per file.\n\n4. `limitChunkMatches` limits the number of `ChunkMatch` entries in a `FileMatch`, by truncating the `Ranges`, `SymbolInfo`, and `Content` fields as needed.\n\n5. `limitLineMatches` limits the number of `LineMatch` entries in a `FileMatch`, by truncating the `LineFragments` field.\n\nSo, in summary, this file contains the logic to apply the configured display limits on the search results, by truncating the file matches and their associated line/chunk matches as per the specified options.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:18 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:15.963Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 64911c2049d0ee26f449fc1e8689ed20
      _order: 0
      cache: {}
      request:
        bodySize: 5528
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ac81987384384b828e184d4d59ea9ca7-360a0978fce07113-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What code do you have access to?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 139647
        content:
          mimeType: text/event-stream
          size: 139647
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context from the README.md file, I have access to the following:\n\n1. The Zoekt text search engine, which is a fork of the original google/zoekt project, now maintained by Sourcegraph.\n2. The following command-line tools:\n   - `zoekt-index`: for indexing directories\n   - `zoekt-git-index`: for indexing Git repositories\n   - `zoekt-repo-index`: for indexing Repo repositories\n   - `zoekt-mirror-gitiles`: for mirroring Gitiles repositories\n   - `zoekt-webserver`: for running a web interface for searching\n   - `zoekt`: a command-line search tool\n3. A search service called `zoekt-indexserver` that can mirror and index repositories from various sources (GitHub, Gitiles, etc.).\n4. Support for symbol/ctag search and ranking.\n5. Some Sourcegraph-specific changes and additions, like the `zoekt-sourcegraph-indexserver` command and the use of the `keegancsmith/rpc` library.\n\nPlease let me know if you need any additional context or have any other questions.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:20.614Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 49d60f6278128108b3da812030b7e939
      _order: 0
      cache: {}
      request:
        bodySize: 4988
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cc98774ab92b085fa6e731a6692f44ed-84060be33f7a4661-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What does this repo do??"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 467829
        content:
          mimeType: text/event-stream
          size: 467829
          text: >+
            event: completion

            data: {"completion":"Based on the provided code, this repository seems to be part of the `zoekt` package, which appears to be a search-related functionality. The code includes the following key points:\n\n1. `SortAndTruncateFiles`: This function takes a list of `FileMatch` and applies sorting and truncation based on the given `SearchOptions`.\n\n2. `DisplayTruncator`: This is a stateful function that enforces document and match display limits by truncating and mutating the `FileMatch` list before returning it.\n\n3. `NewDisplayTruncator`: This function creates a `DisplayTruncator` that enforces the limits specified in the `SearchOptions`. If there are no limits to enforce, it returns a `DisplayTruncator` that simply returns the input `FileMatch` list.\n\n4. `limitMatches`: This function limits the number of matches in a `FileMatch` based on the specified limits. It can handle limiting either chunk matches or line matches.\n\n5. `limitChunkMatches`: This function limits the number of chunk matches in a `FileMatch` by truncating the `Ranges`, `SymbolInfo`, and `Content` fields.\n\n6. `limitLineMatches`: This function limits the number of line matches in a `FileMatch` by truncating the `LineFragments` field.\n\nBased on this, it seems that this repository is part of a search-related functionality, where the codebase is responsible for managing the display of search results by enforcing various limits on the number of documents and matches shown.\n\nTo get a better understanding of the overall purpose and context of this repository, I would need additional information, such as:\n\n- What is the main application or system this code is part of?\n- What is the overall purpose and functionality of this application or system?\n- How does the `zoekt` package fit into the larger system?\n- What are the typical use cases and requirements that this code is designed to address?\n\nWith more context about the broader system and the problem this code is trying to solve, I can provide a more informed analysis and understanding of the repo's purpose.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:24 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:23.375Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 76d73b68cfd915034744ede32633b169
      _order: 0
      cache: {}
      request:
        bodySize: 10276
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-3b5c7e5e4ec74d3057447845f54301d9-388fa059e03fa7b3-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: describe my code"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 248049
        content:
          mimeType: text/event-stream
          size: 248049
          text: >+
            event: completion

            data: {"completion":"The provided codebase context is a Go package called `zoekt` that contains functions and types related to limiting and truncating search results.\n\nThe main functionality is provided by the following functions and types:\n\n1. `SortAndTruncateFiles`: This function takes a slice of `FileMatch` objects, sorts them, and then truncates the results based on the provided `SearchOptions`.\n\n2. `DisplayTruncator`: This is a function type that enforces document and match display limits by truncating and mutating the input slice of `FileMatch` objects. The `NewDisplayTruncator` function returns an instance of this type, along with a boolean indicating whether there are any limits to enforce.\n\n3. `limitMatches`: This function limits the number of matches in a slice of `FileMatch` objects based on the provided limit and whether chunk matches or line matches should be truncated.\n\n4. `limitChunkMatches`: This function truncates the `ChunkMatches` field of a `FileMatch` object, adjusting the `Content` field accordingly.\n\n5. `limitLineMatches`: This function truncates the `LineMatches` field of a `FileMatch` object.\n\nThe purpose of this code is to provide a way to limit the number of search results displayed, either by limiting the number of documents (files) or the number of matches within each document. This is likely to improve performance and responsiveness of the search engine, especially when dealing with large amounts of data.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:29 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:28.147Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ca88767c3cf65965b5f62e0236c31705
      _order: 0
      cache: {}
      request:
        bodySize: 5466
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ebc97fb7e9d76d0c011fcc061d40e1eb-557ad5e3d0197c1d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: @zoekt describe my code."
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 36035
        content:
          mimeType: text/event-stream
          size: 36035
          text: >+
            event: completion

            data: {"completion":"I'm sorry, but I don't see any code provided with the name \"zoekt\" in the context you've given me. The code snippets you've provided are from various Go files, including `agent.go`, `watcher.go`, `README.md`, `limit.go`, and `chunker_test.go`. However, I don't see any code labeled as \"zoekt\". Could you please provide more context or clarify what you're asking about? I'd be happy to try to describe the code once I have a better understanding of what you're looking for.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:33 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:32.485Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 38166ba14e3e9bb1759f043e2a610e55
      _order: 0
      cache: {}
      request:
        bodySize: 5464
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-671e7de6ce8edf18deee5ceeb751ff4e-17c1b1d6e0baaba2-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: is my code base clean?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 203152
        content:
          mimeType: text/event-stream
          size: 203152
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, I don't have enough information to determine if the codebase is \"clean\" or not. The snippets provided cover different areas of the codebase, such as an agent, a directory watcher, a README, a file limiting function, and a test for a chunker. Without seeing the full codebase, understanding the project's requirements, architecture, and coding standards, I cannot make an assessment on the overall cleanliness of the codebase.\n\nTo provide a more meaningful assessment, I would need additional context, such as:\n\n1. The project's overall structure and organization (e.g., directory layout, package structure).\n2. Coding standards and best practices followed in the codebase.\n3. Consistency in code formatting, naming conventions, and overall style.\n4. Evidence of code duplication, complex or confusing logic, lack of comments/documentation.\n5. Information on how the different components of the codebase interact and work together.\n6. Details on the project's maturity, active development, and maintenance practices.\n\nWithout access to the full codebase and a better understanding of the project's context, I cannot provide a reliable assessment of the codebase's cleanliness. Please let me know if you can provide any additional information that would help me evaluate the codebase more thoroughly.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:35 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:34.886Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 3a88bc2461000c313cbda9f013dcccd7
      _order: 0
      cache: {}
      request:
        bodySize: 10430
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-2627eec9585ace5b2e3020a0a554a7a6-f65e8b63ef460a62-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What does directory watcher do?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 345664
        content:
          mimeType: text/event-stream
          size: 345664
          text: >+
            event: completion

            data: {"completion":"Based on the code context provided, the `DirectoryWatcher` seems to be a component responsible for watching a directory for changes and loading shards (possibly related to search indexing) when changes are detected.\n\nThe `newDirectoryWatcher` function appears to be the constructor for the `DirectoryWatcher` struct, which initializes the following fields:\n\n1. `dir`: The directory to be watched.\n2. `timestamps`: A map to keep track of the last modification times of files in the directory.\n3. `loader`: A `shardLoader` instance, which is likely responsible for loading the shards.\n4. `ready`: A channel that is closed when the watcher is ready.\n5. `quit`: A channel used to signal the watcher to stop.\n6. `stopped`: A channel that is closed when the watcher has stopped.\n\nThe code also shows that the `newDirectoryWatcher` function starts a goroutine that:\n1. Calls the `scan()` function to initially scan the directory and load the shards.\n2. Calls the `watch()` function to start watching the directory for changes.\n\nIf any errors occur during the initial scan or watch, the `readyErr` field is set, and the `ready` channel is closed.\n\nTo fully understand the purpose and behavior of the `DirectoryWatcher`, I would need additional context, such as:\n\n1. How the `DirectoryWatcher` is used in the codebase.\n2. What the `shardLoader` interface does and how it is implemented.\n3. More details on the `scan()` and `watch()` functions, and how they interact with the `shardLoader`.\n\nWithout this additional context, I can only provide a high-level understanding of the `DirectoryWatcher` based on the code snippet provided.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:39 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:38.044Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 07413ec11ec9edce274c0f6fb70f66db
      _order: 0
      cache: {}
      request:
        bodySize: 10432
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e46146d1276a608d307a6be66f4e6af0-fbe193c8bc89d0d3-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: where do we test the grpc chunker"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 30838
        content:
          mimeType: text/event-stream
          size: 30838
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the grpc chunker is tested in the file `grpc/chunk/chunker_test.go`. The `TestChunkerE2E` function in this file appears to be the test for the grpc chunker implementation.\n\nThe test function checks the behavior of the chunker by running a server and client, and verifying that the chunked messages are received correctly by the client. It covers two test cases - one with a normal input size and another with an empty payload.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:42 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:41.981Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: e8971158e930b6a28926a8764457c5db
      _order: 0
      cache: {}
      request:
        bodySize: 10166
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b1e40fc52f9a6eb63e5e4140293eac71-888f73f93ddf1b4c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Are you capable of upgrading my pytorch
                  version to 1.0.0, there is a guide in the pytorch site"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 67748
        content:
          mimeType: text/event-stream
          size: 67748
          text: >+
            event: completion

            data: {"completion":"I'm afraid I don't have enough information to upgrade your PyTorch version to 1.0.0. The provided codebase context is related to a text search engine called Zoekt and does not contain any code related to PyTorch or its version management.\n\nWithout access to the actual project or repository that uses PyTorch, I cannot perform the version upgrade you've requested. If you could provide more context about the project you're working on, such as the programming language, framework, and the current PyTorch version, I'd be happy to assist you further with the upgrade process.\n\nPlease let me know if you can share any additional details about the project you're working on, and I'll do my best to help you upgrade the PyTorch version.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:44 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:43.815Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 24813abe7d4784c7cec28685c3303f9c
      _order: 0
      cache: {}
      request:
        bodySize: 10166
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-6ad02604ba3b398d9f76e29f7622faa6-5d716e2b95117ceb-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Can you look through the files and identify
                  the conflicting packages that may be causing this?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 89324
        content:
          mimeType: text/event-stream
          size: 89324
          text: >+
            event: completion

            data: {"completion":"From the provided codebase context, I don't see any obvious conflicting packages. The code appears to be part of the `zoekt` package, which is a text search engine for source code.\n\nThe `limit.go` file defines functions related to limiting the number of file matches and match details returned in search results, based on the configured search options. This is likely a necessary feature to prevent search results from becoming too large and overwhelming the user.\n\nWithout more context about the overall codebase structure, build issues, or specific errors you're encountering, I don't have enough information to identify any conflicting packages that may be causing problems. Could you please provide more details about the issue you're facing or any specific errors you're seeing? That would help me better understand the problem and potentially identify any package conflicts or other issues in the codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:47 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:46.545Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b68b8a612936ff3b1836ef1b4356a93c
      _order: 0
      cache: {}
      request:
        bodySize: 10308
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c5f7a5830912090689334e8b79e109f3-e821ebae34a5016e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Mind taking a second look at the file?
                  @limit.go"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 342797
        content:
          mimeType: text/event-stream
          size: 342797
          text: >+
            event: completion

            data: {"completion":"Sure, I'll take a closer look at the `limit.go` file.\n\nThe `limit.go` file appears to be part of the `zoekt` package and contains functions related to limiting the number of file matches and match details displayed in search results.\n\nHere's a breakdown of the functions in this file:\n\n1. `SortAndTruncateFiles`: This function takes a slice of `FileMatch` objects and an `SearchOptions` object, sorts the files, and then truncates the results based on the limits specified in the `SearchOptions`.\n\n2. `NewDisplayTruncator`: This function creates a `DisplayTruncator` function that enforces the document and match display limits specified in the `SearchOptions`. The `DisplayTruncator` function is returned along with a boolean indicating whether any limits are set.\n\n3. `limitMatches`: This function takes a slice of `FileMatch` objects and a limit, and applies the appropriate match limiting function (`limitChunkMatches` or `limitLineMatches`) based on the `ChunkMatches` option in the `SearchOptions`.\n\n4. `limitChunkMatches`: This function limits the number of `ChunkMatches` in a `FileMatch` object by truncating the `Ranges`, `SymbolInfo`, and `Content` fields.\n\n5. `limitLineMatches`: This function limits the number of `LineMatches` in a `FileMatch` object by truncating the `LineFragments` field.\n\nThe purpose of these functions is to ensure that the search results returned by the `zoekt` package do not exceed the document and match display limits specified in the `SearchOptions`. This helps to keep the search results concise and easy to navigate for the user.\n\nLet me know if you need any additional context or have any other questions!","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:50 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:49.582Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 11a64ea611e47791f3d83e6b442af559
      _order: 0
      cache: {}
      request:
        bodySize: 10114
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-5c768b74d6301dec3185d577110113ed-dcbe515ec4270604-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Why does this project use the MIT license?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 23555
        content:
          mimeType: text/event-stream
          size: 23555
          text: >+
            event: completion

            data: {"completion":"The provided codebase context does not mention anything about the licensing of this project. The README.md file does not contain any information about the license used for this project. Without additional context about the licensing, I cannot determine why this project uses the MIT license. If you could provide more information about the licensing of this project, that would help me better understand the rationale behind the choice of license.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:54 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:53.326Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 3435e99242a11ba5ace3eeadbea86cd2
      _order: 0
      cache: {}
      request:
        bodySize: 10119
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e570269485ab263612753ee512770d0b-9a21888ba0eaa1d9-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: See zoekt repo find location of tensor
                  function"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 96140
        content:
          mimeType: text/event-stream
          size: 96140
          text: >+
            event: completion

            data: {"completion":"To find the location of the `tensor` function in the provided codebase, I will need to search through the code and directories. However, the codebase context provided does not include the full codebase, only the `README.md` and `limit.go` files.\n\nWithout access to the complete codebase, I do not have enough information to determine the location of the `tensor` function. \n\nTo answer this question, I would need the following additional context:\n\n1. The full directory structure of the codebase, including all the source files.\n2. Any information about where the `tensor` function might be defined (e.g. which package, module or directory it is located in).\n\nIf you can provide the complete codebase or more details about the location of the `tensor` function, I would be happy to try and find its location. Please let me know if you can share any additional context.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:56 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:55.009Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0a102d49fd5ddc1ba52cdff4c4b33efb
      _order: 0
      cache: {}
      request:
        bodySize: 10479
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-6625e8efea61f4c8343b4d705f859303-8f7c8b6ea2616c68-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Explain the logic in src/agent.go,
                  particularly how agents interact with ranking"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 125019
        content:
          mimeType: text/event-stream
          size: 125019
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code context does not contain any information about the `agent.go` file or how agents interact with ranking. The only context provided is the comment `// Agent is an agent` from the `agent.go` file, which does not provide enough information to explain the logic in that file or how agents interact with ranking.\n\nTo better understand the logic in `agent.go` and how agents interact with ranking, I would need additional context, such as:\n\n1. The full contents of the `agent.go` file, including any relevant functions, structs, or data types.\n2. Any other files or code that interact with or reference the `Agent` struct or functionality.\n3. Any documentation or comments that describe the purpose and behavior of the `Agent` and how it relates to ranking.\n\nWithout more comprehensive code context, I cannot provide a detailed explanation of the logic in `agent.go` or how agents interact with ranking. Please provide additional relevant code and context, and I'd be happy to analyze and explain the functionality.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:42:58 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:42:57.646Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 68702e73d9477acb047dc1717a98edd9
      _order: 0
      cache: {}
      request:
        bodySize: 5514
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1f5afc6eaff248769213497d6b93414e-07d6c37214619bcf-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: explain @README.md"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 284012
        content:
          mimeType: text/event-stream
          size: 284012
          text: >+
            event: completion

            data: {"completion":"Based on the provided README.md file, this is a fast text search engine, intended for use with source code. It is a fork of the original Zoekt project by Google, and is now the main maintained source of Zoekt.\n\nThe README.md file provides instructions on how to download, index, and search using Zoekt. It covers the following:\n\n1. **Downloading**: Instructions on how to download Zoekt using the `go get` command.\n\n2. **Indexing**: Instructions on how to index directories, Git repositories, and Repo repositories using the provided `zoekt-index`, `zoekt-git-index`, and `zoekt-repo-index` commands.\n\n3. **Searching**: Instructions on how to search using the web interface, JSON API, and command-line interface (CLI).\n\n4. **Installation**: Provides an example systemd unit file for setting up a Zoekt web server on a Linux server.\n\n5. **Search Service**: Explains how to use the `zoekt-indexserver` command to automatically mirror and index repositories from GitHub and Gitiles.\n\n6. **Symbol Search**: Recommends installing Universal ctags to improve ranking for symbol search.\n\n7. **Acknowledgements**: Acknowledges the original creators of Zoekt and the contributors to this fork.\n\n8. **Fork Details**: Explains the differences between this fork and the original Zoekt project, including the addition of a Sourcegraph-specific indexing command and other minor changes.\n\n9. **Disclaimer**: Clarifies that this is not an official Google product.\n\nOverall, the README.md file provides comprehensive information about the Zoekt project, its features, and how to use it.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:01 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:00.853Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: aa29e9968580c4c478927e46cc65acbc
      _order: 0
      cache: {}
      request:
        bodySize: 11767
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-d75463f9a994830a20bbbebc21979951-e2ce942a206b046b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  Based on the provided README.md file, this is a fast text
                  search engine, intended for use with source code. It is a fork
                  of the original Zoekt project by Google, and is now the main
                  maintained source of Zoekt.


                  The README.md file provides instructions on how to download, index, and search using Zoekt. It covers the following:


                  1. **Downloading**: Instructions on how to download Zoekt using the `go get` command.


                  2. **Indexing**: Instructions on how to index directories, Git repositories, and Repo repositories using the provided `zoekt-index`, `zoekt-git-index`, and `zoekt-repo-index` commands.


                  3. **Searching**: Instructions on how to search using the web interface, JSON API, and command-line interface (CLI).


                  4. **Installation**: Provides an example systemd unit file for setting up a Zoekt web server on a Linux server.


                  5. **Search Service**: Explains how to use the `zoekt-indexserver` command to automatically mirror and index repositories from GitHub and Gitiles.


                  6. **Symbol Search**: Recommends installing Universal ctags to improve ranking for symbol search.


                  7. **Acknowledgements**: Acknowledges the original creators of Zoekt and the contributors to this fork.


                  8. **Fork Details**: Explains the differences between this fork and the original Zoekt project, including the addition of a Sourcegraph-specific indexing command and other minor changes.


                  9. **Disclaimer**: Clarifies that this is not an official Google product.


                  Overall, the README.md file provides comprehensive information about the Zoekt project, its features, and how to use it.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: what does @limit.go do?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 388971
        content:
          mimeType: text/event-stream
          size: 388971
          text: >+
            event: completion

            data: {"completion":"Okay, let me take a closer look at the `limit.go` file you provided.\n\nBased on the code in `limit.go`, it seems to be responsible for handling the display limits of search results in the Zoekt search engine.\n\nThe main functions in this file are:\n\n1. `SortAndTruncateFiles`: This function takes a list of `FileMatch` objects (representing search results) and sorts them, then applies display truncation based on the provided `SearchOptions`.\n\n2. `NewDisplayTruncator`: This function creates a `DisplayTruncator` function that can be used to enforce the document and match display limits specified in the `SearchOptions`. It returns a boolean indicating whether there are any limits to enforce.\n\n3. `limitMatches`: This function takes a list of `FileMatch` objects and a limit, and returns the list truncated to fit the limit. It can handle two modes of truncation: `chunkMatches` (truncating at the chunk level) and `lineMatches` (truncating at the line level).\n\n4. `limitChunkMatches`: This function is responsible for truncating the `ChunkMatches` field of a `FileMatch` object to fit the specified limit.\n\n5. `limitLineMatches`: This function is responsible for truncating the `LineMatches` field of a `FileMatch` object to fit the specified limit.\n\nThe main purpose of this code is to ensure that the search results displayed to the user do not exceed the configured limits, in terms of the number of documents and matches shown. This helps to provide a responsive and manageable search experience, especially when dealing with large code bases.\n\nWithout additional context from the rest of the codebase, I don't have enough information to fully explain how this code is used in the overall Zoekt search engine. But this should give you a good understanding of what the `limit.go` file is responsible for.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:05 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:04.674Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f55baa6d58f72a73aa927e3b1d3cc66e
      _order: 0
      cache: {}
      request:
        bodySize: 5623
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e1b18bbb0ecc0114e2f91c1b23ae679f-77cc2f7102bc0f49-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What code do you have access to?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 18449
        content:
          mimeType: text/event-stream
          size: 18449
          text: >+
            event: completion

            data: {"completion":"I have access to the README.md file, which contains information about installing, indexing, and searching with Zoekt, a fast text search engine. The README.md file also includes instructions for using the Zoekt web interface, JSON API, and CLI. Additionally, there are details about a search service, symbol search, acknowledgements, fork details, and a disclaimer.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:10 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:09.691Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7cfb29363cc600d61ed8db1487028fd9
      _order: 0
      cache: {}
      request:
        bodySize: 5083
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-7bf4d6efcee604fa4e5fa7f6a85afa51-f6339ff371294656-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What does this repo do??"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 30752
        content:
          mimeType: text/event-stream
          size: 30752
          text: >+
            event: completion

            data: {"completion":"Based on the provided code, this repository appears to contain code related to searching and sorting files for a search tool. The code includes functions for sorting and truncating file matches based on search options, as well as enforcing display limits for documents and matches. The repository likely facilitates searching for specific content within files and displaying relevant matches within a specified limit. More details about the specific purpose and functionality of the search tool may be found in additional files within the repository.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:12 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:11.477Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 537e27592b76db38f005c7745a6072a5
      _order: 0
      cache: {}
      request:
        bodySize: 10371
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-259c47fea7b8f84a61906bc705aed387-b57700947b8c67e4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: describe my code"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 124352
        content:
          mimeType: text/event-stream
          size: 124352
          text: >+
            event: completion

            data: {"completion":"Based on the code provided, it appears to be related to implementing functionality for sorting and truncating file matches based on search options in a search engine application. \n\nThe `SortAndTruncateFiles` function is a convenience method that sorts a list of `FileMatch` objects and then truncates them based on certain search options. The `DisplayTruncator` type is defined as a stateful function that enforces display limits by truncating and mutating the output.\n\nThe `NewDisplayTruncator` function creates a `DisplayTruncator` based on the search options provided. It enforces limits on the number of documents and matches to be displayed. The `limitMatches`, `limitChunkMatches`, and `limitLineMatches` functions are used to enforce these limits by limiting the number of chunk matches and line matches in each `FileMatch` object.\n\nOverall, the code snippet provided seems to be part of a larger search engine application where file matches are sorted and truncated to provide more manageable search results based on user-specified display limits.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:13.607Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8e3ba80bf1698dec1de9741f9b338996
      _order: 0
      cache: {}
      request:
        bodySize: 5561
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ac70dc33ce62ae5df1efd1272ca55a26-aaf6db0146c10986-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: @zoekt describe my code."
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 3466
        content:
          mimeType: text/event-stream
          size: 3466
          text: >+
            event: completion

            data: {"completion":"Could you provide more context or clarify your request so I can better understand what specific information you are seeking about your code?","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:18 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:17.733Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 03800fe294b40386c5047cf4574fa4f0
      _order: 0
      cache: {}
      request:
        bodySize: 5559
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0983aab2156aba0260058cf95774fa44-101a72440f37b105-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: is my code base clean?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 24751
        content:
          mimeType: text/event-stream
          size: 24751
          text: >+
            event: completion

            data: {"completion":"To determine if your codebase is clean, I would need more context or information about what criteria or standards you are using to define \"clean code.\" Some common considerations for clean code include readability, maintainability, adherence to coding standards, absence of code smells, efficiency, and proper documentation. If you have specific guidelines or requirements in mind, please provide them so I can assess whether your codebase meets those criteria.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:19 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:18.732Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 5740d94bb60512e05aab50a6987e26e0
      _order: 0
      cache: {}
      request:
        bodySize: 10525
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-73e4154bf1a35d0532126f60c7ef7408-058654e78a3060e4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: What does directory watcher do?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 20086
        content:
          mimeType: text/event-stream
          size: 20086
          text: >+
            event: completion

            data: {"completion":"The directory watcher in the provided codebase context appears to be a function that creates a new instance of a directory watcher. It sets up a watcher for a given directory with certain attributes such as timestamps, loader, and channels for handling readiness, quit signal, and stopped signal. The function also includes logic to scan the directory and start watching for changes in the directory asynchronously.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:20.673Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c9ab06238dceada224a29ac4dc5c8a49
      _order: 0
      cache: {}
      request:
        bodySize: 10527
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-d585cb08b1c0affcbf25edb6a5e99156-3de89e9e50bcc8e5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: where do we test the grpc chunker"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 1615
        content:
          mimeType: text/event-stream
          size: 1615
          text: >+
            event: completion

            data: {"completion":"Where do we test the grpc chunker in the provided codebase context?","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:23 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:22.409Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f1f7191753784d5de208f1f568e65673
      _order: 0
      cache: {}
      request:
        bodySize: 10261
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-33c374df1d7b08d15d4976e72c46a6d8-1ddd433d400b7eda-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Are you capable of upgrading my pytorch
                  version to 1.0.0, there is a guide in the pytorch site"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 22987
        content:
          mimeType: text/event-stream
          size: 22987
          text: >+
            event: completion

            data: {"completion":"I'm sorry, but as an AI coding assistant, I can provide guidance and assistance with code-related tasks, but I do not have the capability to directly perform actions such as upgrading software packages like PyTorch. However, I can help guide you through the process based on the guide provided by the PyTorch website. If you have any specific questions or need assistance with the upgrade process, feel free to ask.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:24 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:23.209Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 1a8ae8c241cdfbca78ce5abb95c96cae
      _order: 0
      cache: {}
      request:
        bodySize: 10261
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-bea7d2c785a08bc9455e88fce94eb453-d4bac6b2f02d09a2-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Can you look through the files and identify
                  the conflicting packages that may be causing this?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 9646
        content:
          mimeType: text/event-stream
          size: 9646
          text: >+
            event: completion

            data: {"completion":"Based on the provided context, the conflicting packages that may be causing issues are `import \"log\"` and `package zoekt`. These two packages are from different namespaces and could potentially cause conflicts if they are used improperly within the same codebase.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:26 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:25.148Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: bcd6395d4f7ddf9a9b5f76268fac99fa
      _order: 0
      cache: {}
      request:
        bodySize: 10403
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-579f9e302375e69a88da95f826d6a71a-3386e7e6e8dd2531-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Mind taking a second look at the file?
                  @limit.go"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 1403
        content:
          mimeType: text/event-stream
          size: 1403
          text: >+
            event: completion

            data: {"completion":"Sure, let's take a closer look at the file limit.go.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:27 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:26.589Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d98bc07f0ccde679e0c03a8536f0e19b
      _order: 0
      cache: {}
      request:
        bodySize: 10209
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a0c310e25acb72f9bc49c68ce992b81e-7e09a1e9b8f0529e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Why does this project use the MIT license?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 10292
        content:
          mimeType: text/event-stream
          size: 10292
          text: >+
            event: completion

            data: {"completion":"I do not have access to the complete information about why this project uses the MIT license based on the provided codebase context. If you can provide additional information or context related to the licensing decisions of the project, I can help you analyze it further.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:28 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:27.345Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 4b829b862e7d596cb1f6899f24a5330d
      _order: 0
      cache: {}
      request:
        bodySize: 10214
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-6966235aa84fa6bef7977c6dfba36d48-3f4484f7c56c5722-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: See zoekt repo find location of tensor
                  function"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 29469
        content:
          mimeType: text/event-stream
          size: 29469
          text: >+
            event: completion

            data: {"completion":"To find the location of the \"tensor\" function in the \"zoekt\" repository, you would typically search for the function name in the codebase. In this context, you would likely search for the term \"tensor\" in the code files of the \"zoekt\" repository. You can use tools like `grep` or Search functionality within your code editor to locate the function definition. If you need assistance with any specific search queries or patterns to find the function, please let me know.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:29 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:28.776Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 52b9dd52afddc2a6b47d7d45c07ddfe2
      _order: 0
      cache: {}
      request:
        bodySize: 10574
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c77ee2b621dafa8ad93f647f53570757-b97289677e0ec784-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/agent.go:
                  ```go
                  package agent

                  // Agent is an agent```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: Explain the logic in src/agent.go,
                  particularly how agents interact with ranking"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 7843
        content:
          mimeType: text/event-stream
          size: 7843
          text: >+
            event: completion

            data: {"completion":"Sorry, but the code snippet provided doesn't contain information about how agents interact with ranking in src/agent.go. Could you provide more specific details or relevant sections of the code related to agents interacting with ranking?","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:31 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:30.753Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 05f37fd2b05573ca9372202de6c49109
      _order: 0
      cache: {}
      request:
        bodySize: 5609
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a6e238b8d9a4b2a2c16fef7c9a38e305-0efc2e7ce4f3568c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: explain @README.md"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 3253
        content:
          mimeType: text/event-stream
          size: 3253
          text: >+
            event: completion

            data: {"completion":"Can you provide some additional context or guidance on what specifically you would like me to explain from the README.md file?","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:32 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:31.975Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0fdae712a42eda0334b0efcc4cb790b2
      _order: 0
      cache: {}
      request:
        bodySize: 10398
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-5de71afc65626d64b8459101131e819c-ba92eb105cb0e922-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: Can you provide some additional context or guidance on what specifically
                  you would like me to explain from the README.md file?
              - speaker: human
                text: "The provided codebase context are the code you need and have access to.
                  Do not make any assumptions. Ask for additional context if you
                  need it. Question: what does @limit.go do?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 88845
        content:
          mimeType: text/event-stream
          size: 88845
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file in the codebase implements functions related to limiting and truncating search results for file matches in the `zoekt` search engine. \n\nHere's a breakdown of what the `limit.go` file does:\n1. `SortAndTruncateFiles` function sorts the file matches and truncates them based on search options.\n2. `DisplayTruncator` type and `NewDisplayTruncator` function enforce document and match display limits by truncating and mutating the file matches.\n3. `limitMatches`, `limitChunkMatches`, and `limitLineMatches` functions handle limiting the number of chunk matches or line matches in a file match by truncating them according to specified limits.\n4. These functions ensure that the search results adhere to the display limits specified in the search options, providing a controlled and organized way of presenting search results in the `zoekt` search engine.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:43:33 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:43:32.855Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 12581f1c735a04aeb88af7a54cd007b2
      _order: 0
      cache: {}
      request:
        bodySize: 217
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "217"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 340
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CodyConfigFeaturesResponse {
                  site {
                      codyConfigFeatures {
                          chat
                          autoComplete
                          commands
                          attribution
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CodyConfigFeaturesResponse
            value: null
        url: https://sourcegraph.com/.api/graphql?CodyConfigFeaturesResponse
      response:
        bodySize: 162
        content:
          encoding: base64
          mimeType: application/json
          size: 162
          text: "[\"H4sIAAAAAAAAAzyLwQqA\",\"IBAF/2XPfYFXof/YdC0h3dDnIcR/Dws6DQwznTyDyXSq\
            ETLp1N9Wc4j7KoxWpL72YJBBabIQN6jVdJ0yj885TYmzr38DlLg1RM1kAp9VxhjjAQA\
            A//8=\",\"AwCHzi5CbgAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.351Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 09b59ac55ce3c40d6f9ab8c79846a2c6
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 244
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query ContextFilters {
                  site {
                      codyContextFilters(version: V1) {
                          raw
                      }
                  }
              }
            variables: {}
        queryString:
          - name: ContextFilters
            value: null
        url: https://sourcegraph.com/.api/graphql?ContextFilters
      response:
        bodySize: 114
        content:
          encoding: base64
          mimeType: application/json
          size: 114
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdHJ+SmVzvl5JakVJW6ZOSWpRcUg0aLE\
            ciWrvNKcnNra2loAAAAA//8=\",\"AwA2LshlNQAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.823Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9d0e130a38eaf9d3cd8d9512afc14b87
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 328
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query ContextFilters {
                  site {
                      codyContextFilters(version: V1) {
                          raw
                      }
                  }
              }
            variables: {}
        queryString:
          - name: ContextFilters
            value: null
        url: https://sourcegraph.com/.api/graphql?ContextFilters
      response:
        bodySize: 104
        content:
          encoding: base64
          mimeType: application/json
          size: 104
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdHJ+SmVzvl5JakVJW6ZOSWpRcUg0aLEciWrv\
            NKcnNra2loAAAAA//8DADYuyGU1AAAA\"]"
          textDecoded:
            data:
              site:
                codyContextFilters:
                  raw: null
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.439Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 460fa85fef77ffa15bb82fa3a88049a3
      _order: 0
      cache: {}
      request:
        bodySize: 318
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "318"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 345
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmConfiguration {
                  site {
                      codyLLMConfiguration {
                          chatModel
                          chatModelMaxTokens
                          fastChatModel
                          fastChatModelMaxTokens
                          completionModel
                          completionModelMaxTokens
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmConfiguration
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmConfiguration
      response:
        bodySize: 251
        content:
          encoding: base64
          mimeType: application/json
          size: 251
          text: "[\"H4sIAAAAAAAAA3zOwQqC\",\"QBAG4HeZs+K0BqFXr3rrBYbdMRdtJ3ZXKmTfPSyiSOg0\
            8PP/H7OAoUhQLxBs5PVqMfe27RpxvT3NnqIV98wHip0YnqAGcnHwcrG60BPNhvMyD+I\
            cx1yh2qNSFWSfQUe3o4zsAtQ7hYgZ9BRi898byI7ziyvxAD+bLanlfJl4ffaN9tbzVf\
            wYihDJazHsYdP7gipETCmlBwAAAP//AwBQeP+1EwEAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.931Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7edf90ea650cb304fe26f9d57bd79477
      _order: 0
      cache: {}
      request:
        bodySize: 165
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "165"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 345
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmConfiguration {
                  site {
                      codyLLMConfiguration {
                          smartContextWindow
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmConfiguration
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmConfiguration
      response:
        bodySize: 135
        content:
          encoding: base64
          mimeType: application/json
          size: 135
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdHJ+SmVPj6+zvl5aZnppUWJJZn5eWD5\
            3MSiEuf8vJLUipLwzLyU/HIlK6XUvMSknNQUpdra2loAAAAA//8DAOgINKVLAAAA\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.955Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d890a82b3cc2fe4d514f289e8fe6d158
      _order: 0
      cache: {}
      request:
        bodySize: 150
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "150"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 340
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmProvider {
                  site {
                      codyLLMConfiguration {
                          provider
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmProvider
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmProvider
      response:
        bodySize: 134
        content:
          encoding: base64
          mimeType: application/json
          size: 134
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdHJ+SmVPj6+zvl5aZnppUWJJZn5eSDx\
            gqL8ssyU1CIlK6Xi/NKi5NT0osSCDKXa2tpaAAAAAP//\",\"AwAfFAXARQAAAA==\"\
            ]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.932Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7f3ff10a39505669cb5d36145df5fa95
      _order: 0
      cache: {}
      request:
        bodySize: 227
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "227"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 325
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentUser {
                  currentUser {
                      id
                      hasVerifiedEmail
                      displayName
                      username
                      avatarURL
                      primaryEmail {
                          email
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentUser
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentUser
      response:
        bodySize: 348
        content:
          encoding: base64
          mimeType: application/json
          size: 348
          text: "[\"H4sIAAAAAAAAA2RPy06DQBT9l7uGgmm0MEkTbW1dVImPlNTlZbiFAYbBeVQp4d8bUhMX7\
            s7JOTmPAXK0CGwA7rSm1u4N6YmKHBikh6ThlTonj283LxVfggclmpS0OArKNxJFA8xq\
            Rx7kwnQN9glKAgYfymlOhcauXCnrx2EYggfOkG6vBvNnyJSNa//YfksHHuAJLer9+zM\
            wKK3tDAuCppzPCqWKhqYErlpLrZ1xJQMMHtZFpPhui1/ZJ7lVnVW3+XZz/omyQxrhQs\
            xNmu3WyWu6eApdf6qXJr7zOXjQaSFR978nBqAr+LfsvpiEqQ3GcRwvAAAA//8DALThL\
            hwxAQAA\"]"
          textDecoded:
            data:
              currentUser:
                avatarURL: https://lh3.googleusercontent.com/a/ACg8ocKFaqbYeuBkbj5dFEzx8bXV8a7i3sVbKCNPV7G0uyvk=s96-c
                displayName: SourcegraphBot-9000
                hasVerifiedEmail: true
                id: VXNlcjozNDQ1Mjc=
                primaryEmail:
                  email: sourcegraphbot9k@gmail.com
                username: sourcegraphbot9k-fnwmu
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.977Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 84b962509b12000d0eef7c8a8fa655f3
      _order: 0
      cache: {}
      request:
        bodySize: 268
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "268"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 341
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentUserCodySubscription {
                  currentUser {
                      codySubscription {
                          status
                          plan
                          applyProRateLimits
                          currentPeriodStartAt
                          currentPeriodEndAt
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentUserCodySubscription
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentUserCodySubscription
      response:
        bodySize: 231
        content:
          encoding: base64
          mimeType: application/json
          size: 231
          text: "[\"H4sIAAAAAAAAA1zMsQrC\",\"MBSF4Xc5c4U2VodsRToIgqWtDm6xyRCoSbi5GUrJu4uC\
            oI7n5+Os0IoV5IopERnHl2joPb1ehnSPE9nA1rtXi6w4RUg0h/F4bVEgzMpBouvPKKB\
            CmJeOfK/YnOzDcoRkSqb4fHeGrNcDK+KGISFKUW/K3aaqRyFkVcmtuOFPt05/2f2vzT\
            nnJwAAAP//AwBSFe7+wgAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.116Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ea3ddfc16f0b52a2180a9bd21c87dc08
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 240
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query Repository($name: String!) {
              	repository(name: $name) {
              		id
              	}
              }
            variables:
              name: github.com/sourcegraph/cody
        queryString:
          - name: Repository
            value: null
        url: https://sourcegraph.com/.api/graphql?Repository
      response:
        bodySize: 123
        content:
          encoding: base64
          mimeType: application/json
          size: 123
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqSi3IL84syS+qBPEyU5SslEJzw8qTjP0KUtwt\
            K1ND8o18Q3wr/UJ8K/0dbW2VamtrAQAAAP//AwDHAhygPQAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.592Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8d297306aeea324b87ef494954016fba
      _order: 0
      cache: {}
      request:
        bodySize: 164
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "164"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 248
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteIdentification {
              	site {
              		siteID
              		productSubscription {
              			license {
              				hashedKey
              			}
              		}
              	}
              }
            variables: {}
        queryString:
          - name: SiteIdentification
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteIdentification
      response:
        bodySize: 212
        content:
          encoding: base64
          mimeType: application/json
          size: 212
          text: "[\"H4sIAAAAAAAAAzTLsQ6CMBCA4Xe52YX2rgVmF+PI4HztXaWJAdKWwRDf3WDiv/zTd4BwY\
            xgPqLnp/7crjDCte4n6LLzNDw1wga2sssc27aHGkreW1+UErxx1qT87c51V7vqGEYbo\
            u9AZm/okmgxi70QZlZzzqNEaJOMNReocCdkgiCk4j4btwJwIPmdfAAAA//8DABj2u36\
            gAAAA\"]"
          textDecoded:
            data:
              site:
                productSubscription:
                  license:
                    hashedKey: 9c71b123f8fdef24486dea4e56674ec32452725c5165d53bd44fb6742a39aaf5
                siteID: SourcegraphWeb
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.555Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b584bf96a3d88ab96114e5cbea1e4bca
      _order: 0
      cache: {}
      request:
        bodySize: 164
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "164"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 332
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteIdentification {
              	site {
              		siteID
              		productSubscription {
              			license {
              				hashedKey
              			}
              		}
              	}
              }
            variables: {}
        queryString:
          - name: SiteIdentification
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteIdentification
      response:
        bodySize: 212
        content:
          encoding: base64
          mimeType: application/json
          size: 212
          text: "[\"H4sIAAAAAAAAAzTLsQ6CMBCA4Xe52YX2rgVmF+PI4HztXaWJAdKWwRDf3WDiv/zTd4BwY\
            xgPqLnp/7crjDCte4n6LLzNDw1wga2sssc27aHGkreW1+UErxx1qT87c51V7vqGEYbo\
            u9AZm/okmgxi70QZlZzzqNEaJOMNReocCdkgiCk4j4btwJwIPmdfAAAA//8DABj2u36\
            gAAAA\"]"
          textDecoded:
            data:
              site:
                productSubscription:
                  license:
                    hashedKey: 9c71b123f8fdef24486dea4e56674ec32452725c5165d53bd44fb6742a39aaf5
                siteID: SourcegraphWeb
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:48.350Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 203c1896021c3a09dfe619120ea1b725
      _order: 0
      cache: {}
      request:
        bodySize: 101
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "101"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 248
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteProductVersion {
                  site {
                      productVersion
                  }
              }
            variables: {}
        queryString:
          - name: SiteProductVersion
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteProductVersion
      response:
        bodySize: 139
        content:
          encoding: base64
          mimeType: application/json
          size: 139
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdEFRfkppcklYalFxZn5eUpWSkbm5pbm\
            BvFGBkYmugZmuoaG8aZ6JrqJRobJZimWpolGSQZKtbW1AAAAAP//AwCfPZebSQAAAA==\
            \"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:47 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.736Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2aa42833ae189b030c5bc322f1d27b0c
      _order: 0
      cache: {}
      request:
        bodySize: 101
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "101"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 332
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteProductVersion {
                  site {
                      productVersion
                  }
              }
            variables: {}
        queryString:
          - name: SiteProductVersion
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteProductVersion
      response:
        bodySize: 139
        content:
          encoding: base64
          mimeType: application/json
          size: 139
          text: "[\"H4sIAAAAAAAAA6pWSkks\",\"SVSyqlYqzixJBdEFRfkppcklYalFxZn5eUpWSkbm5pbm\
            BvFGBkYmugZmuoaG8aZ6JrqJRobJZimWpolGSQZKtbW1AAAAAP//AwCfPZebSQAAAA==\
            \"]"
        cookies: []
        headers:
          - name: date
            value: Wed, 12 Jun 2024 00:40:48 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1333
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-12T00:40:47.929Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
  pages: []
  version: "1.2"
