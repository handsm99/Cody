log:
  _recordingName: chat-response-quality
  creator:
    comment: persister:fs
    name: Polly.JS
    version: 6.0.6
  entries:
    - _id: 437826e5a4fb43497da382e960767f26
      _order: 0
      cache: {}
      request:
        bodySize: 5434
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1d0970288a1b486f8bb4a639b096db62-077b52b402191d5d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What code do
                  you have access to?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 11341
        content:
          mimeType: text/event-stream
          size: 11341
          text: >+
            event: completion

            data: {"completion":"Based on the README.md file provided, I have access to the codebase and information about the Zoekt text search engine project, which is a fork of the original Google Zoekt project and is now the main maintained source of Zoekt. The README.md file provides instructions for downloading, indexing, and searching using Zoekt, as well as information about the project's features, installation, and acknowledgements.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:41:54 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "15"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1405
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:41:53.099Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0fe0417403e7c1ed95fba9f75619781c
      _order: 0
      cache: {}
      request:
        bodySize: 5210
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ce819854d8baf1c29af1fd19395bbef6-84c9c83b4cd074d6-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do slices
                  work in go?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 163892
        content:
          mimeType: text/event-stream
          size: 163892
          text: >+
            event: completion

            data: {"completion":"Slices in Go are a powerful data structure that provide a flexible way to work with collections of elements. Here are some key points about how slices work in Go:\n\n1. **Underlying Array**: Slices are built on top of an underlying array. They provide a view into a section of that array.\n\n2. **Length and Capacity**: Each slice has a length, which represents the number of elements it contains, and a capacity, which represents the total number of elements the underlying array can hold.\n\n3. **Slice Expressions**: Slices are created using slice expressions, which allow you to create a new slice from an existing array, slice, or string. The syntax is `array[start:end]`, where `start` is the index where the slice begins (inclusive) and `end` is the index where the slice ends (exclusive).\n\n4. **Zero Value**: The zero value of a slice is `nil`, which means the slice has a length and capacity of 0.\n\n5. **Append and Grow**: The built-in `append` function allows you to add elements to the end of a slice. If the underlying array doesn't have enough capacity, a new, larger array will be allocated, and the elements will be copied over.\n\n6. **Sharing Underlying Array**: When you create a new slice from an existing one, they share the same underlying array. Modifying one slice can affect the other.\n\n7. **Slicing and Copying**: You can create a new slice that references a different section of the underlying array using slicing. You can also create a new slice by copying the elements from another slice using the `copy` function.\n\n8. **Memory Allocation**: Slices are lightweight, as they don't allocate new memory for the elements they contain. Instead, they reference the underlying array, which is where the data is stored.\n\nUnderstanding how slices work in Go is crucial for writing efficient and effective Go code. They provide a flexible and powerful way to work with collections of data.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:41:55 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "13"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1405
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:41:54.812Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c9bbfbb3816ea696bce23fdf14618dad
      _order: 0
      cache: {}
      request:
        bodySize: 5225
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-38133865cefcb1445c9b59545af49591-2266fd2600f4e7b0-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Question:
                  what does this regex do? 

                  /a|e|i|o|u/
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 39256
        content:
          mimeType: text/event-stream
          size: 39256
          text: >+
            event: completion

            data: {"completion":"The provided regular expression `/a|e|i|o|u/` is a character class that matches any of the vowels: \"a\", \"e\", \"i\", \"o\", or \"u\".\n\nHere's a breakdown of how this regex works:\n\n1. The pipe operator `|` is used to create an alternation, which allows the regex to match any of the characters listed.\n2. The characters `a`, `e`, `i`, `o`, and `u` are the individual characters that the regex will match.\n\nThis regex is commonly used for tasks such as:\n\n- Validating if a character is a vowel in a word or string.\n- Extracting all the vowels from a given text.\n- Performing text processing operations that require identifying vowels.\n\nFor example, if you had the string \"Hello World\", this regex would match the vowels \"e\", \"o\", and \"o\" from the input.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:41:59 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "9"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1404
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:41:58.690Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b5425ebf66b4db25db73de678a72c827
      _order: 0
      cache: {}
      request:
        bodySize: 5222
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-de8f3f5be4af05207c2c588cf1dc28d2-e3f7d91fdd74a0f4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: style css
                  checkbox using light purple"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 145812
        content:
          mimeType: text/event-stream
          size: 145812
          text: >+
            event: completion

            data: {"completion":"To style a CSS checkbox using a light purple color, you can use the following code:\n\n```css\n/* Checkbox container */\n.checkbox-container {\n  display: block;\n  position: relative;\n  padding-left: 30px;\n  cursor: pointer;\n  font-size: 16px;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n}\n\n/* Hide the default checkbox */\n.checkbox-container input {\n  position: absolute;\n  opacity: 0;\n  cursor: pointer;\n  height: 0;\n  width: 0;\n}\n\n/* Custom checkbox */\n.checkmark {\n  position: absolute;\n  top: 0;\n  left: 0;\n  height: 20px;\n  width: 20px;\n  background-color: #f1f1f1;\n  border-radius: 3px;\n}\n\n/* When the checkbox is checked, add a light purple background */\n.checkbox-container input:checked ~ .checkmark {\n  background-color: #d8ccf1;\n}\n\n/* Create the checkmark/indicator (hidden when not checked) */\n.checkmark:after {\n  content: \"\";\n  position: absolute;\n  display: none;\n}\n\n/* Show the checkmark when checked */\n.checkbox-container input:checked ~ .checkmark:after {\n  display: block;\n}\n\n/* Style the checkmark/indicator */\n.checkbox-container .checkmark:after {\n  left: 6px;\n  top: 2px;\n  width: 5px;\n  height: 10px;\n  border: solid white;\n  border-width: 0 3px 3px 0;\n  -webkit-transform: rotate(45deg);\n  -ms-transform: rotate(45deg);\n  transform: rotate(45deg);\n}\n```\n\nYou can apply this CSS to your checkbox elements by adding the following HTML structure:\n\n```html\n\u003clabel class=\"checkbox-container\"\u003e\n  Checkbox Label\n  \u003cinput type=\"checkbox\" checked\u003e\n  \u003cspan class=\"checkmark\"\u003e\u003c/span\u003e\n\u003c/label\u003e\n```\n\nThis will create a custom checkbox with a light purple appearance when checked.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:02 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "7"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1404
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:00.921Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 6187da28c4e986c488d9b6cb3873df4d
      _order: 0
      cache: {}
      request:
        bodySize: 5219
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ed6e55364f47bb22b896be357279f50b-639a142a6b296c3c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how to
                  upgrade my  python version?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 162378
        content:
          mimeType: text/event-stream
          size: 162378
          text: >+
            event: completion

            data: {"completion":"The provided codebase context does not contain any information about upgrading a Python version. The code snippets provided are in Go and Markdown, not Python. To upgrade your Python version, you would need to look for information specific to your operating system and Python installation. Some general steps to upgrade Python:\n\n1. **Check your current Python version**: Open a terminal or command prompt and run `python --version` to see which version of Python you currently have installed.\n\n2. **Identify the latest Python version**: Visit the official Python website (https://www.python.org/) to check the latest stable version of Python.\n\n3. **Uninstall the old version (optional)**: If you want to completely remove the old version of Python, you can uninstall it. The steps to do this will depend on your operating system.\n\n4. **Install the new version**: The installation process will vary depending on your operating system:\n   - **Windows**: Download the Python installer from the Python website and run it. Follow the on-screen instructions to complete the installation.\n   - **macOS**: Download the Python installer from the Python website and run it. Alternatively, you can use a package manager like Homebrew to install Python.\n   - **Linux**: The steps will depend on your Linux distribution. You can often use your distribution's package manager (e.g., `apt`, `yum`, `dnf`) to install the new Python version.\n\n5. **Verify the installation**: After the installation is complete, open a terminal or command prompt and run `python --version` again to confirm that the new version of Python is installed.\n\nRemember that the provided codebase context does not contain any information about upgrading Python, as it is focused on Go and Markdown files. For specific guidance on upgrading Python for your project or environment, you may need to consult additional resources or documentation.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:05 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "3"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1404
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:04.763Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0ee6edebdb40296315edaf6d7643b3cb
      _order: 0
      cache: {}
      request:
        bodySize: 4894
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-2224c2798e3ff52ccd23c2c2ef962759-afba8ee930c0553e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  this repo do??"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 69992
        content:
          mimeType: text/event-stream
          size: 69992
          text: >+
            event: completion

            data: {"completion":"Based on the code provided, this seems to be a part of the Zoekt codebase, which is likely a code search tool or platform. The main functionalities that can be inferred from this code are:\n\n1. `SortAndTruncateFiles`: This function sorts a list of `FileMatch` objects and then truncates the list based on the search options provided, such as the maximum number of documents and matches to display.\n\n2. `DisplayTruncator`: This is a higher-order function that returns another function, which can be used to truncate the list of `FileMatch` objects based on the specified limits in the search options. It handles truncating both the number of documents and the number of matches within each document.\n\n3. `limitChunkMatches` and `limitLineMatches`: These are helper functions used by the `DisplayTruncator` to limit the number of chunk matches and line matches, respectively, within each `FileMatch` object.\n\nOverall, this codebase seems to be responsible for managing the display of search results, ensuring that the number of documents and matches shown to the user are within the specified limits, and truncating the data accordingly.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:09 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:08.231Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 4272e7a2567707da64e88a2b214689b1
      _order: 0
      cache: {}
      request:
        bodySize: 10182
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-9990749a83f769e15590789fcc0c1c34-f03d2474db1ed76f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: describe my
                  code"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 134494
        content:
          mimeType: text/event-stream
          size: 134494
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the code you have shared appears to be part of the `zoekt` package, which is a fast text search engine intended for use with source code.\n\nThe main functions and types in the code are:\n\n1. `SortAndTruncateFiles`: This function takes a slice of `FileMatch` and an `SearchOptions` struct, sorts the `FileMatch` slice, and then truncates it based on the limits specified in the `SearchOptions`.\n\n2. `DisplayTruncator`: This is a function type that represents a stateful function that enforces document and match display limits by truncating and mutating the input `FileMatch` slice. The `NewDisplayTruncator` function returns a `DisplayTruncator` and a boolean indicating whether there are any limits to enforce.\n\n3. `limitMatches`: This function takes a slice of `FileMatch`, a limit integer, and a boolean indicating whether to chunk the matches. It then calls either `limitChunkMatches` or `limitLineMatches` to limit the number of matches in each `FileMatch`.\n\n4. `limitChunkMatches`: This function takes a `FileMatch` and a limit integer, and truncates the `ChunkMatches` field of the `FileMatch` to the specified limit. It also updates the `Content` field of the `ChunkMatch` to remove the excess lines.\n\n5. `limitLineMatches`: This function takes a `FileMatch` and a limit integer, and truncates the `LineFragments` field of the `LineMatches` in the `FileMatch` to the specified limit.\n\nThe overall purpose of this code appears to be managing the display of search results in the `zoekt` search engine, ensuring that the number of documents and matches shown to the user does not exceed the specified limits.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:12 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:11.085Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a120c7dc23e976e5023c8c45c034ffb4
      _order: 0
      cache: {}
      request:
        bodySize: 5209
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-40d3647986e7f6f6070c7d824bdebb94-0a46bff4c3eea77e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: @zoekt
                  describe my code."
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 12845
        content:
          mimeType: text/event-stream
          size: 12845
          text: >+
            event: completion

            data: {"completion":"Unfortunately, I don't see any code labeled \"zoekt\" in the provided codebase context. The code snippets you shared are from various Go files, including `watcher.go`, `README.md`, `limit.go`, and `chunker_test.go`. Without more information about the specific \"zoekt\" code you're asking about, I can't provide a detailed description. If you could point me to the relevant code, I'd be happy to take a closer look and provide an overview.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:16 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:15.000Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b744a91b6bd3efc55d846cb72a629f92
      _order: 0
      cache: {}
      request:
        bodySize: 5207
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-96569798142dd782ea6bbad0e4c97a35-999756666f888940-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: is my code
                  base clean?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 137638
        content:
          mimeType: text/event-stream
          size: 137638
          text: >+
            event: completion

            data: {"completion":"Based on the limited codebase context provided, I don't have enough information to comprehensively evaluate the overall cleanliness of your codebase. The code snippets you shared appear to be isolated portions without the full context of the project structure, dependencies, test coverage, and other aspects that would be necessary to make a thorough assessment.\n\nSome observations I can make from the provided snippets:\n\n1. `watcher.go`:\n   - The commented-out code suggests there may be an active development or refactoring process happening in this file.\n   - Without seeing the rest of the file, it's difficult to comment on the overall code quality and adherence to best practices.\n\n2. `README.md`:\n   - The provided README content is very minimal, which may indicate a lack of comprehensive project documentation.\n\n3. `limit.go`:\n   - This file contains a commented-out function, which raises questions about its current usage and whether it's being actively maintained.\n\n4. `chunker_test.go`:\n   - The test file appears to be well-structured and comprehensive, which is a positive sign for code quality and testing practices.\n\nTo provide a more complete assessment of your codebase's cleanliness, I would need access to the full project structure, a broader set of source files, information about the project's age and development lifecycle, and any relevant documentation or guidelines followed by the development team.\n\nWithout a more comprehensive view of the codebase, I cannot confidently determine whether it is \"clean\" or not. I'd be happy to re-evaluate the codebase if you can provide additional context and information.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:17 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:16.741Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 09462119fa8f6b1a482b7347dc028121
      _order: 0
      cache: {}
      request:
        bodySize: 10173
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-308c250887085c78c5576ee5609fe245-2f9ee3c66f8ffea0-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  directory watcher do?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 77751
        content:
          mimeType: text/event-stream
          size: 77751
          text: >+
            event: completion

            data: {"completion":"Based on the codebase context provided, the `DirectoryWatcher` appears to be a component that watches a directory for changes and updates the corresponding search index.\n\nThe `newDirectoryWatcher` function initializes a new `DirectoryWatcher` struct, which contains the following fields:\n\n- `dir`: the directory to watch\n- `timestamps`: a map to store the last modification times of files in the directory\n- `loader`: a `shardLoader` function to load the search index\n- `ready`: a channel to signal when the watcher is ready\n- `quit`: a channel to signal when the watcher should stop\n- `stopped`: a channel to signal when the watcher has stopped\n\nThe function also starts a goroutine that calls two methods:\n\n1. `scan()`: This method scans the directory and updates the `timestamps` map with the last modification times of the files.\n2. `watch()`: This method watches the directory for changes and updates the search index accordingly.\n\nThe `DirectoryWatcher` is likely used as part of a larger system that indexes files for a search engine, such as the Zoekt search engine mentioned in the README.md context. The watcher ensures that the search index is kept up-to-date with changes in the file system.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:20.052Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 72faa6da0149a5045d42bacef2f64d07
      _order: 0
      cache: {}
      request:
        bodySize: 10175
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a6bf7632578cf4c8d7c99a4d515d31a2-561d72aaab851367-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: where do we
                  test the grpc chunker"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 19069
        content:
          mimeType: text/event-stream
          size: 19069
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the grpc chunker is tested in the file `chunker_test.go` within the `grpc/chunk` directory.\n\nThe file `chunker_test.go` contains a test function `TestChunkerE2E` that tests the end-to-end behavior of the chunker. It sets up a test gRPC server, creates a client, and then sends a streaming output call to the server, verifying that the number of messages received and the total payload size match the expected values.\n\nSo the grpc chunker functionality is tested in the `TestChunkerE2E` test case within the `chunker_test.go` file.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:24 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:23.106Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f3cc802773a00db037f8f7cec255ba19
      _order: 0
      cache: {}
      request:
        bodySize: 10072
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a9fb63e73dbdd3093ed24755940b7b2e-c698dfb1c25d5c36-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Can you look
                  through the files and identify the conflicting packages that
                  may be causing this?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 54604
        content:
          mimeType: text/event-stream
          size: 54604
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, there doesn't seem to be any obvious conflicts between packages. The code appears to be a part of the `zoekt` package, which is a fast text search engine for source code.\n\nThe `limit.go` file contains functions related to sorting and truncating search results based on the specified search options. This is a common functionality in a search engine to ensure that the number of results displayed to the user is within the desired limits.\n\nThere is no mention of any conflicting packages or dependencies in the provided context. The code appears to be self-contained within the `zoekt` package and does not seem to be importing or depending on any external packages that could potentially cause conflicts.\n\nWithout more information about the overall codebase structure, build process, or any specific errors or issues you are facing, I cannot identify any conflicting packages that may be causing problems. The provided code appears to be well-structured and consistent within the `zoekt` package.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:26 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:25.142Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f6bcd41f3e0789cd57e5e60baeff8648
      _order: 0
      cache: {}
      request:
        bodySize: 10214
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-60d57238067c556d0aa970d82ab5e44c-9c3be339014f9f71-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Mind taking a
                  second look at the file? @limit.go"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 140432
        content:
          mimeType: text/event-stream
          size: 140432
          text: >+
            event: completion

            data: {"completion":"Sure, let me take a closer look at the `limit.go` file:\n\n1. **SortAndTruncateFiles**: This function first sorts the list of `FileMatch` objects, and then applies a `DisplayTruncator` to truncate the results based on the search options.\n\n2. **DisplayTruncator**: This is a stateful function that enforces the `MaxDocDisplayCount` and `MaxMatchDisplayCount` limits from the `SearchOptions`. It returns a function that, when called, will truncate the input list of `FileMatch` objects and return a new list along with a boolean indicating if there are more results available.\n\n3. **NewDisplayTruncator**: This function creates a `DisplayTruncator` function based on the limits specified in the `SearchOptions`. If there are no limits to enforce, it returns a pass-through function.\n\n4. **limitMatches**: This function is responsible for truncating the `ChunkMatches` or `LineMatches` within each `FileMatch` object, based on the specified limits. It uses either `limitChunkMatches` or `limitLineMatches` to perform the actual truncation.\n\n5. **limitChunkMatches**: This function truncates the `Ranges`, `SymbolInfo`, and `Content` fields of a `ChunkMatch` object when the number of `Ranges` exceeds the limit. It does this by removing the last N lines from the `Content` field, where N is the difference between the line number of the end of the old last `Range` and that of the new last `Range`.\n\n6. **limitLineMatches**: This function truncates the `LineFragments` within a `LineMatch` object when the number of `LineFragments` exceeds the limit.\n\nOverall, this code is responsible for ensuring that the search results returned by Zoekt do not exceed the specified display limits, both in terms of the number of files and the number of matches within each file.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:28 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:27.749Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9a446990d13bbcc43ff325f6103ac039
      _order: 0
      cache: {}
      request:
        bodySize: 10020
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0964acb48b21be50808ac205149d243e-1e1232a9aeda2338-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Why does this
                  project use the MIT license?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 7910
        content:
          mimeType: text/event-stream
          size: 7910
          text: >+
            event: completion

            data: {"completion":"The provided codebase context does not mention anything about the license used for this project. The README.md file does not contain any information about the license. Without any explicit mention of the license in the codebase context, I cannot determine why this project uses the MIT license. The license information is not provided in the given context.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:32 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:31.732Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7b91594eae4babf54f466fe7186b5956
      _order: 0
      cache: {}
      request:
        bodySize: 10025
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-904f2922ad4f87b561982ab90f867186-669451f8a3147c96-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: See zoekt
                  repo find location of tensor function"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 14603
        content:
          mimeType: text/event-stream
          size: 14603
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, there does not appear to be a \"tensor\" function defined in the code. The codebase seems to be related to a text search engine called \"Zoekt\", and the code in the `limit.go` file is responsible for sorting and truncating search results based on certain limits defined in the `SearchOptions` struct.\n\nThe codebase does not contain any references to a \"tensor\" function, so I cannot determine its location within the provided context.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:34 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:33.315Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: e83ced7fea2e2f123f2b6769af4212ba
      _order: 0
      cache: {}
      request:
        bodySize: 10222
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1d8994d058b8cc2ca4042bc2d7dafa56-45f5735864fad901-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Explain the
                  logic in src/agent.go, particularly how agents interact with
                  ranking"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 12799
        content:
          mimeType: text/event-stream
          size: 12799
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the code context provided does not include the `src/agent.go` file. The code snippets provided are from the `watcher.go`, `README.md`, and `limit.go` files, as well as a test file `chunker_test.go`. Without access to the `agent.go` file, I cannot explain the logic and how agents interact with ranking. If you could provide the context from the `agent.go` file, I would be happy to review and explain the relevant logic.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:36 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:35.258Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 40f20276755130e7175337a64f301c6a
      _order: 0
      cache: {}
      request:
        bodySize: 5420
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8058e3c09dd7cb10817b3d392e322265-3b2d37bbae09fbbb-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain
                  @README.md"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 159584
        content:
          mimeType: text/event-stream
          size: 159584
          text: >+
            event: completion

            data: {"completion":"Based on the README.md file provided, here's an overview of the Zoekt project:\n\n1. **Introduction**:\n   - Zoekt is a fast text search engine, primarily intended for searching through source code.\n   - The project is a fork of the original Zoekt repository (github.com/google/zoekt) maintained by Sourcegraph.\n\n2. **Installation and Usage**:\n   - The README covers instructions for downloading, indexing, and searching using Zoekt.\n   - It provides steps for indexing directories, Git repositories, and Repo repositories.\n   - It also explains how to use the web interface, JSON API, and command-line interface for searching.\n   - There are example configurations for setting up Zoekt as a systemd service on a Linux server.\n\n3. **Search Service**:\n   - Zoekt comes with a service management program called `zoekt-indexserver` that can automatically mirror and index repositories from GitHub and Gitiles.\n   - This service takes care of fetching, indexing, and maintaining the search index.\n\n4. **Symbol Search**:\n   - The README recommends installing Universal ctags to improve the ranking of search results.\n\n5. **Acknowledgements**:\n   - The README acknowledges the original creators of Zoekt, Han-Wen Nienhuys and Alexander Neubeck.\n\n6. **Fork Details**:\n   - This section explains the differences between the Sourcegraph fork and the original Google/Zoekt repository.\n   - The key changes include a Sourcegraph-specific indexing command, exposing the API, and adding support for symbol/ctag searches.\n\n7. **Disclaimer**:\n   - This is not an official Google product.\n\nIn summary, the README provides a comprehensive overview of the Zoekt project, its installation and usage, the search service, and the differences between the Sourcegraph fork and the original repository.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:38 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:37.091Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: e241de71f1215ebf2231fe3c296d5f99
      _order: 0
      cache: {}
      request:
        bodySize: 11887
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cb26914515d75fc9ee21286149069965-e2ea84f242a2fd2c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  Based on the README.md file provided, here's an overview of
                  the Zoekt project:


                  1. **Introduction**:
                     - Zoekt is a fast text search engine, primarily intended for searching through source code.
                     - The project is a fork of the original Zoekt repository (github.com/google/zoekt) maintained by Sourcegraph.

                  2. **Installation and Usage**:
                     - The README covers instructions for downloading, indexing, and searching using Zoekt.
                     - It provides steps for indexing directories, Git repositories, and Repo repositories.
                     - It also explains how to use the web interface, JSON API, and command-line interface for searching.
                     - There are example configurations for setting up Zoekt as a systemd service on a Linux server.

                  3. **Search Service**:
                     - Zoekt comes with a service management program called `zoekt-indexserver` that can automatically mirror and index repositories from GitHub and Gitiles.
                     - This service takes care of fetching, indexing, and maintaining the search index.

                  4. **Symbol Search**:
                     - The README recommends installing Universal ctags to improve the ranking of search results.

                  5. **Acknowledgements**:
                     - The README acknowledges the original creators of Zoekt, Han-Wen Nienhuys and Alexander Neubeck.

                  6. **Fork Details**:
                     - This section explains the differences between the Sourcegraph fork and the original Google/Zoekt repository.
                     - The key changes include a Sourcegraph-specific indexing command, exposing the API, and adding support for symbol/ctag searches.

                  7. **Disclaimer**:
                     - This is not an official Google product.

                  In summary, the README provides a comprehensive overview of the Zoekt project, its installation and usage, the search service, and the differences between the Sourcegraph fork and the original repository.
              - speaker: human
                text: "You have access to the provided codebase context. Question: what does
                  @limit.go do?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 150609
        content:
          mimeType: text/event-stream
          size: 150609
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file in the Zoekt codebase provides functionality to sort and truncate the search results based on the specified search options.\n\nHere's a summary of the key components and their functionality:\n\n1. `SortAndTruncateFiles`:\n   - This is a convenience function that takes a slice of `FileMatch` and the search options.\n   - It first sorts the `FileMatch` slice, and then truncates it based on the search options, using the `NewDisplayTruncator` function.\n\n2. `DisplayTruncator`:\n   - This is a type that represents a stateful function, which enforces document and match display limits by truncating and mutating the input `FileMatch` slice.\n   - The `NewDisplayTruncator` function returns a `DisplayTruncator` function that enforces the limits specified in the search options.\n\n3. `limitMatches`:\n   - This function is responsible for limiting the number of matches (either chunk matches or line matches) in each `FileMatch` based on the specified limit.\n   - It uses either `limitChunkMatches` or `limitLineMatches` to perform the actual truncation.\n\n4. `limitChunkMatches`:\n   - This function limits the number of `ChunkMatches` in a `FileMatch` by truncating the `Ranges`, `SymbolInfo`, and `Content` fields.\n   - It ensures that the truncation is done correctly, considering the presence of context lines and multiline ranges.\n\n5. `limitLineMatches`:\n   - This function limits the number of `LineMatches` in a `FileMatch` by truncating the `LineFragments` field.\n\nIn summary, the `limit.go` file provides the necessary functionality to sort and truncate the search results based on the specified search options, ensuring that the returned data adheres to the defined display limits.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:42 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:41.288Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9ed6b2d3563207e049554dc5854ce05c
      _order: 0
      cache: {}
      request:
        bodySize: 5208
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-84f788a0275b4761146fcf6f2ca4903f-f967e085119dc5b7-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do
                  goroutines work?"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 165544
        content:
          mimeType: text/event-stream
          size: 165544
          text: >+
            event: completion

            data: {"completion":"The provided codebase context doesn't contain any direct information about how goroutines work. However, based on my general knowledge of Go programming, I can provide the following overview of how goroutines work:\n\nGoroutines are lightweight threads of execution in the Go programming language. They are similar to threads, but much more lightweight and efficient. Unlike traditional threads, which are managed by the operating system, goroutines are managed by the Go runtime.\n\nThe key features of goroutines include:\n\n1. **Concurrency**: Goroutines allow Go programs to have multiple tasks running concurrently, which can improve performance and responsiveness.\n\n2. **Lightweight**: Goroutines have a small memory footprint compared to traditional threads, and they can be created and destroyed quickly.\n\n3. **Scheduling**: The Go runtime is responsible for scheduling goroutines, which means it decides when and how long each goroutine should run.\n\n4. **Communication**: Goroutines can communicate with each other using channels, which are a built-in mechanism for passing data between goroutines.\n\n5. **Synchronization**: Go provides various synchronization primitives, such as mutexes and wait groups, to help coordinate the execution of goroutines.\n\nIn the provided codebase context, there are some comments that suggest the use of goroutines, such as the `go func()` block in the `newDirectoryWatcher` function. This indicates that the codebase likely uses goroutines to perform certain tasks concurrently, such as scanning and watching directories for changes.\n\nHowever, without more context from the rest of the codebase, I can't provide specific details on how goroutines are used in this project. The general principles of how goroutines work, as described above, should still be applicable.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:46 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:45.604Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 31fbbd6b3b5479c5aecaa606ac679e3f
      _order: 0
      cache: {}
      request:
        bodySize: 7131
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-5bb3981f1edce675eac89b5f3d7c6392-e9df8f61715ec38d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: >-
                  The provided codebase context doesn't contain any direct
                  information about how goroutines work. However, based on my
                  general knowledge of Go programming, I can provide the
                  following overview of how goroutines work:


                  Goroutines are lightweight threads of execution in the Go programming language. They are similar to threads, but much more lightweight and efficient. Unlike traditional threads, which are managed by the operating system, goroutines are managed by the Go runtime.


                  The key features of goroutines include:


                  1. **Concurrency**: Goroutines allow Go programs to have multiple tasks running concurrently, which can improve performance and responsiveness.


                  2. **Lightweight**: Goroutines have a small memory footprint compared to traditional threads, and they can be created and destroyed quickly.


                  3. **Scheduling**: The Go runtime is responsible for scheduling goroutines, which means it decides when and how long each goroutine should run.


                  4. **Communication**: Goroutines can communicate with each other using channels, which are a built-in mechanism for passing data between goroutines.


                  5. **Synchronization**: Go provides various synchronization primitives, such as mutexes and wait groups, to help coordinate the execution of goroutines.


                  In the provided codebase context, there are some comments that suggest the use of goroutines, such as the `go func()` block in the `newDirectoryWatcher` function. This indicates that the codebase likely uses goroutines to perform certain tasks concurrently, such as scanning and watching directories for changes.


                  However, without more context from the rest of the codebase, I can't provide specific details on how goroutines are used in this project. The general principles of how goroutines work, as described above, should still be applicable.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain how
                  they relate to wait groups"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 141199
        content:
          mimeType: text/event-stream
          size: 141199
          text: >+
            event: completion

            data: {"completion":"Based on the codebase context provided, there are no direct references to wait groups. The codebase context includes:\n\n1. `watcher.go`: This file contains a function `newDirectoryWatcher` that creates a new `DirectoryWatcher` struct and starts a goroutine to scan and watch a directory. However, there is no mention of wait groups in this file.\n\n2. `README.md`: This file only contains a brief description of the project and does not mention anything about wait groups.\n\n3. `limit.go`: This file contains a function `SortAndTruncateFiles` that sorts and truncates a list of `FileMatch` objects, but does not use any wait groups.\n\n4. `chunker_test.go`: This file contains a test case for the `ChunkerE2E` function, which tests the end-to-end behavior of a gRPC chunker. Again, there is no mention of wait groups in this file.\n\nWithout any direct references to wait groups in the provided codebase context, I cannot explain how they are used in this specific project. Wait groups are a synchronization primitive in Go that allow you to wait for a collection of goroutines to finish executing before continuing. They are often used when you need to coordinate the execution of multiple goroutines.\n\nIf this codebase did use wait groups, they could be used to ensure that all goroutines spawned by the `newDirectoryWatcher` function have completed before the function returns. This could help ensure that the directory scanning and watching operations are properly set up before the function returns.\n\nHowever, based solely on the provided codebase context, I cannot make any definitive statements about how wait groups (or any other synchronization mechanisms) are used in this project. More context from the broader codebase would be needed to provide a more detailed explanation.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:50 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:49.616Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: cf8c221abaa9970dde8bcc75cb9b4870
      _order: 0
      cache: {}
      request:
        bodySize: 5435
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-09c42d35becb49e231f7a10d627229da-1bfde164adc87af8-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What code do
                  you have access to?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 69394
        content:
          mimeType: text/event-stream
          size: 69394
          text: >+
            event: completion

            data: {"completion":"Based on the README file provided, this repository contains the source code for Zoekt, a fast text search engine intended for use with source code. Some key components and entry points mentioned are:\n\n- `cmd/zoekt-index` - Command to index a directory\n- `cmd/zoekt-git-index` - Command to index a Git repository\n- `cmd/zoekt-repo-index` - Command to index multiple Git repositories\n- `cmd/zoekt-webserver` - Runs the Zoekt web server to serve search requests\n- `cmd/zoekt` - Command line interface for searching\n- `cmd/zoekt-indexserver` - Service management program to mirror and index repositories\n\nThe README indicates this is a fork of the original google/zoekt repository, now being maintained by Sourcegraph. It has some Sourcegraph-specific changes like `zoekt-sourcegraph-indexserver` to index all Sourcegraph repositories.\n\nSo in summary, I have access to the Go source code for the various Zoekt components that handle indexing source code, running the web server, CLI search, and managing the backend indexing services. However, the actual implementation details are not provided in just the README file.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:45 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:43.910Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b21806e22dfa1e8286fe068bf6463f1a
      _order: 0
      cache: {}
      request:
        bodySize: 5211
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1dd3f18c4a2f883d233228e92740b29c-7f1d8d843ac37e91-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do slices
                  work in go?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 214652
        content:
          mimeType: text/event-stream
          size: 214652
          text: >+
            event: completion

            data: {"completion":"In Go, slices are reference types that provide a way to work with arrays in a more flexible and efficient manner. Here's how they work:\n\n1. **Underlying Array**: A slice is a data structure that references an underlying array. It consists of three components: a pointer to the array, a length, and a capacity.\n\n2. **Length and Capacity**: The length of a slice is the number of elements it contains, while the capacity is the maximum number of elements it can hold before it needs to be reallocated. The capacity is always greater than or equal to the length.\n\n3. **Creating Slices**: You can create a slice using the built-in `make` function or by slicing an existing array or slice. For example:\n\n   ```go\n   // Creating a slice with a length of 3 and a capacity of 5\n   slice1 := make([]int, 3, 5)\n\n   // Creating a slice from an array\n   arr := [5]int{1, 2, 3, 4, 5}\n   slice2 := arr[1:4] // slice2 = [2, 3, 4]\n   ```\n\n4. **Modifying Slices**: Since slices are reference types, modifying the elements of a slice modifies the underlying array. If you need to create a new array, you can use the built-in `copy` function or create a new slice using the slice expression.\n\n5. **Appending Elements**: Go provides the `append` function to add new elements to a slice. If the capacity of the underlying array is not sufficient, a new array is allocated, and the existing elements are copied over.\n\n6. **Nil Slices**: An uninitialized slice has a value of `nil`, which has a length and capacity of 0. You can check if a slice is `nil` using the comparison operator.\n\n7. **Slice Expressions**: Go supports slice expressions that allow you to create new slices from existing ones. For example, `slice[low:high:max]` creates a new slice starting at index `low` up to (but not including) index `high`, with a maximum capacity of `max`.\n\nSlices in Go are powerful and efficient data structures that provide a convenient way to work with arrays. They are widely used throughout the Go standard library and in many Go programs.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:52 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:50.548Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7cc20b131c1c6e1047f98502dce3cdee
      _order: 0
      cache: {}
      request:
        bodySize: 5226
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-c4f1273e82d05f2fb5ed55e78a5dbf7a-748ad3692f35603c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Question:
                  what does this regex do? 

                  /a|e|i|o|u/
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 44667
        content:
          mimeType: text/event-stream
          size: 44667
          text: >+
            event: completion

            data: {"completion":"The regular expression `/a|e|i|o|u/` is a pattern that matches any single character that is a vowel (either `a`, `e`, `i`, `o`, or `u`).\n\nThe `|` symbol in a regular expression is used for alternation, meaning it will match any one of the alternatives listed. So, this pattern will match the letter `a`, or the letter `e`, or the letter `i`, or the letter `o`, or the letter `u`.\n\nThis regular expression can be useful for tasks like finding or replacing vowels in a string, or for validating if a string contains vowels or not.\n\nNote that this pattern is case-sensitive, meaning it will only match lowercase vowels. To make it case-insensitive, you can use either the `i` flag (e.g., `/a|e|i|o|u/i`) or include both lowercase and uppercase versions of the vowels in the pattern (e.g., `/a|e|i|o|u|A|E|I|O|U/`).","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:02 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:00.554Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ed752cfdbb6fdb4333f329c74d3bf21c
      _order: 0
      cache: {}
      request:
        bodySize: 5223
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-edff4acb41d1aad499a9fc6b9b888687-d6f79eb75da2b329-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: style css
                  checkbox using light purple"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 97073
        content:
          mimeType: text/event-stream
          size: 97073
          text: >+
            event: completion

            data: {"completion":"Since this is a Go/Golang codebase and it doesn't seem to have any CSS or HTML files, I cannot provide a specific example of styling a CSS checkbox using light purple color. However, here's a general CSS snippet that you can use to style a checkbox with a light purple color:\n\n```css\n/* Change the color of the checkbox itself */\ninput[type=\"checkbox\"] {\n  appearance: none;\n  -webkit-appearance: none;\n  -moz-appearance: none;\n  width: 16px;\n  height: 16px;\n  border: 2px solid #a88be8; /* Light purple color */\n  border-radius: 3px;\n  outline: none;\n  transition: border-color 0.2s ease-in-out;\n}\n\n/* Change the color of the checkbox when checked */\ninput[type=\"checkbox\"]:checked {\n  background-color: #a88be8; /* Light purple color */\n  border-color: #a88be8; /* Light purple color */\n}\n\n/* Change the color of the checkbox when focused */\ninput[type=\"checkbox\"]:focus {\n  border-color: #7b5bba; /* Darker shade of purple */\n}\n```\n\nTo use this CSS, you need to have an HTML element with a checkbox input:\n\n```html\n\u003cinput type=\"checkbox\" id=\"my-checkbox\" /\u003e\n\u003clabel for=\"my-checkbox\"\u003eMy Checkbox\u003c/label\u003e\n```\n\nThis will style the checkbox with a light purple border and background color when checked. You can adjust the color values (`#a88be8` and `#7b5bba`) to your desired shades of purple.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:07 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:05.961Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 87f1e566989288ea4d8691b70a5c2a0d
      _order: 0
      cache: {}
      request:
        bodySize: 5220
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8db46c262bd10bbf8d67e2566ea4e990-e2cf29eabff31248-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how to
                  upgrade my  python version?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 178572
        content:
          mimeType: text/event-stream
          size: 178572
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code snippets do not contain any information related to upgrading Python versions. The code appears to be written in Go and does not reference Python at all.\n\nTo upgrade your Python version, the process depends on your operating system and how you originally installed Python. Here are some general steps you can follow:\n\n1. **Identify your current Python version**: Open a terminal or command prompt and run `python --version` or `python3 --version`. This will tell you the currently installed Python version.\n\n2. **Check if a newer version is available**: Visit the official Python website (https://www.python.org/downloads/) and check for the latest stable release of Python.\n\n3. **Download the latest Python version**: On the Python downloads page, select the appropriate installer for your operating system (Windows, macOS, or Linux).\n\n4. **Run the installer**: Follow the instructions in the installer to upgrade or install the new Python version alongside your existing one. It's generally recommended to keep your existing Python installation and install the new version separately.\n\n5. **Update your system's PATH variable (Windows only)**: On Windows, you may need to add the new Python installation directory to your system's PATH variable to make the new Python version accessible from the command line.\n\n6. **Verify the installation**: After the installation is complete, open a new terminal or command prompt and run `python --version` or `python3 --version` again to verify that the new version is installed correctly.\n\nKeep in mind that upgrading Python may affect existing scripts or applications that rely on the previous version. It's a good practice to test your code with the new Python version and make any necessary updates or adjustments.\n\nIf you need more specific instructions or encounter any issues during the upgrade process, consult the official Python documentation or seek assistance from online resources or forums.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:13.397Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 76d99be873febaa6eb601a7afff4dcc9
      _order: 0
      cache: {}
      request:
        bodySize: 4895
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-3c4aa0e1fd74036cd2024e2626faaa13-ef08498afabfc287-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  this repo do??"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 146519
        content:
          mimeType: text/event-stream
          size: 146519
          text: >+
            event: completion

            data: {"completion":"Based on the code you provided, this appears to be part of the Zoekt repository, which is a fast text search engine focused on source code. \n\nThe code you shared seems to handle limiting and truncating the search results based on various options specified in the `SearchOptions` struct. Here's a breakdown of what the code does:\n\n1. `SortAndTruncateFiles` is a convenience function that sorts the `FileMatch` slice and then truncates it based on the search options using a `DisplayTruncator`.\n\n2. `DisplayTruncator` is a function type that takes a slice of `FileMatch` and returns a (potentially truncated) slice of `FileMatch` along with a boolean indicating if more results are available.\n\n3. `NewDisplayTruncator` creates a `DisplayTruncator` based on the `SearchOptions`. It enforces limits on the maximum number of documents and matches to display.\n\n4. `limitMatches` is a helper function that applies `limitChunkMatches` or `limitLineMatches` to each `FileMatch` in the slice, depending on the `ChunkMatches` option.\n\n5. `limitChunkMatches` truncates the `ChunkMatches` of a `FileMatch` based on the specified limit. It handles multiline ranges, context lines, and updates the `Content` field accordingly.\n\n6. `limitLineMatches` truncates the `LineMatches` of a `FileMatch` based on the specified limit.\n\nIn summary, this part of the Zoekt codebase seems to be responsible for post-processing search results by sorting, limiting, and truncating the matched files and their respective line/chunk matches according to the specified search options. This is likely done to ensure efficient transfer and display of search results, especially for large codebases.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:23 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:22.096Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 74f02ee84695526914c12a4b5d5d24eb
      _order: 0
      cache: {}
      request:
        bodySize: 10183
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-5c13858969278673fc2b9b92668629e7-ea061e716bcf5b11-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: describe my
                  code"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 136087
        content:
          mimeType: text/event-stream
          size: 136087
          text: >+
            event: completion

            data: {"completion":"The provided code is part of the Zoekt project, a fast text search engine intended for searching source code. The code specifically deals with limiting and truncating the search results based on certain options and limits.\n\nHere's a breakdown of the main components:\n\n1. `SortAndTruncateFiles` is a convenience function that sorts the `FileMatch` results and then truncates them based on the specified `SearchOptions`.\n\n2. `DisplayTruncator` is a stateful function type that enforces limits on the number of documents (files) and matches displayed. It returns a new slice of `FileMatch` and a boolean indicating if more results are available beyond the applied limits.\n\n3. `NewDisplayTruncator` creates a new `DisplayTruncator` based on the `SearchOptions`. It checks if any limits need to be enforced (`MaxDocDisplayCount` and `MaxMatchDisplayCount`) and returns a function that applies those limits.\n\n4. `limitMatches` is an internal function that iterates over the `FileMatch` results and applies the `MaxMatchDisplayCount` limit using either `limitChunkMatches` or `limitLineMatches` depending on the `ChunkMatches` option.\n\n5. `limitChunkMatches` and `limitLineMatches` are the functions that actually truncate the `ChunkMatches` and `LineMatches` respectively, based on the specified limit. They return the remaining limit after truncation.\n\nThe code appears to be focused on providing a way to limit the number of search results returned, both at the file level and the individual match level. This is likely done to avoid overwhelming the client with too many results, especially for large codebases.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:33 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:30.891Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7ecbdfeabcd3befe91c8ee7efa7f5ac6
      _order: 0
      cache: {}
      request:
        bodySize: 5210
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-bdb4904a65b0b744e0791a70134eb72d-149a7c22828085a8-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: @zoekt
                  describe my code."
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 62287
        content:
          mimeType: text/event-stream
          size: 62287
          text: >+
            event: completion

            data: {"completion":"Based on the provided code snippets, it seems that you are working on a project related to file watching, searching, and chunking data for efficient transmission over gRPC.\n\nThe `newDirectoryWatcher` function creates a `DirectoryWatcher` struct and starts a goroutine to scan and watch a given directory for changes. This functionality might be used for indexing or monitoring files in a specific directory.\n\nThe `SortAndTruncateFiles` function sorts and truncates a slice of `FileMatch` structs based on some search options. This could be part of a search or indexing system that needs to handle and process file data.\n\nThe `TestChunkerE2E` function is a test case for a chunker implementation used in gRPC streaming. It tests the chunking of data into multiple messages, ensuring that the maximum message size is not exceeded and that the original payload is correctly reassembled on the receiving end.\n\nOverall, it seems like your codebase is focused on building a system for indexing, searching, and efficiently transmitting file data, potentially using gRPC for communication between various components.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:42 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:39.957Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: f8960e56301fc5c26647067dbf200b80
      _order: 0
      cache: {}
      request:
        bodySize: 5208
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e97e1f8c1289f6b8f102f815d636306b-76dfcad8ecf6b415-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: is my code
                  base clean?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 229339
        content:
          mimeType: text/event-stream
          size: 229339
          text: >+
            event: completion

            data: {"completion":"Based on the limited code snippets provided, it's difficult to make a definitive assessment of the cleanliness of your entire codebase. However, I can share some observations about the code samples:\n\n1. **shards/watcher.go**: The code snippet shows the setup of a `DirectoryWatcher` struct and its related channels. The commented-out code seems to be a previous version or an example of what the final code could look like. While it's not necessarily a problem, it's generally better to remove commented-out code from the final codebase to maintain clarity.\n\n2. **README.md**: The README file is very minimal, containing only the string \"This is a readme\". A well-written README file is crucial for providing documentation and context about the project, its purpose, usage instructions, and any other relevant information.\n\n3. **limit.go**: The provided code snippet is a function that sorts and truncates a slice of `FileMatch` structs based on some options. The code appears clean and concise, but without more context, it's hard to assess its overall quality.\n\n4. **grpc/chunk/chunker_test.go**: This file contains a test case for a chunker implementation. The test case appears well-structured, with clear assertions and error handling. However, the use of hardcoded values like `maxMessageSize` makes it harder to understand the context and purpose of the test.\n\nOverall, based on these snippets, it's challenging to make a definitive assessment of the codebase's cleanliness. A clean codebase typically exhibits characteristics like:\n\n- Consistent coding style and formatting\n- Clear and descriptive variable and function names\n- Appropriate use of comments to explain non-trivial or complex logic\n- Separation of concerns and modular design\n- Comprehensive test coverage\n- Meaningful and up-to-date documentation (e.g., README files, code comments)\n\nTo better evaluate the cleanliness of your codebase, it would be helpful to have access to a more representative sample of the codebase, including its structure, organization, and any coding guidelines or conventions followed by the project.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:48 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:46.760Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 1387bde8be3b46d9c087c196c7d29e0b
      _order: 0
      cache: {}
      request:
        bodySize: 10174
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a45352f960731125118177ab242362ab-a738f8017493ab5e-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  directory watcher do?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 103493
        content:
          mimeType: text/event-stream
          size: 103493
          text: >+
            event: completion

            data: {"completion":"Based on the code snippet for `newDirectoryWatcher` in `shards/watcher.go`, it looks like the `DirectoryWatcher` is responsible for watching a directory for changes to files and loading/updating the search index accordingly.\n\nHere's a breakdown of what it does:\n\n1. It creates a new `DirectoryWatcher` struct with fields like `dir` (the directory to watch), `timestamps` (a map to track file modification times), `loader` (a `shardLoader` to load/update the search index), and channels for signaling when it's ready, when to quit, and when it has stopped.\n\n2. It starts a goroutine that does the following:\n   a. Calls `sw.scan()` to initially scan the directory and populate the `timestamps` map.\n   b. If `sw.scan()` returns an error, it sets `sw.readyErr` and returns.\n   c. Calls `sw.watch()` to start watching the directory for changes.\n   d. If `sw.watch()` returns an error, it sets `sw.readyErr` and returns.\n   e. Closes the `sw.ready` channel to signal that the initial scan and watch setup is complete.\n\n3. It returns the `DirectoryWatcher` instance.\n\nSo in summary, the `DirectoryWatcher` is responsible for monitoring a directory for file changes and keeping the search index up-to-date by loading/updating it via the provided `shardLoader`. It does an initial scan of the directory and then continuously watches for changes to reload/update the index as needed.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:44:59 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:44:57.766Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9cff38afbe26b6549723c23d48287894
      _order: 0
      cache: {}
      request:
        bodySize: 10176
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1895a738eacb87f1cdbf147fbaa6853b-509d411e46a6cb05-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: where do we
                  test the grpc chunker"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 37825
        content:
          mimeType: text/event-stream
          size: 37825
          text: >+
            event: completion

            data: {"completion":"Based on the provided code context, the gRPC chunker is tested in the `TestChunkerE2E` function in the `grpc/chunk/chunker_test.go` file. This test function sets up a gRPC server and client, sends a payload of a specified size through the streaming gRPC call, and verifies that the payload is correctly chunked into multiple messages and received on the other end.\n\nSpecifically, the test case creates a gRPC server instance, runs it, and creates a client connection to it. It then initiates a streaming gRPC call with a payload of a specified size (controlled by the `inputSizeBytes` variable in the test case). The test then receives the chunked messages from the server, counts the number of messages received, and verifies that the total size of the received payload matches the original input size. It also checks that each individual message is below the maximum message size limit.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:08 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:05.782Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8c88bc96bfd7f16aef6cf74fa3f2c27f
      _order: 0
      cache: {}
      request:
        bodySize: 10073
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b8cbf15ade79622e8d4b81d79327ff80-de10acc241557d5a-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Can you look
                  through the files and identify the conflicting packages that
                  may be causing this?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 23241
        content:
          mimeType: text/event-stream
          size: 23241
          text: >+
            event: completion

            data: {"completion":"Based on the provided context, there doesn't appear to be any conflicting packages mentioned. The code snippets provided are from the `zoekt` package, which seems to be the main package for the Zoekt search engine.\n\nThe `limit.go` file contains functions for sorting, truncating, and limiting the number of search results returned, based on the specified search options (e.g., `MaxDocDisplayCount`, `MaxMatchDisplayCount`).\n\nSince the question is about conflicting packages, and the provided context doesn't mention any specific issues related to that, I can't identify any conflicting packages from the given information.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:13 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:11.748Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9be4606d1e79b2dc23c3b60fd1ae77b0
      _order: 0
      cache: {}
      request:
        bodySize: 10215
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-242d6566ccc48d68ad1dd68bd3530165-4a3a647dbb3076e4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Mind taking a
                  second look at the file? @limit.go"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 135501
        content:
          mimeType: text/event-stream
          size: 135501
          text: >+
            event: completion

            data: {"completion":"Sure, let me take a closer look at the `limit.go` file.\n\nThis file contains functions related to limiting the number of search results displayed based on the specified options. Here's a breakdown of the main functions:\n\n1. `SortAndTruncateFiles` is a convenience function that sorts the `FileMatch` results and then applies the display limits using the `DisplayTruncator` function.\n\n2. `DisplayTruncator` is a type alias for a function that takes a slice of `FileMatch` and returns a truncated slice along with a boolean indicating if there are more results to be displayed. This function is stateful, and it applies the `MaxDocDisplayCount` and `MaxMatchDisplayCount` limits specified in the `SearchOptions`.\n\n3. `NewDisplayTruncator` is a factory function that returns a `DisplayTruncator` based on the provided `SearchOptions`. If no limits are specified, it returns a no-op function.\n\n4. `limitMatches` is a helper function that applies the `MaxMatchDisplayCount` limit to the `FileMatch` results. It calls either `limitChunkMatches` or `limitLineMatches` depending on the `ChunkMatches` option.\n\n5. `limitChunkMatches` truncates the `ChunkMatches` in each `FileMatch` based on the provided limit. It handles multiline ranges and adjusts the `Content` field accordingly.\n\n6. `limitLineMatches` truncates the `LineMatches` in each `FileMatch` based on the provided limit.\n\nOverall, this file provides functionality to limit the search results and ensure that the output doesn't exceed the specified display limits. The code seems to handle various edge cases, such as multiline ranges and adjusting the content accordingly.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:17 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:16.019Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: aa68bee3005297d2811d39dbdcafde7c
      _order: 0
      cache: {}
      request:
        bodySize: 10021
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cb2ebc04a94d8343bf7295ba86e5ed21-11755f301084c25b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Why does this
                  project use the MIT license?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 11052
        content:
          mimeType: text/event-stream
          size: 11052
          text: >+
            event: completion

            data: {"completion":"Unfortunately, the provided code context does not mention the license used by this project. The README file provides an overview of the Zoekt search engine project, its commands, installation instructions, and other details, but it does not specify the license. Without additional information in the codebase about the licensing, I cannot determine the reason why the MIT license was chosen for this project.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:26 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:24.669Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 20fa031a62ddc2e11ffd65da64a88a04
      _order: 0
      cache: {}
      request:
        bodySize: 10026
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-96113b438b66722d51011a98083939a4-1ccac7e7d8cf3d28-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: See zoekt
                  repo find location of tensor function"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 15149
        content:
          mimeType: text/event-stream
          size: 15149
          text: >+
            event: completion

            data: {"completion":"Unfortunately, there does not appear to be any mention of a \"tensor function\" in the provided code context. The code seems to be related to indexing and searching source code files, with functions like `SortAndTruncateFiles`, `NewDisplayTruncator`, `limitMatches`, `limitChunkMatches`, and `limitLineMatches`.\n\nWithout any additional context or clues about what the \"tensor function\" might be, I cannot locate its implementation within this codebase.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:29 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:27.972Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 88aaaea5fbdd518f45b2d709613a46f5
      _order: 0
      cache: {}
      request:
        bodySize: 10223
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a2684062cfc624a045b8c0504cf5e38d-8946759aacd390fa-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Explain the
                  logic in src/agent.go, particularly how agents interact with
                  ranking"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 9159
        content:
          mimeType: text/event-stream
          size: 9159
          text: >+
            event: completion

            data: {"completion":"Unfortunately, I don't have access to the `src/agent.go` file in the provided code context. The code snippets given are from different files like `shards/watcher.go`, `README.md`, `limit.go`, and `grpc/chunk/chunker_test.go`. Without the specific `src/agent.go` file, I cannot explain the logic related to how agents interact with ranking.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:33 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:31.722Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 79508f424c5a2c7ff17cff67cd448428
      _order: 0
      cache: {}
      request:
        bodySize: 5421
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-66cc1786983c14ba91d5d4de0387c214-c6c34787283e688d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain
                  @README.md"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 125941
        content:
          mimeType: text/event-stream
          size: 125941
          text: >+
            event: completion

            data: {"completion":"The `README.md` file provides an overview and instructions for using Zoekt, a fast text search engine intended for searching source code repositories. Here's a summary of the key sections:\n\n1. **Downloading**: It shows how to download the Zoekt source code using `go get`.\n\n2. **Indexing**: This section explains how to index different types of data sources:\n   - A directory using `zoekt-index`\n   - A Git repository using `zoekt-git-index`\n   - Multiple Git repositories using `zoekt-repo-index` and `zoekt-mirror-gitiles`\n\n3. **Searching**: It covers different ways to search the indexed data:\n   - Web interface using `zoekt-webserver`\n   - JSON API by sending GET requests to the webserver\n   - Command-line interface using `zoekt`\n\n4. **Installation**: It provides an example of setting up Zoekt as a systemd service on a Linux server.\n\n5. **Search Service**: This section describes `zoekt-indexserver`, a service management program that can mirror and index repositories from sources like GitHub, GitHub organizations, and Gitiles URLs.\n\n6. **Symbol Search**: It recommends installing Universal ctags to improve symbol search and ranking.\n\n7. **Acknowledgements**: Credits the original creators of Zoekt.\n\n8. **Fork Details**: Explains the differences between this fork (`sourcegraph/zoekt`) and the original `google/zoekt` repository, including Sourcegraph-specific changes and additions.\n\nThe `README.md` serves as a comprehensive guide for setting up, indexing, and searching with Zoekt, catering to various use cases and data sources.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:36 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:34.897Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 611b4f12bd6314ffca13c1fa6bd30b65
      _order: 0
      cache: {}
      request:
        bodySize: 11653
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-209da4ada65be851f03b2aed250adce6-f24e117cc8ed3ccf-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  The `README.md` file provides an overview and instructions for
                  using Zoekt, a fast text search engine intended for searching
                  source code repositories. Here's a summary of the key
                  sections:


                  1. **Downloading**: It shows how to download the Zoekt source code using `go get`.


                  2. **Indexing**: This section explains how to index different types of data sources:
                     - A directory using `zoekt-index`
                     - A Git repository using `zoekt-git-index`
                     - Multiple Git repositories using `zoekt-repo-index` and `zoekt-mirror-gitiles`

                  3. **Searching**: It covers different ways to search the indexed data:
                     - Web interface using `zoekt-webserver`
                     - JSON API by sending GET requests to the webserver
                     - Command-line interface using `zoekt`

                  4. **Installation**: It provides an example of setting up Zoekt as a systemd service on a Linux server.


                  5. **Search Service**: This section describes `zoekt-indexserver`, a service management program that can mirror and index repositories from sources like GitHub, GitHub organizations, and Gitiles URLs.


                  6. **Symbol Search**: It recommends installing Universal ctags to improve symbol search and ranking.


                  7. **Acknowledgements**: Credits the original creators of Zoekt.


                  8. **Fork Details**: Explains the differences between this fork (`sourcegraph/zoekt`) and the original `google/zoekt` repository, including Sourcegraph-specific changes and additions.


                  The `README.md` serves as a comprehensive guide for setting up, indexing, and searching with Zoekt, catering to various use cases and data sources.
              - speaker: human
                text: "You have access to the provided codebase context. Question: what does
                  @limit.go do?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 148298
        content:
          mimeType: text/event-stream
          size: 148298
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file contains utility functions for limiting and truncating the search results returned by Zoekt based on the configured options.\n\nSpecifically, it provides the following:\n\n1. `SortAndTruncateFiles` - This function sorts the `FileMatch` results and then applies the configured display limits using a `DisplayTruncator`.\n\n2. `DisplayTruncator` - This is a function type that takes a slice of `FileMatch` results as input and returns a truncated slice along with a boolean indicating if further truncation is needed. It enforces the configured limits on the maximum number of documents (`MaxDocDisplayCount`) and matches (`MaxMatchDisplayCount`) to be displayed.\n\n3. `NewDisplayTruncator` - This function returns a `DisplayTruncator` based on the provided `SearchOptions`. If no limits are configured, it returns a no-op truncator.\n\n4. `limitMatches` - This function applies the match limit (`MaxMatchDisplayCount`) to the `FileMatch` results. It can handle both line and chunk matches, depending on the `ChunkMatches` option.\n\n5. `limitChunkMatches` - This function limits the number of `ChunkMatches` in a `FileMatch`. It handles truncating the `Ranges`, `SymbolInfo`, and `Content` fields accordingly.\n\n6. `limitLineMatches` - This function limits the number of `LineMatches` in a `FileMatch` by truncating the `LineFragments` slice.\n\nIn summary, `limit.go` provides functionality to control the number of search results displayed to the user by enforcing configured limits on the maximum number of documents and matches. It handles both line-based and chunk-based (with context lines) match types, ensuring that the truncated results are consistent and meaningful.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:45 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:43.181Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 27a14713fd4a2722582fc19a622fccd6
      _order: 0
      cache: {}
      request:
        bodySize: 5209
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-53e1ce7ed4ae669b13746d28317095ed-a09b9549f314ef23-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do
                  goroutines work?"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 233935
        content:
          mimeType: text/event-stream
          size: 233935
          text: >+
            event: completion

            data: {"completion":"Goroutines are lightweight threads of execution in Go. They are managed by the Go runtime and are designed to be highly efficient and scalable. Here's how they work:\n\n1. **Creation**: Goroutines are created by prepending the `go` keyword before a function call. This tells the Go runtime to spawn a new goroutine and execute the function concurrently with the main program.\n\n2. **Scheduling**: The Go runtime manages a pool of goroutines and schedules them across available CPU cores using a sophisticated scheduler. The scheduler ensures fair distribution of CPU time among goroutines and automatically balances the load across available resources.\n\n3. **Context Switching**: When a goroutine is blocked (e.g., waiting for I/O or a channel operation), the Go scheduler can switch to another runnable goroutine, effectively multiplexing the available CPU cores among many goroutines. This context switching is lightweight and efficient, contributing to the high performance of Go programs.\n\n4. **Communication**: Goroutines communicate with each other primarily through channels. Channels provide a safe and efficient way to pass data between goroutines, eliminating the need for explicit locking or synchronization primitives in many cases.\n\n5. **Synchronization**: While channels provide a built-in synchronization mechanism, Go also offers other synchronization primitives like mutexes and wait groups for more complex scenarios.\n\n6. **Memory Management**: Goroutines share the same address space, but they have their own stack. The Go runtime manages the allocation and deallocation of stack memory for goroutines, ensuring efficient use of memory resources.\n\n7. **Concurrency and Parallelism**: Goroutines enable concurrent execution of code, but true parallelism (executing multiple computations simultaneously) depends on the availability of multiple CPU cores or processors. The Go runtime automatically maps goroutines to available CPU resources, allowing programs to take advantage of parallel hardware when available.\n\nGoroutines, combined with channels and other synchronization primitives, provide a powerful and idiomatic way to write concurrent and parallel programs in Go. The lightweight nature of goroutines and the efficient scheduling and memory management by the Go runtime make Go an excellent choice for building high-performance, scalable systems.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:46 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:44.903Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0bab5f971e6a305f09719e39c2d6d4f2
      _order: 0
      cache: {}
      request:
        bodySize: 7698
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8e98f9dd88d15c6df75bebe26872742f-69c7b31d1834c348-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: >-
                  Goroutines are lightweight threads of execution in Go. They
                  are managed by the Go runtime and are designed to be highly
                  efficient and scalable. Here's how they work:


                  1. **Creation**: Goroutines are created by prepending the `go` keyword before a function call. This tells the Go runtime to spawn a new goroutine and execute the function concurrently with the main program.


                  2. **Scheduling**: The Go runtime manages a pool of goroutines and schedules them across available CPU cores using a sophisticated scheduler. The scheduler ensures fair distribution of CPU time among goroutines and automatically balances the load across available resources.


                  3. **Context Switching**: When a goroutine is blocked (e.g., waiting for I/O or a channel operation), the Go scheduler can switch to another runnable goroutine, effectively multiplexing the available CPU cores among many goroutines. This context switching is lightweight and efficient, contributing to the high performance of Go programs.


                  4. **Communication**: Goroutines communicate with each other primarily through channels. Channels provide a safe and efficient way to pass data between goroutines, eliminating the need for explicit locking or synchronization primitives in many cases.


                  5. **Synchronization**: While channels provide a built-in synchronization mechanism, Go also offers other synchronization primitives like mutexes and wait groups for more complex scenarios.


                  6. **Memory Management**: Goroutines share the same address space, but they have their own stack. The Go runtime manages the allocation and deallocation of stack memory for goroutines, ensuring efficient use of memory resources.


                  7. **Concurrency and Parallelism**: Goroutines enable concurrent execution of code, but true parallelism (executing multiple computations simultaneously) depends on the availability of multiple CPU cores or processors. The Go runtime automatically maps goroutines to available CPU resources, allowing programs to take advantage of parallel hardware when available.


                  Goroutines, combined with channels and other synchronization primitives, provide a powerful and idiomatic way to write concurrent and parallel programs in Go. The lightweight nature of goroutines and the efficient scheduling and memory management by the Go runtime make Go an excellent choice for building high-performance, scalable systems.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain how
                  they relate to wait groups"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 303651
        content:
          mimeType: text/event-stream
          size: 303651
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, there is no direct reference to wait groups (`sync.WaitGroup`). However, the code snippets you provided offer some insight into related concepts.\n\nThe `newDirectoryWatcher` function appears to be starting a goroutine that performs some initialization tasks, such as scanning a directory and setting up a file watcher. The `ready` and `quit` channels are likely used for signaling when the initialization is complete or when the watcher should stop, respectively.\n\nWhile wait groups are not explicitly used in the provided code, they could be useful in this context to coordinate the main goroutine with the goroutine started by `newDirectoryWatcher`. For example, a wait group could be used to ensure that the main goroutine waits for the initialization goroutine to complete before proceeding further.\n\nHere's how you could potentially use a wait group in the `newDirectoryWatcher` function:\n\n```go\nfunc newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {\n    var wg sync.WaitGroup\n    sw := \u0026DirectoryWatcher{\n        dir:        dir,\n        timestamps: map[string]time.Time{},\n        loader:     loader,\n        ready:      make(chan struct{}),\n        quit:       make(chan struct{}),\n        stopped:    make(chan struct{}),\n    }\n\n    wg.Add(1)\n    go func() {\n        defer close(sw.ready)\n        defer wg.Done()\n\n        if err := sw.scan(); err != nil {\n            sw.readyErr = err\n            return\n        }\n\n        if err := sw.watch(); err != nil {\n            sw.readyErr = err\n            return\n        }\n    }()\n\n    // Wait for the initialization goroutine to complete\n    wg.Wait()\n\n    return sw, sw.readyErr\n}\n```\n\nIn this modified version, a `sync.WaitGroup` is created, and its `Add` method is called with a count of 1 before starting the goroutine. Inside the goroutine, `wg.Done()` is called before returning, signaling that the goroutine has completed its work. The main goroutine then calls `wg.Wait()` to block until the initialization goroutine is done.\n\nThis approach ensures that the `newDirectoryWatcher` function doesn't return until the initialization tasks are complete, and it provides a way to handle any errors that might occur during initialization.\n\nIt's worth noting that while wait groups can be useful in coordinating goroutines, they are not always necessary. In some cases, channels can be used for similar purposes, as demonstrated in the provided code snippets.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:45:56 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "593"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:54.815Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9ac6fe857a0f52d3587dfdcf2d23909f
      _order: 0
      cache: {}
      request:
        bodySize: 5213
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-838e7f126be75899f3f9f637f1e61cd3-22713acd8958466a-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do slices
                  work in go?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 120859
        content:
          mimeType: text/event-stream
          size: 120859
          text: >+
            event: completion

            data: {"completion":"I apologize, but the provided codebase context doesn't contain specific information about how slices work in Go. The code snippets provided are mostly related to other functionalities and don't directly explain slice behavior.\n\nHowever, I can provide you with a general explanation of how slices work in Go:\n\n1. Slices are dynamic, flexible views into arrays.\n\n2. They consist of three components:\n   - A pointer to the underlying array\n   - The length of the slice\n   - The capacity of the slice\n\n3. Slices are declared using the syntax: `[]T`, where T is the type of elements.\n\n4. You can create slices using:\n   - Slice literals: `s := []int{1, 2, 3}`\n   - Using make: `s := make([]int, length, capacity)`\n   - Slicing an existing array or slice: `s := arr[1:4]`\n\n5. Slices can be resized dynamically (up to their capacity) using the `append` function.\n\n6. When a slice's capacity is exceeded, Go automatically allocates a new, larger array and copies the data.\n\n7. Multiple slices can share the same underlying array, which allows for efficient memory usage.\n\n8. Modifying a slice modifies the underlying array, which can affect other slices sharing the same array.\n\nThis is a basic overview of how slices work in Go. If you need more specific information about slice usage in the context of this codebase, please let me know, and I'll try to find relevant examples if they exist in the provided snippets.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:01 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "588"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:45:59.909Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 6f4b602217304df50e2468ebbb324248
      _order: 0
      cache: {}
      request:
        bodySize: 5228
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-5a10fe544329459ce5bfc1f9efce2892-ee317439c367e484-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Question:
                  what does this regex do? 

                  /a|e|i|o|u/
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 72183
        content:
          mimeType: text/event-stream
          size: 72183
          text: >+
            event: completion

            data: {"completion":"The regex `/a|e|i|o|u/` is not specifically mentioned or used in the provided codebase context. However, I can explain what this regex does in general:\n\nThis regular expression matches any single vowel (lowercase) in the English alphabet. Here's a breakdown:\n\n- `/` at the beginning and end denotes the start and end of the regex pattern\n- `a|e|i|o|u` is a series of alternatives separated by the `|` (pipe) character\n- It will match either 'a' OR 'e' OR 'i' OR 'o' OR 'u'\n\nSo, this regex will match any single occurrence of a lowercase vowel in a given text. For example:\n- It would match the 'a' in \"cat\"\n- It would match the 'e' in \"bed\"\n- It would match the 'i' in \"sit\"\n- It would match the 'o' in \"dog\"\n- It would match the 'u' in \"sun\"\n\nIt's worth noting that this regex is case-sensitive and will not match uppercase vowels. If you wanted to match both uppercase and lowercase vowels, you would need to modify the regex to something like `/[aeiouAEIOU]/` or use a case-insensitive flag if supported by the regex engine you're using.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:07 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "581"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:06.367Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7d89c8f77e0276c3aa83594fd86846d3
      _order: 0
      cache: {}
      request:
        bodySize: 5225
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-55372eb2a59d73fdad0310bbcda63f8a-1345931253628e98-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: style css
                  checkbox using light purple"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 91335
        content:
          mimeType: text/event-stream
          size: 91335
          text: >+
            event: completion

            data: {"completion":"I apologize, but I don't see any CSS code or styling information in the provided codebase context. The snippets you've shared are primarily Go code and some Markdown, which don't contain any CSS styling for checkboxes.\n\nTo style a checkbox using light purple in CSS, you would typically do something like this:\n\n```css\ninput[type=\"checkbox\"] {\n  appearance: none;\n  width: 20px;\n  height: 20px;\n  border: 2px solid #e6e6fa; /* Light purple border */\n  border-radius: 3px;\n  background-color: #f8f8ff; /* Very light purple background */\n  outline: none;\n  cursor: pointer;\n}\n\ninput[type=\"checkbox\"]:checked {\n  background-color: #e6e6fa; /* Light purple when checked */\n  position: relative;\n}\n\ninput[type=\"checkbox\"]:checked::before {\n  content: '\\2714'; /* Checkmark */\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  transform: translate(-50%, -50%);\n  color: #483d8b; /* Darker purple for the checkmark */\n}\n```\n\nThis CSS would create a custom checkbox with a light purple theme. However, this is not related to the Go code or other context you've provided. If you have a specific question about the provided code or if you need help with a different aspect of the codebase, please let me know.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:13 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "576"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:11.489Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 00c1943bcd099f6dcc4ab0c1b19fd2e2
      _order: 0
      cache: {}
      request:
        bodySize: 5222
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-55432c1915b1b092d94f51331167c7bb-28b3dd8102f31d1f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how to
                  upgrade my  python version?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 67319
        content:
          mimeType: text/event-stream
          size: 67319
          text: >+
            event: completion

            data: {"completion":"I apologize, but I don't see any information in the provided codebase context about upgrading Python versions. The code snippets you've shared are primarily in Go and don't contain any information related to Python or version upgrades.\n\nThe codebase context you've provided includes:\n1. A Go file snippet for a directory watcher\n2. A brief README\n3. A Go file snippet for sorting and truncating files\n4. A Go test file for a gRPC chunker\n\nNone of these are related to Python or upgrading Python versions. \n\nIf you need help upgrading your Python version, I'd be happy to provide general advice, but it would not be based on the codebase context you've shared. Typically, upgrading Python involves:\n\n1. Visiting the official Python website (python.org)\n2. Downloading the latest version for your operating system\n3. Running the installer\n4. Updating your PATH environment variable if necessary\n\nHowever, the exact steps can vary depending on your operating system and current setup. If you need more specific help, please provide more details about your current Python version and operating system.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:18 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "570"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:17.297Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 762a1a1b56a8aa1ec631477ca8dea82f
      _order: 0
      cache: {}
      request:
        bodySize: 4897
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-3c5b0ee5a6c6afa68e31f029842f7959-f031055648f197dd-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  this repo do??"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 111802
        content:
          mimeType: text/event-stream
          size: 111802
          text: >+
            event: completion

            data: {"completion":"Based on the provided code snippet from the `limit.go` file, this repository appears to be part of a search engine or search-related tool called \"zoekt\". Here's what we can infer about its functionality:\n\n1. It deals with search results, particularly file matches and their display.\n\n2. It provides functionality to sort and truncate search results based on certain criteria and limits.\n\n3. The code implements various limits on the display of search results, including:\n   - A maximum number of documents to display (`MaxDocDisplayCount`)\n   - A maximum number of matches to display (`MaxMatchDisplayCount`)\n\n4. It can handle two types of matches:\n   - Chunk matches: Matches that span multiple lines or have context\n   - Line matches: Matches that are line-based\n\n5. The code includes functions to limit the number of matches displayed, either by limiting chunk matches or line matches.\n\n6. It has the ability to truncate content in chunk matches to fit within the specified limits.\n\n7. The code seems to be designed to work with a larger search system, providing helper functions to process and format search results for display.\n\nIn summary, this repository likely contains code for a search engine or search tool, with this particular file focusing on managing and limiting the display of search results. The name \"zoekt\" suggests it might be related to a search functionality, possibly in a larger development or code search context.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:23 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "566"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:22.151Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 294891c8b52eb044847766b7a2fd8bb8
      _order: 0
      cache: {}
      request:
        bodySize: 32163
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-689358b6d32ca1c016a4715ae30d2e4d-00c09a6143e0ec71-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: describe my
                  code"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 118817
        content:
          mimeType: text/event-stream
          size: 118817
          text: >+
            event: completion

            data: {"completion":"Based on the provided code snippets, it appears you are working with a codebase for a search engine called Zoekt. Here's a summary of what I can see:\n\n1. The codebase is written in Go.\n\n2. It includes functionality for indexing and searching through source code repositories.\n\n3. The search functionality supports various query types, including regular expressions, substring matches, and file name searches.\n\n4. It has features for handling multiple repositories, branches, and languages.\n\n5. The search process involves building and evaluating match trees, which are data structures used to efficiently find matches in the indexed data.\n\n6. There's support for limiting the number of matches returned and truncating results.\n\n7. The codebase includes performance optimization features, such as simplifying queries and pruning match trees.\n\n8. It has a concept of \"shards\" for distributing the search across multiple units of data.\n\n9. The search results can include file matches, line matches, and chunk matches, depending on the search options.\n\n10. There's support for different scoring methods, including an experimental BM25 scoring option.\n\n11. The codebase includes functionality for listing repositories based on search criteria.\n\n12. It has detailed statistics tracking for search operations.\n\nThis appears to be a sophisticated search engine designed specifically for searching through source code repositories, with features tailored to that use case.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:30 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "560"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:28.203Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0e083ccbc7c4a22da0c1a3f682c30229
      _order: 0
      cache: {}
      request:
        bodySize: 5212
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-7271cc5a5002ea6f0352da4282fcc5a3-1ddb8c744a25adda-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: @zoekt
                  describe my code."
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 153059
        content:
          mimeType: text/event-stream
          size: 153059
          text: >+
            event: completion

            data: {"completion":"Based on the provided code snippets, I can describe the following aspects of your codebase:\n\n1. Directory Watcher:\n   - There's a `DirectoryWatcher` struct implementation in `shards/watcher.go`.\n   - It watches a specified directory for changes.\n   - It uses channels for synchronization (`ready`, `quit`, `stopped`).\n   - It has a method to scan the directory and another to watch for changes.\n\n2. File Sorting and Truncation:\n   - In `limit.go`, there's a function `SortAndTruncateFiles` that sorts and potentially truncates a list of `FileMatch` objects based on given search options.\n\n3. gRPC Chunker:\n   - In `grpc/chunk/chunker_test.go`, there's a test suite for a gRPC streaming implementation.\n   - It tests different scenarios for streaming output, including normal payload and empty payload cases.\n   - The tests ensure that large payloads are correctly chunked into smaller messages that don't exceed a maximum size.\n\n4. General Structure:\n   - The codebase seems to be written in Go.\n   - It appears to be related to search functionality, possibly for a code search tool like Sourcegraph.\n   - There's evidence of using gRPC for communication.\n\n5. Testing:\n   - The codebase includes unit tests, particularly for the gRPC chunking functionality.\n\n6. Documentation:\n   - There's a README.md file, but the provided snippet doesn't contain much information.\n\nOverall, this seems to be a Go codebase for a system that involves file watching, search result processing, and gRPC-based data streaming, possibly as part of a larger code search or analysis tool.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:37 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "552"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:36.000Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 62dd6f8e1bd8895d812eef65f7ba1b7d
      _order: 0
      cache: {}
      request:
        bodySize: 5210
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-812c88a786845a2a66d6a89c99ec9e50-35d9c35ec9e54b7d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: is my code
                  base clean?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 194487
        content:
          mimeType: text/event-stream
          size: 194487
          text: >+
            event: completion

            data: {"completion":"Based on the limited code snippets provided, it's difficult to make a comprehensive assessment of the entire codebase's cleanliness. However, I can provide some observations on the code samples you've shared:\n\n1. The code in `watcher.go` appears to be reasonably structured, with clear variable naming and separation of concerns. It uses goroutines for concurrent operations, which is a good practice in Go.\n\n2. The `README.md` file is extremely minimal. A more comprehensive README would typically be considered better practice, as it helps other developers understand the project.\n\n3. The `limit.go` snippet is too short to draw many conclusions, but the function name `SortAndTruncateFiles` is descriptive of its purpose.\n\n4. The test file `chunker_test.go` shows good testing practices:\n   - It uses table-driven tests, which is a common and clean way to structure tests in Go.\n   - The test cases have descriptive names.\n   - It uses subtests, which allows for better organization and more granular test running.\n   - It employs cleanup functions to ensure resources are properly managed.\n   - The assertions use the `require` package, which is generally preferred over `assert` for its fail-fast behavior.\n\nOverall, the code snippets you've provided show some good practices, particularly in the test file. However, to truly assess if a codebase is \"clean,\" we'd need to look at more factors such as:\n\n- Consistent coding style across files\n- Proper error handling\n- Good documentation and comments\n- Efficient algorithms and data structures\n- Adherence to SOLID principles\n- Absence of code duplication\n- Proper use of packages and modules\n\nWithout seeing more of the codebase, it's not possible to make a definitive judgment on its overall cleanliness. The samples provided do show some good practices, but a comprehensive review would be needed for a full assessment.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:45 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "544"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:44.012Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: c2f0fe8b0bf5c08ee488650d72c38613
      _order: 0
      cache: {}
      request:
        bodySize: 10176
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-d35376f68f63b4bbe12a537a91a1b3ff-742cf8e67a3432f2-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  directory watcher do?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 112679
        content:
          mimeType: text/event-stream
          size: 112679
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, specifically from the `shards/watcher.go` file, the directory watcher appears to be responsible for monitoring a specified directory for changes. Here's what we can infer about its functionality:\n\n1. It's implemented as a `DirectoryWatcher` struct, which is created by the `newDirectoryWatcher` function.\n\n2. The watcher keeps track of file timestamps in the specified directory.\n\n3. It has a `scan` method that likely scans the directory initially to build its internal state.\n\n4. It has a `watch` method that presumably sets up continuous monitoring of the directory for changes.\n\n5. The watcher runs asynchronously in a separate goroutine, as evidenced by the `go func()` block in the `newDirectoryWatcher` function.\n\n6. It provides a way to signal when it's ready and when it encounters errors during initialization.\n\n7. It has channels for quitting and signaling when it has stopped.\n\n8. It uses a `shardLoader`, which suggests it might be related to loading shards (possibly for the search functionality mentioned in other parts of the codebase).\n\nThe main purpose of this directory watcher seems to be to monitor a specific directory, likely for changes in search index shards or other relevant files, and to trigger appropriate actions (such as reloading) when changes are detected.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:46:54 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "535"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:52.609Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9aa621eb51a4b78145e258705fbc9f24
      _order: 0
      cache: {}
      request:
        bodySize: 10178
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-859a7c17543c104568894b725a2e9ccd-da7f196f48c61b0a-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: where do we
                  test the grpc chunker"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 60193
        content:
          mimeType: text/event-stream
          size: 60193
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, the gRPC chunker is tested in the file `grpc/chunk/chunker_test.go`. Specifically, there's a test function called `TestChunkerE2E` that performs end-to-end testing of the chunker functionality.\n\nThe test function includes multiple test cases that check different scenarios:\n\n1. A \"normal\" case where the input size is 3.5 times the `maxMessageSize`, expecting 4 messages to be sent.\n2. An \"empty payload\" case where the input size is 0 bytes, expecting 1 message to be sent.\n\nEach test case sets up a gRPC server and client, sends a request with a payload of the specified size, and then receives the chunked responses. The test verifies:\n\n- The number of messages received matches the expected count.\n- The size of each received message is less than the `maxMessageSize`.\n- The total size of the received payload matches the input size.\n\nThis test ensures that the chunker correctly splits large payloads into smaller chunks for transmission over gRPC, and that these chunks can be reassembled correctly on the receiving end.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:00 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "529"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:46:59.152Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: dfccf59a18316fedebb3a016c9ef780b
      _order: 0
      cache: {}
      request:
        bodySize: 10075
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8790a29d626aba50650bfd0168d21adf-fb56ea14182f6290-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Can you look
                  through the files and identify the conflicting packages that
                  may be causing this?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 48998
        content:
          mimeType: text/event-stream
          size: 48998
          text: >+
            event: completion

            data: {"completion":"I apologize for the confusion, but after carefully examining the provided codebase context, I don't see any conflicting packages that could be causing an issue. Both files (README.md and limit.go) seem to be part of the same project (Zoekt) and there are no apparent package conflicts.\n\nThe README.md file is a markdown file containing project information and instructions, while limit.go is a Go source file that belongs to the `zoekt` package.\n\nThe limit.go file defines several functions and types related to truncating and limiting search results, which appears to be a normal part of the Zoekt search engine's functionality.\n\nIf you're experiencing a specific issue or error related to conflicting packages, it would be helpful if you could provide more information about the problem you're encountering. Without additional context about a specific error or conflict, I cannot identify any package conflicts based solely on the provided files.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:05 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "524"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:03.904Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d6a379dd7b9be404aec9a4935518280d
      _order: 0
      cache: {}
      request:
        bodySize: 32195
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e7d1979a70aa7dd869d287fdc646abbe-839cb42d9051efa2-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Mind taking a
                  second look at the file? @limit.go"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 113768
        content:
          mimeType: text/event-stream
          size: 113768
          text: >+
            event: completion

            data: {"completion":"Certainly! Let me review the `limit.go` file for you.\n\nThe `limit.go` file contains several important functions related to limiting and truncating search results in the Zoekt search engine. Here's a summary of the key components:\n\n1. `SortAndTruncateFiles`: A convenience function that sorts and truncates file matches based on search options.\n\n2. `DisplayTruncator`: A type definition for a function that enforces document and match display limits.\n\n3. `NewDisplayTruncator`: Creates a new DisplayTruncator based on the provided search options.\n\n4. `limitMatches`: Applies limits to the number of matches in files.\n\n5. `limitChunkMatches`: Limits the number of ChunkMatches in a given FileMatch.\n\n6. `limitLineMatches`: Limits the number of LineMatches in a given FileMatch.\n\nThe file focuses on implementing various limiting mechanisms to control the amount of data returned in search results. This is important for performance and resource management, especially when dealing with large codebases or numerous search results.\n\nThe code handles both chunk-based and line-based matches, allowing for flexibility in how search results are presented. It also takes care to properly truncate content and adjust related metadata (like symbol information) when applying limits.\n\nIs there any specific aspect of this file you'd like me to elaborate on?","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:10 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "520"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:07.975Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 6e2d2384ae3e62ce8987306903328eb5
      _order: 0
      cache: {}
      request:
        bodySize: 10023
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-29d5e506861476bc4efdc5c2a2fd1ad4-a5c072e781866f8b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Why does this
                  project use the MIT license?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 10341
        content:
          mimeType: text/event-stream
          size: 10341
          text: >+
            event: completion

            data: {"completion":"I apologize, but there is no information provided in the given codebase context about the project's license. The README.md file and the limit.go file do not mention any licensing information. To accurately answer why this project uses the MIT license, we would need to see the project's LICENSE file or any explicit mention of licensing in the provided documentation, which is not present in the given context.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:17 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "512"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:15.505Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 406b805a186294724d517e5bd2a5d993
      _order: 0
      cache: {}
      request:
        bodySize: 32006
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cc5eb88b75f1200bffd1d68cd71a94ba-d500c4f9bce8da95-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file eval.go:

                  ```go

                  // Copyright 2016 Google Inc. All rights reserved.

                  //

                  // Licensed under the Apache License, Version 2.0 (the "License");

                  // you may not use this file except in compliance with the License.

                  // You may obtain a copy of the License at

                  //

                  //    http://www.apache.org/licenses/LICENSE-2.0

                  //

                  // Unless required by applicable law or agreed to in writing, software

                  // distributed under the License is distributed on an "AS IS" BASIS,

                  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

                  // See the License for the specific language governing permissions and

                  // limitations under the License.


                  package zoekt


                  import (
                  	"context"
                  	"fmt"
                  	"log"
                  	"regexp/syntax"
                  	"sort"
                  	"strings"
                  	"time"

                  	enry_data "github.com/go-enry/go-enry/v2/data"
                  	"github.com/grafana/regexp"

                  	"github.com/sourcegraph/zoekt/query"
                  )


                  // simplifyMultiRepo takes a query and a predicate. It returns Const(true) if all

                  // repository names fulfill the predicate, Const(false) if none of them do, and q

                  // otherwise.

                  func (d *indexData) simplifyMultiRepo(q query.Q, predicate func(*Repository) bool) query.Q {
                  	count := 0
                  	alive := len(d.repoMetaData)
                  	for i := range d.repoMetaData {
                  		if d.repoMetaData[i].Tombstone {
                  			alive--
                  		} else if predicate(&d.repoMetaData[i]) {
                  			count++
                  		}
                  	}
                  	if count == alive {
                  		return &query.Const{Value: true}
                  	}
                  	if count > 0 {
                  		return q
                  	}
                  	return &query.Const{Value: false}
                  }


                  func (d *indexData) simplify(in query.Q) query.Q {
                  	eval := query.Map(in, func(q query.Q) query.Q {
                  		switch r := q.(type) {
                  		case *query.Repo:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.RepoRegexp:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Regexp.MatchString(repo.Name)
                  			})
                  		case *query.BranchesRepos:
                  			for i := range d.repoMetaData {
                  				for _, br := range r.List {
                  					if br.Repos.Contains(d.repoMetaData[i].ID) {
                  						return q
                  					}
                  				}
                  			}
                  			return &query.Const{Value: false}
                  		case *query.RepoSet:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Set[repo.Name]
                  			})
                  		case *query.RepoIDs:
                  			return d.simplifyMultiRepo(q, func(repo *Repository) bool {
                  				return r.Repos.Contains(repo.ID)
                  			})
                  		case *query.Language:
                  			_, has := d.metaData.LanguageMap[r.Language]
                  			if !has && d.metaData.IndexFeatureVersion < 12 {
                  				// For index files that haven't been re-indexed by go-enry,
                  				// fall back to file-based matching and continue even if this
                  				// repo doesn't have the specific language present.
                  				extsForLang := enry_data.ExtensionsByLanguage[r.Language]
                  				if extsForLang != nil {
                  					extFrags := make([]string, 0, len(extsForLang))
                  					for _, ext := range extsForLang {
                  						extFrags = append(extFrags, regexp.QuoteMeta(ext))
                  					}
                  					if len(extFrags) > 0 {
                  						pattern := fmt.Sprintf("(?i)(%s)$", strings.Join(extFrags, "|"))
                  						// inlined copy of query.regexpQuery
                  						re, err := syntax.Parse(pattern, syntax.Perl)
                  						if err != nil {
                  							return &query.Const{Value: false}
                  						}
                  						if re.Op == syntax.OpLiteral {
                  							return &query.Substring{
                  								Pattern:  string(re.Rune),
                  								FileName: true,
                  							}
                  						}
                  						return &query.Regexp{
                  							Regexp:   re,
                  							FileName: true,
                  						}
                  					}
                  				}
                  			}
                  			if !has {
                  				return &query.Const{Value: false}
                  			}
                  		}
                  		return q
                  	})
                  	return query.Simplify(eval)
                  }


                  func (o *SearchOptions) SetDefaults() {
                  	if o.ShardMaxMatchCount == 0 {
                  		// We cap the total number of matches, so overly broad
                  		// searches don't crash the machine.
                  		o.ShardMaxMatchCount = 100000
                  	}
                  	if o.TotalMaxMatchCount == 0 {
                  		o.TotalMaxMatchCount = 10 * o.ShardMaxMatchCount
                  	}
                  }


                  func (d *indexData) Search(ctx context.Context, q query.Q, opts *SearchOptions) (sr *SearchResult, err error) {
                  	timer := newTimer()

                  	copyOpts := *opts
                  	opts = &copyOpts
                  	opts.SetDefaults()

                  	var res SearchResult
                  	if len(d.fileNameIndex) == 0 {
                  		return &res, nil
                  	}

                  	select {
                  	case <-ctx.Done():
                  		res.Stats.ShardsSkipped++
                  		return &res, nil
                  	default:
                  	}

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok && !c.Value {
                  		return &res, nil
                  	}

                  	if opts.EstimateDocCount {
                  		res.Stats.ShardFilesConsidered = len(d.fileBranchMasks)
                  		return &res, nil
                  	}

                  	q = query.Map(q, query.ExpandFileContent)

                  	mt, err := d.newMatchTree(q, matchTreeOpt{})
                  	if err != nil {
                  		return nil, err
                  	}

                  	// Capture the costs of construction before pruning
                  	updateMatchTreeStats(mt, &res.Stats)

                  	mt, err = pruneMatchTree(mt)
                  	if err != nil {
                  		return nil, err
                  	}
                  	res.Stats.MatchTreeConstruction = timer.Elapsed()
                  	if mt == nil {
                  		res.Stats.ShardsSkippedFilter++
                  		return &res, nil
                  	}

                  	res.Stats.ShardsScanned++

                  	cp := &contentProvider{
                  		id:    d,
                  		stats: &res.Stats,
                  	}

                  	// Track the number of documents found in a repository for
                  	// ShardRepoMaxMatchCount
                  	var (
                  		lastRepoID     uint16
                  		repoMatchCount int
                  	)

                  	docCount := uint32(len(d.fileBranchMasks))
                  	lastDoc := int(-1)

                  nextFileMatch:
                  	for {
                  		canceled := false
                  		select {
                  		case <-ctx.Done():
                  			canceled = true
                  		default:
                  		}

                  		nextDoc := mt.nextDoc()
                  		if int(nextDoc) <= lastDoc {
                  			nextDoc = uint32(lastDoc + 1)
                  		}

                  		for ; nextDoc < docCount; nextDoc++ {
                  			repoID := d.repos[nextDoc]
                  			repoMetadata := &d.repoMetaData[repoID]

                  			// Skip tombstoned repositories
                  			if repoMetadata.Tombstone {
                  				continue
                  			}

                  			// Skip documents that are tombstoned
                  			if len(repoMetadata.FileTombstones) > 0 {
                  				if _, tombstoned := repoMetadata.FileTombstones[string(d.fileName(nextDoc))]; tombstoned {
                  					continue
                  				}
                  			}

                  			// Skip documents over ShardRepoMaxMatchCount if specified.
                  			if opts.ShardRepoMaxMatchCount > 0 {
                  				if repoMatchCount >= opts.ShardRepoMaxMatchCount && repoID == lastRepoID {
                  					res.Stats.FilesSkipped++
                  					continue
                  				}
                  			}

                  			break
                  		}

                  		if nextDoc >= docCount {
                  			break
                  		}

                  		lastDoc = int(nextDoc)

                  		// We track lastRepoID for ShardRepoMaxMatchCount
                  		if lastRepoID != d.repos[nextDoc] {
                  			lastRepoID = d.repos[nextDoc]
                  			repoMatchCount = 0
                  		}

                  		if canceled || (res.Stats.MatchCount >= opts.ShardMaxMatchCount && opts.ShardMaxMatchCount > 0) {
                  			res.Stats.FilesSkipped += int(docCount - nextDoc)
                  			break
                  		}

                  		res.Stats.FilesConsidered++
                  		mt.prepare(nextDoc)

                  		cp.setDocument(nextDoc)

                  		known := make(map[matchTree]bool)
                  		md := d.repoMetaData[d.repos[nextDoc]]

                  		for cost := costMin; cost <= costMax; cost++ {
                  			switch evalMatchTree(cp, cost, known, mt) {
                  			case matchesRequiresHigherCost:
                  				if cost == costMax {
                  					log.Panicf("did not decide. Repo %s, doc %d, known %v",
                  						md.Name, nextDoc, known)
                  				}
                  			case matchesFound:
                  				// could short-circuit now, but we want to run higher costs to
                  				// potentially find higher ranked matches.
                  			case matchesNone:
                  				continue nextFileMatch
                  			}
                  		}

                  		fileMatch := FileMatch{
                  			Repository:         md.Name,
                  			RepositoryID:       md.ID,
                  			RepositoryPriority: md.priority,
                  			FileName:           string(d.fileName(nextDoc)),
                  			Checksum:           d.getChecksum(nextDoc),
                  			Language:           d.languageMap[d.getLanguage(nextDoc)],
                  		}

                  		if s := d.subRepos[nextDoc]; s > 0 {
                  			if s >= uint32(len(d.subRepoPaths[d.repos[nextDoc]])) {
                  				log.Panicf("corrupt index: subrepo %d beyond %v", s, d.subRepoPaths)
                  			}
                  			path := d.subRepoPaths[d.repos[nextDoc]][s]
                  			fileMatch.SubRepositoryPath = path
                  			sr := md.SubRepoMap[path]
                  			fileMatch.SubRepositoryName = sr.Name
                  			if idx := d.branchIndex(nextDoc); idx >= 0 {
                  				fileMatch.Version = sr.Branches[idx].Version
                  			}
                  		} else {
                  			idx := d.branchIndex(nextDoc)
                  			if idx >= 0 {
                  				fileMatch.Version = md.Branches[idx].Version
                  			}
                  		}

                  		// Important invariant for performance: finalCands is sorted by offset and
                  		// non-overlapping. gatherMatches respects this invariant and all later
                  		// transformations respect this.
                  		shouldMergeMatches := !opts.ChunkMatches
                  		finalCands := d.gatherMatches(nextDoc, mt, known, shouldMergeMatches)

                  		if opts.ChunkMatches {
                  			fileMatch.ChunkMatches = cp.fillChunkMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		} else {
                  			fileMatch.LineMatches = cp.fillMatches(finalCands, opts.NumContextLines, fileMatch.Language, opts.DebugScore)
                  		}

                  		if opts.UseBM25Scoring {
                  			d.scoreFileUsingBM25(&fileMatch, nextDoc, finalCands, opts)
                  		} else {
                  			// Use the standard, non-experimental scoring method by default
                  			d.scoreFile(&fileMatch, nextDoc, mt, known, opts)
                  		}

                  		fileMatch.Branches = d.gatherBranches(nextDoc, mt, known)
                  		sortMatchesByScore(fileMatch.LineMatches)
                  		sortChunkMatchesByScore(fileMatch.ChunkMatches)
                  		if opts.Whole {
                  			fileMatch.Content = cp.data(false)
                  		}

                  		matchedChunkRanges := 0
                  		for _, cm := range fileMatch.ChunkMatches {
                  			matchedChunkRanges += len(cm.Ranges)
                  		}

                  		repoMatchCount += len(fileMatch.LineMatches)
                  		repoMatchCount += matchedChunkRanges

                  		if opts.DebugScore {
                  			fileMatch.Debug = fmt.Sprintf("score:%.2f <- %s", fileMatch.Score, fileMatch.Debug)
                  		}

                  		res.Files = append(res.Files, fileMatch)
                  		res.Stats.MatchCount += len(fileMatch.LineMatches)
                  		res.Stats.MatchCount += matchedChunkRanges
                  		res.Stats.FileCount++
                  	}

                  	for _, md := range d.repoMetaData {
                  		r := md
                  		addRepo(&res, &r)
                  		for _, v := range r.SubRepoMap {
                  			addRepo(&res, v)
                  		}
                  	}

                  	// Update stats based on work done during document search.
                  	updateMatchTreeStats(mt, &res.Stats)

                  	// If document ranking is enabled, then we can rank and truncate the files to save memory.
                  	if opts.UseDocumentRanks {
                  		res.Files = SortAndTruncateFiles(res.Files, opts)
                  	}

                  	res.Stats.MatchTreeSearch = timer.Elapsed()

                  	return &res, nil
                  }


                  func addRepo(res *SearchResult, repo *Repository) {
                  	if res.RepoURLs == nil {
                  		res.RepoURLs = map[string]string{}
                  	}
                  	res.RepoURLs[repo.Name] = repo.FileURLTemplate

                  	if res.LineFragments == nil {
                  		res.LineFragments = map[string]string{}
                  	}
                  	res.LineFragments[repo.Name] = repo.LineFragmentTemplate
                  }


                  // Gather matches from this document. The matches are returned in document

                  // order and are non-overlapping. All filename and content matches are

                  // returned, with filename matches first.

                  //

                  // If `merge` is set, overlapping and adjacent matches will be merged

                  // into a single match. Otherwise, overlapping matches will be removed,

                  // but adjacent matches will remain.

                  func (d *indexData) gatherMatches(nextDoc uint32, mt matchTree, known map[matchTree]bool, merge bool) []*candidateMatch {
                  	var cands []*candidateMatch
                  	visitMatches(mt, known, 1, func(mt matchTree, scoreWeight float64) {
                  		if smt, ok := mt.(*substrMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.current)...)
                  		}
                  		if rmt, ok := mt.(*regexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if rmt, ok := mt.(*wordMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, rmt.found)...)
                  		}
                  		if smt, ok := mt.(*symbolRegexpMatchTree); ok {
                  			cands = append(cands, setScoreWeight(scoreWeight, smt.found)...)
                  		}
                  	})

                  	// If we found no candidate matches at all, assume there must have been a match on filename.
                  	if len(cands) == 0 {
                  		nm := d.fileName(nextDoc)
                  		return []*candidateMatch{{
                  			caseSensitive: false,
                  			fileName:      true,
                  			substrBytes:   nm,
                  			substrLowered: nm,
                  			file:          nextDoc,
                  			runeOffset:    0,
                  			byteOffset:    0,
                  			byteMatchSz:   uint32(len(nm)),
                  		}}
                  	}

                  	sort.Sort((sortByOffsetSlice)(cands))
                  	res := cands[:0]
                  	mergeRun := 1
                  	for i, c := range cands {
                  		if i == 0 {
                  			res = append(res, c)
                  			continue
                  		}

                  		last := res[len(res)-1]

                  		// Never compare filename and content matches
                  		if last.fileName != c.fileName {
                  			res = append(res, c)
                  			continue
                  		}

                  		if merge {
                  			// Merge adjacent candidates. This guarantees that the matches
                  			// are non-overlapping.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			end := c.byteOffset + c.byteMatchSz
                  			if lastEnd >= c.byteOffset {
                  				mergeRun++
                  				// Average out the score across the merged candidates. Only do it if
                  				// we are boosting to avoid floating point funkiness in the normal
                  				// case.
                  				if !(epsilonEqualsOne(last.scoreWeight) && epsilonEqualsOne(c.scoreWeight)) {
                  					last.scoreWeight = ((last.scoreWeight * float64(mergeRun-1)) + c.scoreWeight) / float64(mergeRun)
                  				}

                  				// latest candidate goes further, update our end
                  				if end > lastEnd {
                  					last.byteMatchSz = end - last.byteOffset
                  				}

                  				continue
                  			} else {
                  				mergeRun = 1
                  			}
                  		} else {
                  			// Remove overlapping candidates. This guarantees that the matches
                  			// are non-overlapping, but also preserves expected match counts.
                  			lastEnd := last.byteOffset + last.byteMatchSz
                  			if lastEnd > c.byteOffset {
                  				continue
                  			}
                  		}

                  		res = append(res, c)
                  	}
                  	return res
                  }


                  type sortByOffsetSlice []*candidateMatch


                  func (m sortByOffsetSlice) Len() int      { return len(m) }

                  func (m sortByOffsetSlice) Swap(i, j int) { m[i], m[j] = m[j], m[i] }

                  func (m sortByOffsetSlice) Less(i, j int) bool {
                  	// Sort all filename matches to the start
                  	if m[i].fileName != m[j].fileName {
                  		return m[i].fileName
                  	}

                  	if m[i].byteOffset == m[j].byteOffset { // tie break if same offset
                  		// Prefer longer candidates if starting at same position
                  		return m[i].byteMatchSz > m[j].byteMatchSz
                  	}
                  	return m[i].byteOffset < m[j].byteOffset
                  }


                  // setScoreWeight is a helper used by gatherMatches to set the weight based on

                  // the score weight of the matchTree.

                  func setScoreWeight(scoreWeight float64, cm []*candidateMatch) []*candidateMatch {
                  	for _, m := range cm {
                  		m.scoreWeight = scoreWeight
                  	}
                  	return cm
                  }


                  func (d *indexData) branchIndex(docID uint32) int {
                  	mask := d.fileBranchMasks[docID]
                  	idx := 0
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			return idx
                  		}
                  		idx++
                  		mask >>= 1
                  	}
                  	return -1
                  }


                  // gatherBranches returns a list of branch names taking into account any branch

                  // filters in the query. If the query contains a branch filter, it returns all

                  // branches containing the docID and matching the branch filter. Otherwise, it

                  // returns all branches containing docID.

                  func (d *indexData) gatherBranches(docID uint32, mt matchTree, known map[matchTree]bool) []string {
                  	var mask uint64
                  	visitMatchAtoms(mt, known, func(mt matchTree) {
                  		bq, ok := mt.(*branchQueryMatchTree)
                  		if !ok {
                  			return
                  		}

                  		mask = mask | bq.branchMask()
                  	})

                  	if mask == 0 {
                  		mask = d.fileBranchMasks[docID]
                  	}

                  	var branches []string
                  	id := uint32(1)
                  	branchNames := d.branchNames[d.repos[docID]]
                  	for mask != 0 {
                  		if mask&0x1 != 0 {
                  			branches = append(branches, branchNames[uint(id)])
                  		}
                  		id <<= 1
                  		mask >>= 1
                  	}

                  	return branches
                  }


                  func (d *indexData) List(ctx context.Context, q query.Q, opts *ListOptions) (rl *RepoList, err error) {
                  	var include func(rle *RepoListEntry) bool

                  	q = d.simplify(q)
                  	if c, ok := q.(*query.Const); ok {
                  		if !c.Value {
                  			return &RepoList{}, nil
                  		}
                  		include = func(rle *RepoListEntry) bool {
                  			return true
                  		}
                  	} else {
                  		sr, err := d.Search(ctx, q, &SearchOptions{
                  			ShardRepoMaxMatchCount: 1,
                  		})
                  		if err != nil {
                  			return nil, err
                  		}

                  		foundRepos := make(map[string]struct{}, len(sr.Files))
                  		for _, file := range sr.Files {
                  			foundRepos[file.Repository] = struct{}{}
                  		}

                  		include = func(rle *RepoListEntry) bool {
                  			_, ok := foundRepos[rle.Repository.Name]
                  			return ok
                  		}
                  	}

                  	var l RepoList

                  	field, err := opts.GetField()
                  	if err != nil {
                  		return nil, err
                  	}
                  	switch field {
                  	case RepoListFieldRepos:
                  		l.Repos = make([]*RepoListEntry, 0, len(d.repoListEntry))
                  	case RepoListFieldReposMap:
                  		l.ReposMap = make(ReposMap, len(d.repoListEntry))
                  	}

                  	for i := range d.repoListEntry {
                  		if d.repoMetaData[i].Tombstone {
                  			continue
                  		}
                  		rle := &d.repoListEntry[i]
                  		if !include(rle) {
                  			continue
                  		}

                  		l.Stats.Add(&rle.Stats)

                  		// Backwards compat for when ID is missing
                  		if rle.Repository.ID == 0 {
                  			l.Repos = append(l.Repos, rle)
                  			continue
                  		}

                  		switch field {
                  		case RepoListFieldRepos:
                  			l.Repos = append(l.Repos, rle)
                  		case RepoListFieldReposMap:
                  			l.ReposMap[rle.Repository.ID] = MinimalRepoListEntry{
                  				HasSymbols:    rle.Repository.HasSymbols,
                  				Branches:      rle.Repository.Branches,
                  				IndexTimeUnix: rle.IndexMetadata.IndexTime.Unix(),
                  			}
                  		}

                  	}

                  	// Only one of these fields is populated and in all cases the size of that
                  	// field is the number of Repos in this shard.
                  	l.Stats.Repos = len(l.Repos) + len(l.ReposMap)

                  	return &l, nil
                  }


                  // regexpToMatchTreeRecursive converts a regular expression to a matchTree mt. If

                  // mt is equivalent to the input r, isEqual = true and the matchTree can be used

                  // in place of the regex r. If singleLine = true, then the matchTree and all

                  // its children only match terms on the same line. singleLine is used during

                  // recursion to decide whether to return an andLineMatchTree (singleLine = true)

                  // or a andMatchTree (singleLine = false).

                  func (d *indexData) regexpToMatchTreeRecursive(r *syntax.Regexp, minTextSize int, fileName bool, caseSensitive bool) (mt matchTree, isEqual bool, singleLine bool, err error) {
                  	// TODO - we could perhaps transform Begin/EndText in '/n'?
                  	// TODO - we could perhaps transform CharClass in (OrQuery )
                  	// if there are just a few runes, and part of a OpConcat?
                  	switch r.Op {
                  	case syntax.OpLiteral:
                  		s := string(r.Rune)
                  		if len(s) >= minTextSize {
                  			ignoreCase := syntax.FoldCase == (r.Flags & syntax.FoldCase)
                  			mt, err := d.newSubstringMatchTree(&query.Substring{Pattern: s, FileName: fileName, CaseSensitive: !ignoreCase && caseSensitive})
                  			return mt, true, !strings.Contains(s, "/n"), err
                  		}
                  	case syntax.OpCapture:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpPlus:
                  		return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)

                  	case syntax.OpRepeat:
                  		if r.Min == 1 {
                  			return d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  		} else if r.Min > 1 {
                  			// (x){2,} can't be expressed precisely by the matchTree
                  			mt, _, singleLine, err := d.regexpToMatchTreeRecursive(r.Sub[0], minTextSize, fileName, caseSensitive)
                  			return mt, false, singleLine, err
                  		}
                  	case syntax.OpConcat, syntax.OpAlternate:
                  		var qs []matchTree
                  		isEq := true
                  		singleLine = true
                  		for _, sr := range r.Sub {
                  			if sq, subIsEq, subSingleLine, err := d.regexpToMatchTreeRecursive(sr, minTextSize, fileName, caseSensitive); sq != nil {
                  				if err != nil {
                  					return nil, false, false, err
                  				}
                  				isEq = isEq && subIsEq
                  				singleLine = singleLine && subSingleLine
                  				qs = append(qs, sq)
                  			}
                  		}
                  		if r.Op == syntax.OpConcat {
                  			if len(qs) > 1 {
                  				isEq = false
                  			}
                  			newQs := make([]matchTree, 0, len(qs))
                  			for _, q := range qs {
                  				if _, ok := q.(*bruteForceMatchTree); ok {
                  					continue
                  				}
                  				newQs = append(newQs, q)
                  			}
                  			if len(newQs) == 1 {
                  				return newQs[0], isEq, singleLine, nil
                  			}
                  			if len(newQs) == 0 {
                  				return &bruteForceMatchTree{}, isEq, singleLine, nil
                  			}
                  			if singleLine {
                  				return &andLineMatchTree{andMatchTree{children: newQs}}, isEq, singleLine, nil
                  			}
                  			return &andMatchTree{newQs}, isEq, singleLine, nil
                  		}
                  		for _, q := range qs {
                  			if _, ok := q.(*bruteForceMatchTree); ok {
                  				return q, isEq, false, nil
                  			}
                  		}
                  		if len(qs) == 0 {
                  			return &noMatchTree{Why: "const"}, isEq, false, nil
                  		}
                  		return &orMatchTree{qs}, isEq, false, nil
                  	case syntax.OpStar:
                  		if r.Sub[0].Op == syntax.OpAnyCharNotNL {
                  			return &bruteForceMatchTree{}, false, true, nil
                  		}
                  	}
                  	return &bruteForceMatchTree{}, false, false, nil
                  }


                  type timer struct {
                  	last time.Time
                  }


                  func newTimer() *timer {
                  	return &timer{
                  		last: time.Now(),
                  	}
                  }


                  func (t *timer) Elapsed() time.Duration {
                  	now := time.Now()
                  	d := now.Sub(t.last)
                  	t.last = now
                  	return d
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: See zoekt
                  repo find location of tensor function"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 55540
        content:
          mimeType: text/event-stream
          size: 55540
          text: >+
            event: completion

            data: {"completion":"I apologize, but after reviewing the provided codebase context, I couldn't find any specific mention or implementation of a \"tensor\" function in the Zoekt codebase. The provided files (README.md, limit.go, and eval.go) don't contain any references to tensors or tensor-related functionality.\n\nZoekt is primarily a fast text search engine designed for source code, and it doesn't appear to have built-in tensor operations. The codebase seems to focus on indexing, searching, and matching text patterns in source code repositories.\n\nIf you're looking for tensor functionality, you might want to consider other libraries or frameworks specifically designed for tensor operations, such as TensorFlow or PyTorch. These are not part of the Zoekt codebase.\n\nIf you believe there should be a tensor function in Zoekt and it's not in the provided context, you might want to search other parts of the codebase or provide more specific information about where you expect to find this function.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:20 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "509"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:18.260Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8f8cab3031fd34e3737fc9640a31df82
      _order: 0
      cache: {}
      request:
        bodySize: 10225
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-74d3afe99c46f09c524ab3754a564708-4da33bf6400b2158-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Explain the
                  logic in src/agent.go, particularly how agents interact with
                  ranking"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 57895
        content:
          mimeType: text/event-stream
          size: 57895
          text: >+
            event: completion

            data: {"completion":"I apologize, but I don't have access to a file named \"src/agent.go\" in the codebase context you've provided. The context you've shared includes snippets from files like \"shards/watcher.go\", \"README.md\", \"limit.go\", and \"grpc/chunk/chunker_test.go\", but there's no information about a file named \"src/agent.go\" or any specific agent-related code.\n\nWithout the relevant code, I can't explain the logic in \"src/agent.go\" or how agents interact with ranking. If you have access to the contents of \"src/agent.go\", please provide that information, and I'll be happy to analyze it for you.\n\nIn the meantime, I can tell you that the provided context doesn't contain any explicit information about agents or ranking logic. The code snippets are mostly related to file watching, search result processing, and gRPC chunking tests.\n\nIf you have any specific questions about the code snippets that were provided, or if you can share the contents of \"src/agent.go\", I'd be glad to help further.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:25 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "504"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:23.602Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a03e562c69b4e925bc53925ca73a1029
      _order: 0
      cache: {}
      request:
        bodySize: 5423
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b7d39a743abbdc207c0619e2d7821d22-fe82cfc903f180cb-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain
                  @README.md"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 139000
        content:
          mimeType: text/event-stream
          size: 139000
          text: >+
            event: completion

            data: {"completion":"Sure, I'd be happy to explain the README.md file for the Zoekt project. Here's a summary of its key points:\n\n1. Introduction:\n   - Zoekt is a fast text search engine designed for source code.\n   - It's a fork maintained by Sourcegraph, originally from Google.\n\n2. Installation and Usage:\n   - You can download Zoekt using `go get github.com/sourcegraph/zoekt/`\n   - There are different indexing options:\n     - For directories: use `zoekt-index`\n     - For Git repositories: use `zoekt-git-index`\n     - For Repo repositories: use `zoekt-repo-index` and `zoekt-mirror-gitiles`\n\n3. Searching:\n   - Web interface: Use `zoekt-webserver`\n   - JSON API: Available through HTTP GET requests\n   - CLI: Use the `zoekt` command\n\n4. Deployment:\n   - Suggests using a systemd unit file for organized installation on Linux servers\n\n5. Search Service:\n   - `zoekt-indexserver` can be used to manage mirroring and indexing of repositories\n\n6. Symbol Search:\n   - Recommends installing Universal ctags for improved ranking\n\n7. Acknowledgements:\n   - Credits Han-Wen Nienhuys for creating Zoekt and Alexander Neubeck for the idea\n\n8. Fork Details:\n   - Explains that this Sourcegraph fork is now the main source for Zoekt\n   - Lists some differences from the original Google version\n\n9. Disclaimer:\n   - States that this is not an official Google product\n\nThe README provides instructions for installation, indexing, searching, and deploying Zoekt, making it a comprehensive guide for users looking to set up and use this search engine for source code.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:29 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "499"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:28.306Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: a5c4702546152c4ec4b2aca662958780
      _order: 0
      cache: {}
      request:
        bodySize: 11659
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-409e72048557a91d024a478fe03ed8ce-ad94099f728d1370-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: >-
                  Sure, I'd be happy to explain the README.md file for the Zoekt
                  project. Here's a summary of its key points:


                  1. Introduction:
                     - Zoekt is a fast text search engine designed for source code.
                     - It's a fork maintained by Sourcegraph, originally from Google.

                  2. Installation and Usage:
                     - You can download Zoekt using `go get github.com/sourcegraph/zoekt/`
                     - There are different indexing options:
                       - For directories: use `zoekt-index`
                       - For Git repositories: use `zoekt-git-index`
                       - For Repo repositories: use `zoekt-repo-index` and `zoekt-mirror-gitiles`

                  3. Searching:
                     - Web interface: Use `zoekt-webserver`
                     - JSON API: Available through HTTP GET requests
                     - CLI: Use the `zoekt` command

                  4. Deployment:
                     - Suggests using a systemd unit file for organized installation on Linux servers

                  5. Search Service:
                     - `zoekt-indexserver` can be used to manage mirroring and indexing of repositories

                  6. Symbol Search:
                     - Recommends installing Universal ctags for improved ranking

                  7. Acknowledgements:
                     - Credits Han-Wen Nienhuys for creating Zoekt and Alexander Neubeck for the idea

                  8. Fork Details:
                     - Explains that this Sourcegraph fork is now the main source for Zoekt
                     - Lists some differences from the original Google version

                  9. Disclaimer:
                     - States that this is not an official Google product

                  The README provides instructions for installation, indexing, searching, and deploying Zoekt, making it a comprehensive guide for users looking to set up and use this search engine for source code.
              - speaker: human
                text: "You have access to the provided codebase context. Question: what does
                  @limit.go do?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 89382
        content:
          mimeType: text/event-stream
          size: 89382
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file provides functionality for sorting, truncating, and limiting search results in Zoekt. Here's a breakdown of its main components and functions:\n\n1. `SortAndTruncateFiles`: This function sorts the given file matches and then truncates them based on the provided search options.\n\n2. `DisplayTruncator`: This is a type definition for a function that enforces document and match display limits by truncating and mutating the results.\n\n3. `NewDisplayTruncator`: This function creates a new `DisplayTruncator` based on the given search options. It enforces limits on the number of documents and matches to display.\n\n4. `limitMatches`: This function limits the number of matches in the file results based on a given limit and whether to chunk matches or not.\n\n5. `limitChunkMatches`: This function limits the number of chunk matches in a file, truncating the content and ranges as necessary.\n\n6. `limitLineMatches`: This function limits the number of line matches in a file.\n\nThe main purpose of this file is to provide mechanisms for controlling the amount of data returned in search results, which is crucial for performance and usability in large codebases. It allows Zoekt to return a manageable amount of results to the user, even when there are many matches across many files.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:36 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "492"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:35.260Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b5223dbc62f13747ba206842a0eacaa2
      _order: 0
      cache: {}
      request:
        bodySize: 5211
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-ddca08fcb30ac01e75980436cedb9a10-fa8512ed42c162f9-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do
                  goroutines work?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 115962
        content:
          mimeType: text/event-stream
          size: 115962
          text: >+
            event: completion

            data: {"completion":"Based on the provided codebase context, I can't give a comprehensive explanation of how goroutines work in general, as the code snippets don't provide a full tutorial on goroutines. However, I can point out an example of goroutine usage from the given code.\n\nIn the `newDirectoryWatcher` function from the `shards/watcher.go` file, we can see an example of a goroutine being used:\n\n```go\ngo func() {\n    defer close(sw.ready)\n\n    if err := sw.scan(); err != nil {\n        sw.readyErr = err\n        return\n    }\n\n    if err := sw.watch(); err != nil {\n        sw.readyErr = err\n        return\n    }\n}()\n```\n\nThis code demonstrates a few key aspects of goroutines:\n\n1. Goroutines are launched using the `go` keyword followed by a function call.\n2. They run concurrently with other goroutines in the same address space.\n3. They can be used for background tasks that don't need to complete before the function returns.\n4. They can communicate with other parts of the program using channels (like `sw.ready` in this case).\n\nIn this specific example, the goroutine is used to perform scanning and watching tasks asynchronously, allowing the `newDirectoryWatcher` function to return immediately while these operations continue in the background.\n\nHowever, for a full understanding of how goroutines work, you would need to refer to Go language documentation or tutorials, as the provided code snippets don't offer a complete explanation of goroutine concepts and behavior.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:39 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "489"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:38.307Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2b95e90ed423c42826897127e47b9f78
      _order: 0
      cache: {}
      request:
        bodySize: 6808
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-d35b0bbb563c0add6009c1ca4995aaff-067863864eecf527-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: >-
                  Based on the provided codebase context, I can't give a
                  comprehensive explanation of how goroutines work in general,
                  as the code snippets don't provide a full tutorial on
                  goroutines. However, I can point out an example of goroutine
                  usage from the given code.


                  In the `newDirectoryWatcher` function from the `shards/watcher.go` file, we can see an example of a goroutine being used:


                  ```go

                  go func() {
                      defer close(sw.ready)

                      if err := sw.scan(); err != nil {
                          sw.readyErr = err
                          return
                      }

                      if err := sw.watch(); err != nil {
                          sw.readyErr = err
                          return
                      }
                  }()

                  ```


                  This code demonstrates a few key aspects of goroutines:


                  1. Goroutines are launched using the `go` keyword followed by a function call.

                  2. They run concurrently with other goroutines in the same address space.

                  3. They can be used for background tasks that don't need to complete before the function returns.

                  4. They can communicate with other parts of the program using channels (like `sw.ready` in this case).


                  In this specific example, the goroutine is used to perform scanning and watching tasks asynchronously, allowing the `newDirectoryWatcher` function to return immediately while these operations continue in the background.


                  However, for a full understanding of how goroutines work, you would need to refer to Go language documentation or tutorials, as the provided code snippets don't offer a complete explanation of goroutine concepts and behavior.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain how
                  they relate to wait groups"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 59140
        content:
          mimeType: text/event-stream
          size: 59140
          text: >+
            event: completion

            data: {"completion":"I apologize for the confusion, but after reviewing the provided codebase context, I don't see any direct use or mention of wait groups in the given code snippets. The code examples don't show any implementation or usage of sync.WaitGroup, which is typically used for wait groups in Go.\n\nThe provided code snippets mainly show:\n\n1. A directory watcher implementation\n2. A test file for a gRPC chunker\n3. A function for sorting and truncating files\n4. A basic README\n\nNone of these directly relate to or demonstrate the use of wait groups. \n\nWait groups are typically used in Go to wait for a collection of goroutines to finish executing. They're part of the sync package and are useful for coordinating concurrent operations. However, the given code doesn't showcase this particular concurrency pattern.\n\nIf you have a specific question about wait groups or if there's a particular part of the codebase you're curious about, please let me know and I'll do my best to help based on the information available.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:47:46 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "482"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:47:45.214Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: aa5bb0bf87a0e50b747c8a60ef3bf444
      _order: 0
      cache: {}
      request:
        bodySize: 5437
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1972042ff6001132f4eec637d8634db5-ad4c510395f9d22c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What code do
                  you have access to?"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 57689
        content:
          mimeType: text/event-stream
          size: 57689
          text: >+
            event: completion

            data: {"completion":"Based on the provided README.md file, I have access to information about the Zoekt project, which is a fast text search engine intended for use with source code. However, I don't have direct access to the actual source code files of the project. The README.md provides instructions, explanations, and context about Zoekt, including:\n\n1. How to download and install Zoekt\n2. How to use Zoekt for indexing different types of repositories (directory, Git, Repo)\n3. How to use Zoekt for searching, including web interface, JSON API, and CLI\n4. Information about setting up Zoekt as a service\n5. Details about the search service functionality\n6. Information about symbol search capabilities\n7. Acknowledgements and project history\n8. Details about this specific fork of Zoekt by Sourcegraph\n\nWhile this gives a good overview of the project and its capabilities, it doesn't contain the actual implementation code. To access the source code, I would need additional files from the repository.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:54:04 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "104"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:54:03.329Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 47ff501bf22411ce815404f67676dc72
      _order: 0
      cache: {}
      request:
        bodySize: 10072
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-4a2ce8d101158fdbc897e507a22324d7-fe7eb2765572d5a6-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Are you
                  capable of upgrading my pytorch version to 1.0.0, there is a
                  guide in the pytorch site"
            model: anthropic/claude-3-haiku-20240307
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 198218
        content:
          mimeType: text/event-stream
          size: 198218
          text: >+
            event: completion

            data: {"completion":"Unfortunately I don't have the capability to actually upgrade the PyTorch version in your codebase. As an AI assistant, I don't have direct access to modify your local development environment or project dependencies.\n\nHowever, I can provide you with some guidance on how you might be able to upgrade the PyTorch version yourself, based on the information provided:\n\n1. **Check the current PyTorch version**: First, you should check the current PyTorch version used in your project. You can do this by inspecting your project's dependencies or running the appropriate command in your development environment.\n\n2. **Review the PyTorch upgrade guide**: As you mentioned, there is a guide on the PyTorch website for upgrading to version 1.0.0. You can find this guide at the PyTorch documentation site. The guide should provide step-by-step instructions on how to upgrade PyTorch, including any potential compatibility issues or breaking changes you should be aware of.\n\n3. **Update your project dependencies**: Once you've reviewed the upgrade guide, you can update your project's PyTorch dependency to the desired version 1.0.0. Depending on your project's setup, this may involve modifying your project's configuration files (e.g., `requirements.txt`, `package.json`, `Gemfile`, etc.) or using your package manager's commands to update the dependency.\n\n4. **Test your application**: After updating the PyTorch version, be sure to thoroughly test your application to ensure it's still functioning as expected. Pay close attention to any breaking changes or deprecations introduced in the new PyTorch version.\n\n5. **Address any issues**: If you encounter any issues or problems during the upgrade process, refer back to the PyTorch upgrade guide or consult the PyTorch documentation for troubleshooting steps.\n\nRemember, as an AI assistant, I can provide guidance and information, but I cannot directly perform the upgrade process for you. The actual steps to upgrade the PyTorch version in your codebase will depend on your project's specific setup and requirements.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 17:25:47 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "231"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T17:25:45.999Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 1b26f9ad54bfda340f9a4ebde8861fec
      _order: 0
      cache: {}
      request:
        bodySize: 10073
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e4734ff6b74f9e1542be48239c8ca8d2-94078e85a799abd4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Are you
                  capable of upgrading my pytorch version to 1.0.0, there is a
                  guide in the pytorch site"
            model: anthropic/claude-3-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 39860
        content:
          mimeType: text/event-stream
          size: 39860
          text: >+
            event: completion

            data: {"completion":"Unfortunately, this codebase does not appear to be related to PyTorch or provide any instructions on upgrading PyTorch versions. The context you provided is for a code search engine called Zoekt, which is written in Go.\n\nTo upgrade your PyTorch version, you would need to follow the official PyTorch installation guide for your specific operating system and Python environment. The guide can be found on the PyTorch website: https://pytorch.org/get-started/locally/\n\nIn general, the steps to upgrade PyTorch involve:\n\n1. Uninstalling the current PyTorch version\n2. Installing the desired PyTorch 1.0.0 version using pip or conda, depending on your environment\n\nHowever, without access to your specific environment and requirements, I cannot provide more detailed instructions. I'd recommend consulting the PyTorch installation guide and following the steps carefully to ensure a successful upgrade.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 17:25:55 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "223"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T17:25:53.866Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ac6cb2ccdfb7c2283aa751e6d8b0cd6c
      _order: 0
      cache: {}
      request:
        bodySize: 10075
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-26e41f294d635d3457fd64785269be91-d1167dedab45eda7-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 431
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: system
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Are you
                  capable of upgrading my pytorch version to 1.0.0, there is a
                  guide in the pytorch site"
            model: anthropic/claude-3-5-sonnet-20240620
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: api-version
            value: "1"
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?api-version=1&client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 32634
        content:
          mimeType: text/event-stream
          size: 32634
          text: >+
            event: completion

            data: {"completion":"I apologize, but I don't have access to any information about upgrading PyTorch versions or guides on the PyTorch site. The codebase context you provided is for a project called Zoekt, which is a fast text search engine for source code. It doesn't contain any information related to PyTorch.\n\nThe provided code is primarily about sorting and truncating search results, and implementing display limits for search matches. It doesn't have anything to do with PyTorch or version upgrades.\n\nIf you need help upgrading PyTorch, I'd recommend checking the official PyTorch documentation or asking a question specifically about PyTorch upgrades. The context provided here is not relevant to that task.","stopReason":"end_turn"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 17:26:01 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "217"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T17:25:59.643Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: e891fbeeeed06871148411e2eb515fd2
      _order: 0
      cache: {}
      request:
        bodySize: 5529
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-f43e6b269c9bb2dfde1a816d1ab0d4b0-3a42c89af41fd975-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What code do
                  you have access to?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 33609
        content:
          mimeType: text/event-stream
          size: 33609
          text: >+
            event: completion

            data: {"completion":"Based on the provided README.md file, I have access to the codebase of the Zoekt project, specifically the source code related to searching, indexing, and managing repositories using Zoekt. The README.md file contains instructions for downloading, indexing, and searching repositories, as well as information about the Zoekt project, its features, and acknowledgements. Additionally, it includes details about the fork of Zoekt by Sourcegraph, differences from the original Google version, and acknowledgements for contributions to the project.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:54 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:53.447Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 5fac89aa66071f339d2dd6a0ea2dd738
      _order: 0
      cache: {}
      request:
        bodySize: 5305
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-cce292f8705eb40f8530c073a83a08ba-b968e96df322d48f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do slices
                  work in go?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 97554
        content:
          mimeType: text/event-stream
          size: 97554
          text: >+
            event: completion

            data: {"completion":"In Go, a slice is a data structure that represents a flexible view into an underlying array. Slices are like dynamic arrays with a variable length, and they provide a more powerful and convenient way to work with sequences of data compared to arrays.\n\nWhen you declare a slice in Go, you do not specify its length upfront. Instead, a slice is defined by a starting index, a length, and a capacity. Slices are reference types, meaning that when you pass a slice to a function or assign it to another variable, you are passing a reference to the underlying array, not a copy of the slice's data.\n\nSlices dynamically adjust their length as needed, allowing you to append, delete, and modify elements easily. Slices can also be sliced, meaning you can create new slices that reference subsets of the original slice's data.\n\nOverall, slices in Go are a powerful and flexible way to work with collections of data.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:42:56 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:55.843Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 277dceb2a6ed2688b82a40fe90e8dbcd
      _order: 0
      cache: {}
      request:
        bodySize: 5320
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-0191c88d46293b27250580c5b39b2ba1-6a3c4ca8e5ba1406-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >
                  You have access to the provided codebase context. Question:
                  what does this regex do? 

                  /a|e|i|o|u/
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 2338
        content:
          mimeType: text/event-stream
          size: 2338
          text: >+
            event: completion

            data: {"completion":"This regex matches any lowercase vowel (a, e, i, o, u) in a string.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:00 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:42:59.568Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 13f7beda1adebaa46d354ebf49fe30c0
      _order: 0
      cache: {}
      request:
        bodySize: 5317
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b9e2246fd25fae138c9711cecc995124-f5f55f0864eb0849-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: style css
                  checkbox using light purple"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 35594
        content:
          mimeType: text/event-stream
          size: 35594
          text: >+
            event: completion

            data: {"completion":"To style a CSS checkbox using light purple color, you can use the following CSS code snippet:\n\n```css\n.checkbox {\n  appearance: none;\n  width: 16px;\n  height: 16px;\n  border: 2px solid #9370db; /* Light purple color */\n  border-radius: 4px;\n  cursor: pointer;\n}\n\n.checkbox:checked {\n  background-color: #9370db; /* Light purple color when checkbox is checked */\n}\n```\n\nYou can apply this CSS styling to your checkbox element in your HTML code to achieve the desired appearance.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:01 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:00.484Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 4e3b5dd7decdbb6af9982202ff3cf594
      _order: 0
      cache: {}
      request:
        bodySize: 4989
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-b0d1e9a0af30643f249f9876cb1ffc81-23b0802c4c99ff1d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  this repo do??"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 29288
        content:
          mimeType: text/event-stream
          size: 29288
          text: >+
            event: completion

            data: {"completion":"The provided codebase context appears to be related to a package called `zoekt` which involves sorting, truncating, and displaying file matches based on search options. The code includes functions to sort and truncate file matches, enforce document and match display limits, limit chunk matches and line matches in file matches, as well as create a display truncator based on search options. Ultimately, this package seems to be used for searching and displaying search results in a codebase.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:05 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:04.275Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 625c9aaddd3ddf9894acce2b04b288c5
      _order: 0
      cache: {}
      request:
        bodySize: 10277
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-1d66059025ff19f9cb658fe7549da574-2e92790fcaacf97c-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: describe my
                  code"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 197142
        content:
          mimeType: text/event-stream
          size: 197142
          text: >+
            event: completion

            data: {"completion":"The code in limit.go file is part of the zoekt package and defines functions related to sorting and truncating file matches based on search options. \n\n- The SortAndTruncateFiles function sorts the file matches and then truncates them based on search options. It uses the SortFiles function and a DisplayTruncator function to assist with the sorting and truncation.\n\n- The DisplayTruncator function enforces document and match display limits by truncating and mutating the file matches. It is a stateful function that returns a new set of file matches with enforced limits.\n\n- The NewDisplayTruncator function constructs a DisplayTruncator based on the search options provided. It checks for document and match display limits and creates the truncator accordingly.\n\n- The limitMatches function is used to limit the number of matches in each file match based on the specified limit and whether to chunk matches.\n\n- The limitChunkMatches function limits the number of chunk matches in a file match by truncating the ranges and content if necessary based on the specified limit.\n\n- The limitLineMatches function limits the number of line matches in a file match by truncating the line fragments if necessary based on the specified limit.\n\nOverall, the code in limit.go focuses on sorting and truncating file matches to enforce display limits specified in the search options.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:07 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:06.446Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 1b9fcd02ad8c6cf0293422f448ce0eb9
      _order: 0
      cache: {}
      request:
        bodySize: 5304
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-19e6bd26e8951637cf6bb07cee8aa992-81f1585d09d486d0-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: @zoekt
                  describe my code."
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 10479
        content:
          mimeType: text/event-stream
          size: 10479
          text: >+
            event: completion

            data: {"completion":"I'm sorry, but I don't have access to the \"zoekt\" tool. However, I can analyze and provide information or suggestions based on the codebase context you have provided. If you have any specific questions or need assistance with the code, feel free to ask.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:12 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:11.756Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 82997ff7e4d525505297c31bef8022db
      _order: 0
      cache: {}
      request:
        bodySize: 5302
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-f5617166822149d60b4550f84156c790-e80dba105da16ecb-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: is my code
                  base clean?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 7168
        content:
          mimeType: text/event-stream
          size: 7168
          text: >+
            event: completion

            data: {"completion":"I don't have the ability to analyze codebases for cleanliness. If you have specific criteria or guidelines for what constitutes clean code in your project, I can help you review the code based on those criteria.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:14 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:13.209Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 3f1242b40df6ceaf03eac96d72f0a06c
      _order: 0
      cache: {}
      request:
        bodySize: 10268
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-477d2c5c155e61cd2383a4e3fc992594-6425e0800cfd3657-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: What does
                  directory watcher do?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 33013
        content:
          mimeType: text/event-stream
          size: 33013
          text: >+
            event: completion

            data: {"completion":"The directory watcher in the provided codebase context is responsible for watching a directory for changes. It creates a new instance of `DirectoryWatcher` with the specified directory, loads shards, and sets up channels for signaling readiness, quitting, and stopping. The directory watcher also scans the directory and watches for any changes by running the `scan()` and `watch()` functions in separate goroutines. If any errors occur during scanning or watching, the `readyErr` field is set to the error.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:15 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:14.416Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 022f5d1993aa2709622751305d2fbe2a
      _order: 0
      cache: {}
      request:
        bodySize: 10270
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-126a986ea71d3a7f49ccb3f9dec7de60-b5773da23721245f-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: where do we
                  test the grpc chunker"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 9125
        content:
          mimeType: text/event-stream
          size: 9125
          text: >+
            event: completion

            data: {"completion":"The tests for the `grpc` chunker are located in the `chunker_test.go` file within the `grpc/chunk` package. The specific test function that tests the `Chunker` end-to-end functionality is `TestChunkerE2E`.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:17 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:16.710Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 0398a53c98b71de9d4b7f3ff656b8ec9
      _order: 0
      cache: {}
      request:
        bodySize: 10167
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-f48b70ad4b0056044c2705e74f55ba90-2e66217afd2ee0c5-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Can you look
                  through the files and identify the conflicting packages that
                  may be causing this?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 23410
        content:
          mimeType: text/event-stream
          size: 23410
          text: >+
            event: completion

            data: {"completion":"Based on the code snippets provided in the README.md and limit.go files, there does not appear to be any conflicting packages causing issues in the codebase. The README.md file provides information about the Zoekt search engine and its related commands, while the limit.go file contains functions related to sorting and truncating file matches in the Zoekt package. There is no evidence of conflicting packages based on the provided context.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:19 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:18.150Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: e07891609ba3aae9a8e131ae0a71132b
      _order: 0
      cache: {}
      request:
        bodySize: 10309
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-7f33189e808416fdb44ff2973f96d816-db4283c8ff833bfb-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: |-
                  Codebase context from file vscode/src/external-services.ts:
                  ```typescript

                  ```typescript
                          },
                      }
                  }
                  ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Mind taking a
                  second look at the file? @limit.go"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 1732
        content:
          mimeType: text/event-stream
          size: 1732
          text: >+
            event: completion

            data: {"completion":"Sure! What specific information are you looking for in the file limit.go?","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:20.140Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ec5e1741ae6e0b92ccf780b2b8501a79
      _order: 0
      cache: {}
      request:
        bodySize: 10115
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-910f4f7c2dc935051e6d434595a1394c-90cfaacaaf4de16d-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Why does this
                  project use the MIT license?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 12541
        content:
          mimeType: text/event-stream
          size: 12541
          text: >+
            event: completion

            data: {"completion":"This project likely uses the MIT license because it is a permissive open-source license that allows for the code to be used, modified, and distributed with minimal restrictions. The MIT license is known for being simple and easy to understand, making it a popular choice for many open-source projects.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:21 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:21.042Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 771e990dbd30aef2699d013ad70b9081
      _order: 0
      cache: {}
      request:
        bodySize: 10120
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-59a7990d73bf8b98c81023c4f1856a94-437acf1daf8633e4-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: See zoekt
                  repo find location of tensor function"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 21890
        content:
          mimeType: text/event-stream
          size: 21890
          text: >+
            event: completion

            data: {"completion":"To find the location of the `tensor` function in the `zoekt` repository, you would typically search for the function name within the codebase. In this case, you can search for \"tensor\" using the search functionality provided in your development environment or code editor. You can also utilize the search capabilities provided by the `zoekt` search engine itself to search for the function within the codebase.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:23 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:22.667Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2ae91c7459bc1ec0cd62bfd801d947a8
      _order: 0
      cache: {}
      request:
        bodySize: 10317
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-a4c29cc27deb7ef5b797fcdd51118936-c1b8a61c07abb910-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Explain the
                  logic in src/agent.go, particularly how agents interact with
                  ranking"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 175151
        content:
          mimeType: text/event-stream
          size: 175151
          text: >+
            event: completion

            data: {"completion":"Since I don't have the exact content of the 'src/agent.go' file, I can provide a general explanation based on common practices in codebases.\n\nIn a typical codebase, the 'agent.go' file would likely contain the logic for managing agents within the system. Agents are typically responsible for performing tasks such as indexing, searching, or handling requests.\n\nWhen it comes to agents interacting with ranking, here is a possible logic explanation based on common practices:\n\n1. Agents are responsible for querying and retrieving search results based on the given query parameters.\n2. Once the agents retrieve search results, they may process and rank the results based on relevance.\n3. The ranking logic may involve factors such as keyword matching, result freshness, popularity, or custom relevance scoring algorithms.\n4. Agents may also interact with other components, such as the indexer, to fetch additional metadata that can be used for ranking purposes.\n5. The ranked search results are then returned to the caller or passed on to other components for further processing or display.\n\nIt's important to note that the specific details of how agents interact with ranking can vary greatly depending on the system's architecture, requirements, and the complexity of the ranking algorithms implemented in the codebase.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:26 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:24.952Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 733154f225700cacd919e8fd8ddb1f72
      _order: 0
      cache: {}
      request:
        bodySize: 5515
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-37ca77e3ffd828171aea67a5b15774a8-fc867fb945ff23ec-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain
                  @README.md"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 40173
        content:
          mimeType: text/event-stream
          size: 40173
          text: >+
            event: completion

            data: {"completion":"README.md is a file that provides documentation for the Zoekt codebase. It includes information on what Zoekt is, how to download and install it, how to index directories, git repositories, and repo repositories, how to search using the web interface, JSON API, and CLI, as well as details on installation using systemd unit files. Additionally, it mentions the Zoekt search service and symbol search, acknowledgements to the creators, details about the fork from google/zoekt to sourcegraph/zoekt, and a disclaimer that it is not an official Google product.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:30 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:29.989Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 51d4540b1d850ca623a0277b5a16b06b
      _order: 0
      cache: {}
      request:
        bodySize: 10736
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-72507c516316ed672828fff9a5a9691c-f51fce77d479c98b-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: explain @README.md
              - speaker: assistant
                text: README.md is a file that provides documentation for the Zoekt codebase. It
                  includes information on what Zoekt is, how to download and
                  install it, how to index directories, git repositories, and
                  repo repositories, how to search using the web interface, JSON
                  API, and CLI, as well as details on installation using systemd
                  unit files. Additionally, it mentions the Zoekt search service
                  and symbol search, acknowledgements to the creators, details
                  about the fork from google/zoekt to sourcegraph/zoekt, and a
                  disclaimer that it is not an official Google product.
              - speaker: human
                text: "You have access to the provided codebase context. Question: what does
                  @limit.go do?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 56905
        content:
          mimeType: text/event-stream
          size: 56905
          text: >+
            event: completion

            data: {"completion":"The `limit.go` file in the Zoekt codebase contains functions related to sorting and truncating file matches based on search options. \n\n- The `SortAndTruncateFiles` function sorts the files and then truncates them based on search options.\n- The `NewDisplayTruncator` function creates a display truncator that enforces document and match display limits.\n- The `limitMatches`, `limitChunkMatches`, and `limitLineMatches` functions are used to limit the number of chunk matches and line matches in file matches by truncating them based on the specified limits.\n\nOverall, the `limit.go` file provides functionality for controlling the display limits of file matches in Zoekt search results.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:33 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:32.566Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 454cc476d40addefba77aa1c1de0ef05
      _order: 0
      cache: {}
      request:
        bodySize: 5303
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-e1e030e52b6891826b67e1436acb3a55-b6d32596ca3dd146-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: how do
                  goroutines work?"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 75156
        content:
          mimeType: text/event-stream
          size: 75156
          text: >+
            event: completion

            data: {"completion":"Goroutines in Go are lightweight threads managed by the Go runtime. They allow concurrent execution of code within a program. When a goroutine is created using the `go` keyword, it runs concurrently with other goroutines in the same program. Goroutines are scheduled by the Go runtime, which multiplexes them onto a smaller number of OS threads, allowing for efficient execution of concurrent tasks.\n\nGoroutines can communicate with each other using channels, which provide a way to pass data between goroutines safely and efficiently. Channels are a core feature of Go's concurrency model and are used to coordinate goroutines and synchronize their execution.\n\nOverall, goroutines in Go provide a simple and efficient way to achieve concurrency in programs, allowing developers to write concurrent code that is easy to understand and maintain.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:36 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:35.747Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 44baa8043c8f4d5d934990377c4a6d7a
      _order: 0
      cache: {}
      request:
        bodySize: 6253
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-717a53e3983a925cc9129c403f0562dc-ad44a50e5cd7596a-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file shards/watcher.go:

                  ```go
                     func newDirectoryWatcher(dir string, loader shardLoader) (*DirectoryWatcher, error) {
                  //                   	sw := &DirectoryWatcher{

                  //                   		dir:        dir,

                  //                   		timestamps: map[string]time.Time{},

                  //                   		loader:     loader,

                  //                   		ready:      make(chan struct{}),

                  //                   		quit:       make(chan struct{}),

                  //                   		stopped:    make(chan struct{}),

                  //                   	}

                  //

                  //                   	go func() {

                  //                   		defer close(sw.ready)

                  //

                  //                   		if err := sw.scan(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //

                  //                   		if err := sw.watch(); err != nil {

                  //                   			sw.readyErr = err

                  //                   			return

                  //                   		}

                  //                   	}()

                  //

                  //                   	return sw, nil```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: |-
                  Codebase context from file README.md:
                  ```markdown
                  ## Readme

                  This is a readme```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  ```go

                  //

                  //                   func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {

                  //                   	SortFiles(files)

                  //                   	truncator, _ := NewDisplayTruncator(opts)

                  //                   	files, _ = truncator(files)

                  //                   	return files

                  //                   ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file grpc/chunk/chunker_test.go:

                  ```go
                   ```go

                                    func TestChunkerE2E(t *testing.T) {
                                    	for _, test := range []struct {
                                    		name string

                                    		inputSizeBytes       int
                                    		expectedMessageCount int
                                    	}{
                                    		{
                                    			name: "normal",

                                    			inputSizeBytes:       int(3.5 * maxMessageSize),
                                    			expectedMessageCount: 4,
                                    		},
                                    		{
                                    			name:                 "empty payload",
                                    			inputSizeBytes:       0,
                                    			expectedMessageCount: 1,
                                    		},
                                    	} {
                                    		t.Run(test.name, func(t *testing.T) {
                                    			s := &server{}
                                    			srv, serverSocketPath := runServer(t, s)
                                    			t.Cleanup(func() {
                                    				srv.Stop()
                                    			})

                                    			client, conn := newClient(t, serverSocketPath)
                                    			t.Cleanup(func() {
                                    				_ = conn.Close()
                                    			})

                                    			ctx := context.Background()

                                    			stream, err := client.StreamingOutputCall(ctx, &grpc_testing.StreamingOutputCallRequest{
                                    				Payload: &grpc_testing.Payload{
                                    					Body: []byte(strconv.FormatInt(int64(test.inputSizeBytes), 10)),
                                    				},
                                    			})

                                    			require.NoError(t, err)

                                    			messageCount := 0
                                    			var receivedPayload []byte
                                    			for {
                                    				resp, err := stream.Recv()
                                    				if errors.Is(err, io.EOF) {
                                    					break
                                    				}

                                    				if err != nil {
                                    					t.Fatal(err)
                                    				}

                                    				messageCount++
                                    				receivedPayload = append(receivedPayload, resp.GetPayload().GetBody()...)

                                    				require.Less(t, proto.Size(resp), maxMessageSize)
                                    			}

                                    			require.Equal(t, test.expectedMessageCount, messageCount)

                                    			receivedPayloadSizeBytes := len(receivedPayload)

                                    			expectedSizeBytes := test.inputSizeBytes

                                    			if receivedPayloadSizeBytes != expectedSizeBytes {
                                    				t.Fatalf("input payload size is not %d bytes (~ %q), got size: %d (~ %q)",
                                    					expectedSizeBytes, humanize.Bytes(uint64(expectedSizeBytes)),
                                    					receivedPayloadSizeBytes, humanize.Bytes(uint64(receivedPayloadSizeBytes)),
                                    				)
                                    			}
                                    		})
                                    	}
                                    ``````
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: how do goroutines work?
              - speaker: assistant
                text: >-
                  Goroutines in Go are lightweight threads managed by the Go
                  runtime. They allow concurrent execution of code within a
                  program. When a goroutine is created using the `go` keyword,
                  it runs concurrently with other goroutines in the same
                  program. Goroutines are scheduled by the Go runtime, which
                  multiplexes them onto a smaller number of OS threads, allowing
                  for efficient execution of concurrent tasks.


                  Goroutines can communicate with each other using channels, which provide a way to pass data between goroutines safely and efficiently. Channels are a core feature of Go's concurrency model and are used to coordinate goroutines and synchronize their execution.


                  Overall, goroutines in Go provide a simple and efficient way to achieve concurrency in programs, allowing developers to write concurrent code that is easy to understand and maintain.
              - speaker: human
                text: "You have access to the provided codebase context. Question: explain how
                  they relate to wait groups"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 164694
        content:
          mimeType: text/event-stream
          size: 164694
          text: >+
            event: completion

            data: {"completion":"The provided codebase context includes examples of testing functions in Go that utilize goroutines and `testing.T` objects. In these tests, wait groups can be used to synchronize the completion of multiple goroutines before proceeding to the next step in the test or checking the final results.\n\nIn the context of testing, wait groups in Go can be used to ensure that all goroutines spawned during a test have completed their execution before asserting the expected outcomes or doing cleanup tasks. By adding goroutines to the wait group when they are started and calling `wg.Wait()` before proceeding, the test can wait for all goroutines to finish before continuing.\n\nFor example, in the \"TestChunkerE2E\" function in the provided codebase context, multiple test cases are executed within a loop. For each test case, goroutines are spawned to simulate concurrent operations, and a wait group can be used to wait for all goroutines to complete before checking the test results and doing necessary clean-up.\n\nIn summary, wait groups are useful in testing scenarios involving concurrent operations with goroutines, as they provide a way to synchronize and coordinate the execution of multiple goroutines to ensure the correct behavior of the test cases.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 02:43:40 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1299
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T02:43:39.248Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 858abcd598e9f3a23e630d5b0615dcf1
      _order: 0
      cache: {}
      request:
        bodySize: 10167
        cookies: []
        headers:
          - name: content-type
            value: application/json
          - name: accept-encoding
            value: gzip;q=0
          - name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - name: user-agent
            value: chat-response-quality / v1
          - name: traceparent
            value: 00-8e611e8934a9fa76a286be30ff497ad2-e5ff2572a8941447-01
          - name: connection
            value: keep-alive
          - name: host
            value: sourcegraph.com
        headersSize: 417
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json
          params: []
          textJSON:
            maxTokensToSample: 4000
            messages:
              - speaker: human
                text: You are Cody, an AI coding assistant from Sourcegraph.
              - speaker: assistant
                text: I am Cody, an AI coding assistant from Sourcegraph.
              - speaker: human
                text: >-
                  Codebase context from file README.md:

                  ```markdown

                      "Zoekt, en gij zult spinazie eten" - Jan Eertink

                      ("seek, and ye shall eat spinach" - My primary school teacher)

                  This is a fast text search engine, intended for use with source

                  code. (Pronunciation: roughly as you would pronounce "zooked" in English)


                  **Note:** This is a [Sourcegraph](https://github.com/sourcegraph/zoekt) fork

                  of [github.com/google/zoekt](https://github.com/google/zoekt). It is now the

                  main maintained source of Zoekt.


                  # INSTRUCTIONS


                  ## Downloading

                      go get github.com/sourcegraph/zoekt/

                  ## Indexing


                  ### Directory

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-index
                      $GOPATH/bin/zoekt-index .

                  ### Git repository

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-git-index
                      $GOPATH/bin/zoekt-git-index -branches master,stable-1.4 -prefix origin/ .

                  ### Repo repositories

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-{repo-index,mirror-gitiles}
                      zoekt-mirror-gitiles -dest ~/repos/ https://gfiber.googlesource.com
                      zoekt-repo-index /n        -name gfiber /n        -base_url https://gfiber.googlesource.com/ /n        -manifest_repo ~/repos/gfiber.googlesource.com/manifests.git /n        -repo_cache ~/repos /n        -manifest_rev_prefix=refs/heads/ --rev_prefix= /n        master:default_unrestricted.xml

                  ## Searching


                  ### Web interface

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-webserver
                      $GOPATH/bin/zoekt-webserver -listen :6070

                  ### JSON API


                  You can retrieve search results as JSON by sending a GET request to zoekt-webserver.

                      curl --get /n        --url "http://localhost:6070/search" /n        --data-urlencode "q=ngram f:READ" /n        --data-urlencode "num=50" /n        --data-urlencode "format=json"

                  The response data is a JSON object. You can refer to [web.ApiSearchResult](https://sourcegraph.com/github.com/sourcegraph/zoekt@6b1df4f8a3d7b34f13ba0cafd8e1a9b3fc728cf0/-/blob/web/api.go?L23:6&subtree=true) to learn about the structure of the object.


                  ### CLI

                      go install github.com/sourcegraph/zoekt/cmd/zoekt
                      $GOPATH/bin/zoekt 'ngram f:READ'

                  ## Installation

                  A more organized installation on a Linux server should use a systemd unit file,

                  eg.

                      [Unit]
                      Description=zoekt webserver

                      [Service]
                      ExecStart=/zoekt/bin/zoekt-webserver -index /zoekt/index -listen :443  --ssl_cert /zoekt/etc/cert.pem   --ssl_key /zoekt/etc/key.pem
                      Restart=always

                      [Install]
                      WantedBy=default.target


                  # SEARCH SERVICE


                  Zoekt comes with a small service management program:

                      go install github.com/sourcegraph/zoekt/cmd/zoekt-indexserver

                      cat << EOF > config.json
                      [{"GithubUser": "username"},
                       {"GithubOrg": "org"},
                       {"GitilesURL": "https://gerrit.googlesource.com", "Name": "zoekt" }
                      ]
                      EOF

                      $GOPATH/bin/zoekt-indexserver -mirror_config config.json

                  This will mirror all repos under 'github.com/username', 'github.com/org', as

                  well as the 'zoekt' repository. It will index the repositories.


                  It takes care of fetching and indexing new data and cleaning up logfiles.


                  The webserver can be started from a standard service management framework, such

                  as systemd.



                  # SYMBOL SEARCH


                  It is recommended to install [Universal

                  ctags](https://github.com/universal-ctags/ctags) to improve

                  ranking. See [here](doc/ctags.md) for more information.



                  # ACKNOWLEDGEMENTS


                  Thanks to Han-Wen Nienhuys for creating Zoekt. Thanks to Alexander Neubeck for

                  coming up with this idea, and helping Han-Wen Nienhuys flesh it out.



                  # FORK DETAILS


                  Originally this fork contained some changes that do not make sense to upstream

                  and or have not yet been upstreamed. However, this is now the defacto source

                  for Zoekt. This section will remain for historical reasons and contains

                  outdated information. It can be removed once the dust settles on moving from

                  google/zoekt to sourcegraph/zoekt. Differences:


                  - [zoekt-sourcegraph-indexserver](cmd/zoekt-sourcegraph-indexserver/main.go)
                    is a Sourcegraph specific command which indexes all enabled repositories on
                    Sourcegraph, as well as keeping the indexes up to date.
                  - We have exposed the API via
                    [keegancsmith/rpc](https://github.com/keegancsmith/rpc) (a fork of `net/rpc`
                    which supports cancellation).
                  - Query primitive `BranchesRepos` to efficiently specify a set of repositories to
                    search.
                  - Allow empty shard directories on startup. Needed when starting a fresh
                    instance which hasn't indexed anything yet.
                  - We can return symbol/ctag data in results. Additionally we can run symbol regex queries.

                  - We search shards in order of repo name and ignore shard ranking.

                  - Other minor changes.


                  Assuming you have the gerrit upstream configured, a useful way to see what we

                  changed is:


                  ``` shellsession

                  $ git diff gerrit/master -- ':(exclude)vendor/' ':(exclude)Gopkg*'

                  ```


                  # DISCLAIMER


                  This is not an official Google product

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: >-
                  Codebase context from file limit.go:

                  ```go

                  package zoekt


                  import "log"


                  // SortAndTruncateFiles is a convenience around SortFiles and

                  // DisplayTruncator. Given an aggregated files it will sort and then truncate

                  // based on the search options.

                  func SortAndTruncateFiles(files []FileMatch, opts *SearchOptions) []FileMatch {
                  	SortFiles(files)
                  	truncator, _ := NewDisplayTruncator(opts)
                  	files, _ = truncator(files)
                  	return files
                  }


                  // DisplayTruncator is a stateful function which enforces Document and Match

                  // display limits by truncating and mutating before. hasMore is true until the

                  // limits are exhausted. Once hasMore is false each subsequent call will

                  // return an empty after and hasMore false.

                  type DisplayTruncator func(before []FileMatch) (after []FileMatch, hasMore bool)


                  // NewDisplayTruncator will return a DisplayTruncator which enforces the limits in

                  // opts. If there are no limits to enforce, hasLimits is false and there is no

                  // need to call DisplayTruncator.

                  func NewDisplayTruncator(opts *SearchOptions) (_ DisplayTruncator, hasLimits bool) {
                  	docLimit := opts.MaxDocDisplayCount
                  	docLimited := docLimit > 0

                  	matchLimit := opts.MaxMatchDisplayCount
                  	matchLimited := matchLimit > 0

                  	done := false

                  	if !docLimited && !matchLimited {
                  		return func(fm []FileMatch) ([]FileMatch, bool) {
                  			return fm, true
                  		}, false
                  	}

                  	return func(fm []FileMatch) ([]FileMatch, bool) {
                  		if done {
                  			return nil, false
                  		}

                  		if docLimited {
                  			if len(fm) >= docLimit {
                  				done = true
                  				fm = fm[:docLimit]
                  			}
                  			docLimit -= len(fm)
                  		}

                  		if matchLimited {
                  			fm, matchLimit = limitMatches(fm, matchLimit, opts.ChunkMatches)
                  			if matchLimit <= 0 {
                  				done = true
                  			}
                  		}

                  		return fm, !done
                  	}, true
                  }


                  func limitMatches(files []FileMatch, limit int, chunkMatches bool) ([]FileMatch, int) {
                  	var limiter func(file *FileMatch, limit int) int
                  	if chunkMatches {
                  		limiter = limitChunkMatches
                  	} else {
                  		limiter = limitLineMatches
                  	}
                  	for i := range files {
                  		limit = limiter(&files[i], limit)
                  		if limit <= 0 {
                  			return files[:i+1], 0
                  		}
                  	}
                  	return files, limit
                  }


                  // Limit the number of ChunkMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitChunkMatches(file *FileMatch, limit int) int {
                  	for i := range file.ChunkMatches {
                  		cm := &file.ChunkMatches[i]
                  		if len(cm.Ranges) > limit {
                  			// We potentially need to effect the limit upon 3 different fields:
                  			// Ranges, SymbolInfo, and Content.

                  			// Content is the most complicated: we need to remove the last N
                  			// lines from it, where N is the difference between the line number
                  			// of the end of the old last Range and that of the new last Range.
                  			// This calculation is correct in the presence of both context lines
                  			// and multiline Ranges, taking into account that Content never has
                  			// a trailing newline.
                  			n := cm.Ranges[len(cm.Ranges)-1].End.LineNumber - cm.Ranges[limit-1].End.LineNumber
                  			if n > 0 {
                  				for b := len(cm.Content) - 1; b >= 0; b-- {
                  					if cm.Content[b] == '/n' {
                  						n -= 1
                  					}
                  					if n == 0 {
                  						cm.Content = cm.Content[:b]
                  						break
                  					}
                  				}
                  				if n > 0 {
                  					// Should be impossible.
                  					log.Panicf("Failed to find enough newlines when truncating Content, %d left over, %d ranges", n, len(cm.Ranges))
                  				}
                  			}

                  			cm.Ranges = cm.Ranges[:limit]
                  			if cm.SymbolInfo != nil {
                  				// When non-nil, SymbolInfo is specified to have the same length
                  				// as Ranges.
                  				cm.SymbolInfo = cm.SymbolInfo[:limit]
                  			}
                  		}
                  		if len(cm.Ranges) == limit {
                  			file.ChunkMatches = file.ChunkMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(cm.Ranges)
                  	}
                  	return limit
                  }


                  // Limit the number of LineMatches in the given FileMatch, returning the

                  // remaining limit, if any.

                  func limitLineMatches(file *FileMatch, limit int) int {
                  	for i := range file.LineMatches {
                  		lm := &file.LineMatches[i]
                  		if len(lm.LineFragments) > limit {
                  			lm.LineFragments = lm.LineFragments[:limit]
                  		}
                  		if len(lm.LineFragments) == limit {
                  			file.LineMatches = file.LineMatches[:i+1]
                  			limit = 0
                  			break
                  		}
                  		limit -= len(lm.LineFragments)
                  	}
                  	return limit
                  }

                  ```
              - speaker: assistant
                text: Ok.
              - speaker: human
                text: "You have access to the provided codebase context. Question: Are you
                  capable of upgrading my pytorch version to 1.0.0, there is a
                  guide in the pytorch site"
              - speaker: assistant
            model: openai/gpt-3.5-turbo
            temperature: 0
            topK: -1
            topP: -1
        queryString:
          - name: client-name
            value: chat-response-quality
          - name: client-version
            value: v1
        url: https://sourcegraph.com/.api/completions/stream?client-name=chat-response-quality&client-version=v1
      response:
        bodySize: 26826
        content:
          mimeType: text/event-stream
          size: 26826
          text: >+
            event: completion

            data: {"completion":"I apologize, but as an AI coding assistant, I am currently focused on assisting with code-related tasks and providing programming help rather than performing specific system administration tasks like upgrading software versions. You can refer to the PyTorch site for the guide on upgrading your PyTorch version to 1.0.0. If you have any code-related questions or need help with implementing PyTorch functionality in your code, feel free to ask.","stopReason":"stop"}


            event: done

            data: {}

        cookies: []
        headers:
          - name: date
            value: Tue, 25 Jun 2024 17:25:51 GMT
          - name: content-type
            value: text/event-stream
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "226"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
        headersSize: 1406
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-25T17:25:50.532Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 12581f1c735a04aeb88af7a54cd007b2
      _order: 0
      cache: {}
      request:
        bodySize: 217
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "217"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 340
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CodyConfigFeaturesResponse {
                  site {
                      codyConfigFeatures {
                          chat
                          autoComplete
                          commands
                          attribution
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CodyConfigFeaturesResponse
            value: null
        url: https://sourcegraph.com/.api/graphql?CodyConfigFeaturesResponse
      response:
        bodySize: 159
        content:
          encoding: base64
          mimeType: application/json
          size: 159
          text: "[\"H4sIAAAAAAAAAzyLwQqAIBAF/2XPfYFXof/YdC0h3dDnIcR/Dws6DQwznTyDyXSqETLp1\
            N9Wc4j7KoxWpL72YJBBabIQN6jVdJ0yj885TYmzr38DlLg1RM1kAp9VxhjjAQAA//8=\
            \",\"AwCHzi5CbgAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.760Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 09b59ac55ce3c40d6f9ab8c79846a2c6
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 244
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query ContextFilters {
                  site {
                      codyContextFilters(version: V1) {
                          raw
                      }
                  }
              }
            variables: {}
        queryString:
          - name: ContextFilters
            value: null
        url: https://sourcegraph.com/.api/graphql?ContextFilters
      response:
        bodySize: 104
        content:
          encoding: base64
          mimeType: application/json
          size: 104
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdHJ+SmVzvl5JakVJW6ZOSWpRcUg0aLEciWrv\
            NKcnNra2loAAAAA//8DADYuyGU1AAAA\"]"
          textDecoded:
            data:
              site:
                codyContextFilters:
                  raw: null
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.036Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 9d0e130a38eaf9d3cd8d9512afc14b87
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 328
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query ContextFilters {
                  site {
                      codyContextFilters(version: V1) {
                          raw
                      }
                  }
              }
            variables: {}
        queryString:
          - name: ContextFilters
            value: null
        url: https://sourcegraph.com/.api/graphql?ContextFilters
      response:
        bodySize: 104
        content:
          encoding: base64
          mimeType: application/json
          size: 104
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdHJ+SmVzvl5JakVJW6ZOSWpRcUg0aLEciWrv\
            NKcnNra2loAAAAA//8DADYuyGU1AAAA\"]"
          textDecoded:
            data:
              site:
                codyContextFilters:
                  raw: null
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:38 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "256"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.877Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 460fa85fef77ffa15bb82fa3a88049a3
      _order: 0
      cache: {}
      request:
        bodySize: 318
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "318"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 345
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmConfiguration {
                  site {
                      codyLLMConfiguration {
                          chatModel
                          chatModelMaxTokens
                          fastChatModel
                          fastChatModelMaxTokens
                          completionModel
                          completionModelMaxTokens
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmConfiguration
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmConfiguration
      response:
        bodySize: 248
        content:
          encoding: base64
          mimeType: application/json
          size: 248
          text: "[\"H4sIAAAAAAAAA3zOwQqCQBAG4HeZs+K0BqFXr3rrBYbdMRdtJ3ZXKmTfPSyiSOg08PP/H\
            7OAoUhQLxBs5PVqMfe27RpxvT3NnqIV98wHip0YnqAGcnHwcrG60BPNhvMyD+Icx1yh\
            2qNSFWSfQUe3o4zsAtQ7hYgZ9BRi898byI7ziyvxAD+bLanlfJl4ffaN9tbzVfwYihD\
            JazHsYdP7gipETCmlBwAAAP//AwBQeP+1EwEAAA==\"]"
          textDecoded:
            data:
              site:
                codyLLMConfiguration:
                  chatModel: anthropic/claude-3-sonnet-20240229
                  chatModelMaxTokens: 12000
                  completionModel: fireworks/starcoder
                  completionModelMaxTokens: 9000
                  fastChatModel: anthropic/claude-3-haiku-20240307
                  fastChatModelMaxTokens: 12000
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.202Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7edf90ea650cb304fe26f9d57bd79477
      _order: 0
      cache: {}
      request:
        bodySize: 165
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "165"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 345
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmConfiguration {
                  site {
                      codyLLMConfiguration {
                          smartContextWindow
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmConfiguration
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmConfiguration
      response:
        bodySize: 139
        content:
          encoding: base64
          mimeType: application/json
          size: 139
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdHJ+SmVPj6+zvl5aZnppUWJJZn5eWD53MSiE\
            uf8vJLUipLwzLyU/HIlK6XUvMSknNQUpdra2loAAAAA//8=\",\"AwDoCDSlSwAAAA==\
            \"]"
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.230Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: d890a82b3cc2fe4d514f289e8fe6d158
      _order: 0
      cache: {}
      request:
        bodySize: 150
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "150"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 340
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentSiteCodyLlmProvider {
                  site {
                      codyLLMConfiguration {
                          provider
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentSiteCodyLlmProvider
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentSiteCodyLlmProvider
      response:
        bodySize: 131
        content:
          encoding: base64
          mimeType: application/json
          size: 131
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdHJ+SmVPj6+zvl5aZnppUWJJZn5eSDxgqL8s\
            syU1CIlK6Xi/NKi5NT0osSCDKXa2tpaAAAAAP//\",\"AwAfFAXARQAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.204Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 7f3ff10a39505669cb5d36145df5fa95
      _order: 0
      cache: {}
      request:
        bodySize: 227
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "227"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 325
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentUser {
                  currentUser {
                      id
                      hasVerifiedEmail
                      displayName
                      username
                      avatarURL
                      primaryEmail {
                          email
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentUser
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentUser
      response:
        bodySize: 348
        content:
          encoding: base64
          mimeType: application/json
          size: 348
          text: "[\"H4sIAAAAAAAAA2RPy06DQBT9l7uGgmm0MEkTbW1dVImPlNTlZbiFAYbBeVQp4d8bUhMX7\
            s7JOTmPAXK0CGwA7rSm1u4N6YmKHBikh6ThlTonj283LxVfggclmpS0OArKNxJFA8xq\
            Rx7kwnQN9glKAgYfymlOhcauXCnrx2EYggfOkG6vBvNnyJSNa//YfksHHuAJLer9+zM\
            wKK3tDAuCppzPCqWKhqYErlpLrZ1xJQMMHtZFpPhui1/ZJ7lVnVW3+XZz/omyQxrhQs\
            xNmu3WyWu6eApdf6qXJr7zOXjQaSFR978nBqAr+LfsvpiEqQ3GcRwvAAAA//8DALThL\
            hwxAQAA\"]"
          textDecoded:
            data:
              currentUser:
                avatarURL: https://lh3.googleusercontent.com/a/ACg8ocKFaqbYeuBkbj5dFEzx8bXV8a7i3sVbKCNPV7G0uyvk=s96-c
                displayName: SourcegraphBot-9000
                hasVerifiedEmail: true
                id: VXNlcjozNDQ1Mjc=
                primaryEmail:
                  email: sourcegraphbot9k@gmail.com
                username: sourcegraphbot9k-fnwmu
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.250Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 84b962509b12000d0eef7c8a8fa655f3
      _order: 0
      cache: {}
      request:
        bodySize: 268
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "268"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 341
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query CurrentUserCodySubscription {
                  currentUser {
                      codySubscription {
                          status
                          plan
                          applyProRateLimits
                          currentPeriodStartAt
                          currentPeriodEndAt
                      }
                  }
              }
            variables: {}
        queryString:
          - name: CurrentUserCodySubscription
            value: null
        url: https://sourcegraph.com/.api/graphql?CurrentUserCodySubscription
      response:
        bodySize: 231
        content:
          encoding: base64
          mimeType: application/json
          size: 231
          text: "[\"H4sIAAAAAAAAA1zMsQrCMBSF4Xc5c4U2FoVsRToIgqWtDm6xyRCoSbi5GUrJu4uCoI7n5\
            +Os0IoV5IopERnHl2joPb1ehnSPE9nA1rtXi6w4RUg0h/F4bVEgzMpBouvPKKBCmJeO\
            fK/YnOzDcoRkSqb4fHeGrNcDK+KGISFKUW/K3aaqRyFkVcmtuOFPt05/2f2vzTnnJwA\
            AAP//\",\"AwBuKtnYwgAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.512Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: ea3ddfc16f0b52a2180a9bd21c87dc08
      _order: 0
      cache: {}
      request:
        bodySize: 144
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "144"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 240
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query Repository($name: String!) {
              	repository(name: $name) {
              		id
              	}
              }
            variables:
              name: github.com/sourcegraph/cody
        queryString:
          - name: Repository
            value: null
        url: https://sourcegraph.com/.api/graphql?Repository
      response:
        bodySize: 123
        content:
          encoding: base64
          mimeType: application/json
          size: 123
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqSi3IL84syS+qBPEyU5SslEJzw8qTjP0KUtwtK1ND8\
            o18Q3wr/UJ8K/0dbW2VamtrAQAAAP//\",\"AwDHAhygPQAAAA==\"]"
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:36 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "258"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:36.650Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 8d297306aeea324b87ef494954016fba
      _order: 0
      cache: {}
      request:
        bodySize: 164
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "164"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 248
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteIdentification {
              	site {
              		siteID
              		productSubscription {
              			license {
              				hashedKey
              			}
              		}
              	}
              }
            variables: {}
        queryString:
          - name: SiteIdentification
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteIdentification
      response:
        bodySize: 212
        content:
          encoding: base64
          mimeType: application/json
          size: 212
          text: "[\"H4sIAAAAAAAAAzTLsQ6CMBCA4Xe52YX2rgVmF+PI4HztXaWJAdKWwRDf3WDiv/zTd4BwY\
            xgPqLnp/7crjDCte4n6LLzNDw1wga2sssc27aHGkreW1+UErxx1qT87c51V7vqGEYbo\
            u9AZm/okmgxi70QZlZzzqNEaJOMNReocCdkgiCk4j4btwJwIPmdfAAAA//8DABj2u36\
            gAAAA\"]"
          textDecoded:
            data:
              site:
                productSubscription:
                  license:
                    hashedKey: 9c71b123f8fdef24486dea4e56674ec32452725c5165d53bd44fb6742a39aaf5
                siteID: SourcegraphWeb
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:36 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "258"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:36.613Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: b584bf96a3d88ab96114e5cbea1e4bca
      _order: 0
      cache: {}
      request:
        bodySize: 164
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "164"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 332
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteIdentification {
              	site {
              		siteID
              		productSubscription {
              			license {
              				hashedKey
              			}
              		}
              	}
              }
            variables: {}
        queryString:
          - name: SiteIdentification
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteIdentification
      response:
        bodySize: 212
        content:
          encoding: base64
          mimeType: application/json
          size: 212
          text: "[\"H4sIAAAAAAAAAzTLsQ6CMBCA4Xe52YX2rgVmF+PI4HztXaWJAdKWwRDf3WDiv/zTd4BwY\
            xgPqLnp/7crjDCte4n6LLzNDw1wga2sssc27aHGkreW1+UErxx1qT87c51V7vqGEYbo\
            u9AZm/okmgxi70QZlZzzqNEaJOMNReocCdkgiCk4j4btwJwIPmdfAAAA//8DABj2u36\
            gAAAA\"]"
          textDecoded:
            data:
              site:
                productSubscription:
                  license:
                    hashedKey: 9c71b123f8fdef24486dea4e56674ec32452725c5165d53bd44fb6742a39aaf5
                siteID: SourcegraphWeb
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.758Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 203c1896021c3a09dfe619120ea1b725
      _order: 0
      cache: {}
      request:
        bodySize: 101
        cookies: []
        headers:
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "101"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 248
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteProductVersion {
                  site {
                      productVersion
                  }
              }
            variables: {}
        queryString:
          - name: SiteProductVersion
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteProductVersion
      response:
        bodySize: 136
        content:
          encoding: base64
          mimeType: application/json
          size: 136
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdEFRfkppcklYalFxZn5eUpWSkbmlmampvFGB\
            kYmugZmukYm8aZ6JrqmJobGaSmGaSkmZgZKtbW1AAAAAP//AwDJee+dSQAAAA==\"]"
          textDecoded:
            data:
              site:
                productVersion: 279655_2024-06-24_5.4-5413fd1fd460
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:36.900Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
    - _id: 2aa42833ae189b030c5bc322f1d27b0c
      _order: 0
      cache: {}
      request:
        bodySize: 101
        cookies: []
        headers:
          - _fromType: array
            name: authorization
            value: token
              REDACTED_d5e0f0a37c9821e856b923fe14e67a605e3f6c0a517d5a4f46a4e35943ee0f6d
          - _fromType: array
            name: content-type
            value: application/json; charset=utf-8
          - _fromType: array
            name: user-agent
            value: chat-response-quality / v1
          - _fromType: array
            name: accept
            value: "*/*"
          - _fromType: array
            name: content-length
            value: "101"
          - _fromType: array
            name: accept-encoding
            value: gzip,deflate
          - name: host
            value: sourcegraph.com
        headersSize: 332
        httpVersion: HTTP/1.1
        method: POST
        postData:
          mimeType: application/json; charset=utf-8
          params: []
          textJSON:
            query: |-
              
              query SiteProductVersion {
                  site {
                      productVersion
                  }
              }
            variables: {}
        queryString:
          - name: SiteProductVersion
            value: null
        url: https://sourcegraph.com/.api/graphql?SiteProductVersion
      response:
        bodySize: 136
        content:
          encoding: base64
          mimeType: application/json
          size: 136
          text: "[\"H4sIAAAAAAAAA6pWSkksSVSyqlYqzixJBdEFRfkppcklYalFxZn5eUpWSkbmlmampvFGB\
            kYmugZmukYm8aZ6JrqmJobGaSmGaSkmZgZKtbW1AAAAAP//AwDJee+dSQAAAA==\"]"
          textDecoded:
            data:
              site:
                productVersion: 279655_2024-06-24_5.4-5413fd1fd460
        cookies: []
        headers:
          - name: date
            value: Mon, 24 Jun 2024 23:37:37 GMT
          - name: content-type
            value: application/json
          - name: transfer-encoding
            value: chunked
          - name: connection
            value: keep-alive
          - name: retry-after
            value: "257"
          - name: access-control-allow-credentials
            value: "true"
          - name: access-control-allow-origin
            value: ""
          - name: cache-control
            value: no-cache, max-age=0
          - name: vary
            value: Cookie,Accept-Encoding,Authorization,Cookie, Authorization,
              X-Requested-With,Cookie
          - name: x-content-type-options
            value: nosniff
          - name: x-frame-options
            value: DENY
          - name: x-xss-protection
            value: 1; mode=block
          - name: strict-transport-security
            value: max-age=31536000; includeSubDomains; preload
          - name: content-encoding
            value: gzip
        headersSize: 1440
        httpVersion: HTTP/1.1
        redirectURL: ""
        status: 200
        statusText: OK
      startedDateTime: 2024-06-24T23:37:37.201Z
      time: 0
      timings:
        blocked: -1
        connect: -1
        dns: -1
        receive: 0
        send: 0
        ssl: -1
        wait: 0
  pages: []
  version: "1.2"
